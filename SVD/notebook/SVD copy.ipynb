{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100836 entries, 0 to 100835\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   userId     100836 non-null  int64  \n",
      " 1   movieId    100836 non-null  int64  \n",
      " 2   rating     100836 non-null  float64\n",
      " 3   timestamp  100836 non-null  int64  \n",
      "dtypes: float64(1), int64(3)\n",
      "memory usage: 3.1 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1        1     4.0  964982703\n",
       "1       1        3     4.0  964981247\n",
       "2       1        6     4.0  964982224"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/ml-latest-small/ratings.csv')\n",
    "df.info()\n",
    "df.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --------> OBSERVATIONS:\n",
    "\n",
    "+ movieId: A unique identifier for the movie.\n",
    "+ title: The title of the movie, along with its release year in parentheses.\n",
    "+ genres: The genres associated with the movie, separated by pipe characters (|)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for missing values and infinities\n",
    "df.isnull().sum()\n",
    "df.isnull().values.any()\n",
    "# check for infinities\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df.isnull().values.any()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique users: 610\n",
      "\n",
      "Number of unique movies: 9724\n",
      "\n",
      "Number of unique ratings: 10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# unique users\n",
    "print(f'Number of unique users: {df.userId.unique().shape[0]}\\n')\n",
    "\n",
    "# unique movies\n",
    "print(f'Number of unique movies: {df.movieId.unique().shape[0]}\\n')\n",
    "\n",
    "# unique ratings\n",
    "print(f'Number of unique ratings: {df.rating.unique().shape[0]}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M50 set:\n",
      "        userId  movieId  rating   timestamp\n",
      "261         3       31     0.5  1306463578\n",
      "262         3      527     0.5  1306464275\n",
      "263         3      647     0.5  1306463619\n",
      "264         3      688     0.5  1306464228\n",
      "265         3      720     0.5  1306463595\n",
      "...       ...      ...     ...         ...\n",
      "95960     601   170705     5.0  1521397596\n",
      "95961     601   172591     4.5  1521467819\n",
      "95962     601   174055     4.0  1521397739\n",
      "95963     601   176371     4.0  1521397623\n",
      "95964     601   177765     4.5  1521397621\n",
      "\n",
      "[6273 rows x 4 columns]\n",
      "M100 set:\n",
      "        userId  movieId  rating   timestamp\n",
      "1569       16       47     3.5  1377477814\n",
      "1570       16       50     4.0  1377476781\n",
      "1571       16      111     4.5  1377477446\n",
      "1572       16      204     2.0  1377476617\n",
      "1573       16      260     3.0  1377476936\n",
      "...       ...      ...     ...         ...\n",
      "98474     606    76093     4.0  1368460114\n",
      "98475     606    91500     4.5  1349082477\n",
      "98476     606    95105     2.5  1349083032\n",
      "98477     606    97225     3.5  1368460191\n",
      "98478     606    98243     3.0  1368460316\n",
      "\n",
      "[15912 rows x 4 columns]\n",
      "M400 set:\n",
      "        userId  movieId  rating  timestamp\n",
      "0           1        1     4.0  964982703\n",
      "1           1        3     4.0  964981247\n",
      "2           1        6     4.0  964982224\n",
      "3           1       47     5.0  964983815\n",
      "4           1       50     5.0  964982931\n",
      "...       ...      ...     ...        ...\n",
      "99529     609      892     3.0  847221080\n",
      "99530     609     1056     3.0  847221080\n",
      "99531     609     1059     3.0  847221054\n",
      "99532     609     1150     4.0  847221054\n",
      "99533     609     1161     4.0  847221080\n",
      "\n",
      "[67165 rows x 4 columns]\n",
      "Test set:\n",
      "         userId  movieId  rating   timestamp\n",
      "232          2      318     3.0  1445714835\n",
      "233          2      333     4.0  1445715029\n",
      "234          2     1704     4.5  1445715228\n",
      "235          2     3578     4.0  1445714885\n",
      "236          2     6874     4.0  1445714952\n",
      "...        ...      ...     ...         ...\n",
      "100831     610   166534     4.0  1493848402\n",
      "100832     610   168248     5.0  1493850091\n",
      "100833     610   168250     5.0  1494273047\n",
      "100834     610   168252     5.0  1493846352\n",
      "100835     610   170875     3.0  1493846415\n",
      "\n",
      "[11486 rows x 4 columns]\n",
      "Training set:\n",
      "         userId  movieId  rating   timestamp\n",
      "21452      140     4234     3.0  1012505945\n",
      "22899      156     2080     1.0   951113118\n",
      "58090      380   182639     4.0  1536874706\n",
      "79604      495     5254     3.5  1458636268\n",
      "100382     610    69134     3.0  1493848172\n",
      "...        ...      ...     ...         ...\n",
      "49818      318   136024     3.0  1455886225\n",
      "66934      432     5507     1.5  1315242710\n",
      "74191      474     4012     2.0  1046887657\n",
      "80857      510      497     1.5  1141158809\n",
      "40375      274    51709     3.5  1285897528\n",
      "\n",
      "[80668 rows x 4 columns]\n",
      "Test set:\n",
      "       userId  movieId  rating   timestamp\n",
      "0          1     1920     4.0   964981780\n",
      "1          1      457     5.0   964981909\n",
      "2          1     2648     4.0   964983414\n",
      "3          1      316     3.0   964982310\n",
      "4          1      661     5.0   964982838\n",
      "...      ...      ...     ...         ...\n",
      "5247     610     4020     3.5  1479542683\n",
      "5248     610    90600     3.5  1493847740\n",
      "5249     610    57669     5.0  1493845166\n",
      "5250     610     6287     3.0  1493847091\n",
      "5251     610     6620     4.0  1493845340\n",
      "\n",
      "[5252 rows x 4 columns]\n",
      "All-But-One Training set:\n",
      "         userId  movieId  rating   timestamp\n",
      "0            1        1     4.0   964982703\n",
      "1            1        3     4.0   964981247\n",
      "2            1        6     4.0   964982224\n",
      "3            1       47     5.0   964983815\n",
      "4            1       50     5.0   964982931\n",
      "...        ...      ...     ...         ...\n",
      "100831     610   166534     4.0  1493848402\n",
      "100832     610   168248     5.0  1493850091\n",
      "100833     610   168250     5.0  1494273047\n",
      "100834     610   168252     5.0  1493846352\n",
      "100835     610   170875     3.0  1493846415\n",
      "\n",
      "[100226 rows x 4 columns]\n",
      "All-But-One Test set:\n",
      "        userId  movieId  rating   timestamp\n",
      "219         1     3578     5.0   964980668\n",
      "245         2    77455     3.0  1445714941\n",
      "294         3     6835     5.0  1306463670\n",
      "306         4      106     4.0   986848784\n",
      "548         5      527     5.0   847434960\n",
      "...       ...      ...     ...         ...\n",
      "98227     606     7131     3.0  1171813499\n",
      "98506     607      423     3.0   963080410\n",
      "98707     608      188     3.5  1117503407\n",
      "99501     609      137     3.0   847221054\n",
      "99587     610      903     5.0  1479542931\n",
      "\n",
      "[610 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "def split_data_by_rated_items(df, test_size, given_n):\n",
    "    train_df, test_df = train_test_split(df, test_size=test_size, random_state=42, stratify=df['userId'])\n",
    "\n",
    "    # For each user in the test set, keep only 'given_n' rated items if they have rated that many,\n",
    "    # otherwise keep all the items they have rated.\n",
    "    test_df = test_df.groupby('userId').apply(lambda x: x.sample(min(len(x), given_n), random_state=42))\n",
    "\n",
    "    return train_df, test_df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "def split_data_by_unique_users(df):\n",
    "    unique_users = df['userId'].unique()\n",
    "    np.random.shuffle(unique_users)\n",
    "\n",
    "    # Get the user IDs for each set\n",
    "    M50_users = unique_users[:50]\n",
    "    M100_users = unique_users[50:150]\n",
    "    M400_users = unique_users[150:550]\n",
    "    test_users = unique_users[550:]\n",
    "\n",
    "    # Split the DataFrame into the different sets based on the user IDs\n",
    "    M50_df = df[df['userId'].isin(M50_users)]\n",
    "    M100_df = df[df['userId'].isin(M100_users)]\n",
    "    M400_df = df[df['userId'].isin(M400_users)]\n",
    "    test_df = df[df['userId'].isin(test_users)]\n",
    "\n",
    "    return M50_df, M100_df, M400_df, test_df\n",
    "\n",
    "\n",
    "def all_but_one(df):\n",
    "    # For each user, select one rating and split it into a separate DataFrame\n",
    "    test_df = df.groupby('userId').sample(n=1, random_state=42)\n",
    "    train_df = df.drop(test_df.index)\n",
    "    \n",
    "    return train_df, test_df\n",
    "\n",
    "# Call the function\n",
    "M50_df, M100_df, M400_df, test_df = split_data_by_unique_users(df)\n",
    "\n",
    "print('M50 set:\\n', M50_df)\n",
    "print('M100 set:\\n', M100_df)\n",
    "print('M400 set:\\n', M400_df)\n",
    "print('Test set:\\n', test_df)\n",
    "\n",
    "# Call the functions\n",
    "train_df_given_10, test_df_given_10 = split_data_by_rated_items(df, test_size=0.2, given_n=10)  # Modify test_size and given_n as needed\n",
    "print('Training set:\\n', train_df_given_10)\n",
    "print('Test set:\\n', test_df_given_10)\n",
    "\n",
    "train_df, test_df = all_but_one(df)\n",
    "print('All-But-One Training set:\\n', train_df)\n",
    "print('All-But-One Test set:\\n', test_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1        1     4.0  964982703\n",
       "1       1        3     4.0  964981247\n",
       "2       1        6     4.0  964982224"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rmse: root mean squared error\n",
    "def rmse(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    return sqrt(mse)\n",
    "\n",
    "# mae: mean absolute error\n",
    "def mae(y_true, y_pred):\n",
    "    return np.mean(np.abs(np.array(y_true) - np.array(y_pred)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVD\n",
    "\n",
    "+ \"cold-start handling\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVD:\n",
    "    def __init__(self, num_factors, learning_rate, num_epochs, top_n=10):\n",
    "        # Initializing the instance variables with given arguments\n",
    "        self.num_factors = num_factors\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_epochs = num_epochs\n",
    "        self.top_n = top_n  # number of movies to recommend for cold start\n",
    "\n",
    "    def fit(self, user_item_ratings):\n",
    "        # Initializing the user and movie latent factors matrices with random numbers\n",
    "        self.user_factors = np.random.randn(user_item_ratings.userId.nunique(), self.num_factors)\n",
    "        self.movie_factors = np.random.randn(user_item_ratings.movieId.nunique(), self.num_factors)\n",
    "        \n",
    "        # Creating dictionaries to map user and movie IDs to their respective indices in the factor matrices\n",
    "        self.user_index = {user_id: idx for idx, user_id in enumerate(user_item_ratings.userId.unique())}\n",
    "        self.movie_index = {movie_id: idx for idx, movie_id in enumerate(user_item_ratings.movieId.unique())}\n",
    "\n",
    "        # Calculate average rating for each movie\n",
    "        self.movie_avg_rating = user_item_ratings.groupby('movieId')['rating'].mean().to_dict()\n",
    "\n",
    "        # Get top-N movies based on average rating for cold start problem\n",
    "        sorted_movies_by_avg_rating = sorted(self.movie_avg_rating.items(), key=lambda x: x[1], reverse=True)\n",
    "        self.top_n_movies = [movie_id for movie_id, _ in sorted_movies_by_avg_rating[:self.top_n]]\n",
    "\n",
    "        # Loop over epochs\n",
    "        for epoch in range(self.num_epochs):\n",
    "            # Loop over all user-item-rating rows in the DataFrame\n",
    "            for idx, row in user_item_ratings.iterrows():\n",
    "                user_id = row['userId']\n",
    "                movie_id = row['movieId']\n",
    "                rating = row['rating']\n",
    "\n",
    "                # Getting the user and movie indices for the current user-item pair\n",
    "                user_idx = self.user_index[user_id]\n",
    "                movie_idx = self.movie_index[movie_id]\n",
    "\n",
    "                # Computing the predicted rating as the dot product of the user and movie factors\n",
    "                prediction = np.dot(self.user_factors[user_idx], self.movie_factors[movie_idx])\n",
    "                # Computing the error as the difference between the actual and predicted ratings\n",
    "                error = rating - prediction\n",
    "\n",
    "                # Updating the user and movie factor vectors in the direction that minimizes the error\n",
    "                self.user_factors[user_idx] += self.learning_rate * error * self.movie_factors[movie_idx]\n",
    "                self.movie_factors[movie_idx] += self.learning_rate * error * self.user_factors[user_idx]\n",
    "\n",
    "    def predict(self, user_id, movie_id):\n",
    "        # Getting the user and movie indices for the given user-item pair\n",
    "        user_idx = self.user_index.get(user_id, -1)\n",
    "        movie_idx = self.movie_index.get(movie_id, -1)\n",
    "\n",
    "        # If the user or the movie is not present in the training data, return the movie's average rating\n",
    "        if user_idx == -1 or movie_idx == -1:\n",
    "            return self.movie_avg_rating.get(movie_id)\n",
    "\n",
    "        # Otherwise, return the predicted rating as the dot product of the user and movie factors\n",
    "        return np.dot(self.user_factors[user_idx], self.movie_factors[movie_idx])\n",
    "\n",
    "    def recommend(self, user_id):\n",
    "        # If the user is not present in the training data, return top-N movies\n",
    "        if user_id not in self.user_index:\n",
    "            return self.top_n_movies\n",
    "\n",
    "        # Otherwise, predict the rating for each movie and return the top-N movies\n",
    "        user_ratings = {movie_id: self.predict(user_id, movie_id) for movie_id in self.movie_index.keys()}\n",
    "        sorted_user_ratings = sorted(user_ratings.items(), key=lambda x: x[1], reverse=True)\n",
    "        return [movie_id for movie_id, _ in sorted_user_ratings[:self.top_n]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE (M50): 1.6440047060689733\n",
      "Test MAE (M50): 1.244640771592552\n",
      "CPU times: user 2.53 s, sys: 24.9 ms, total: 2.55 s\n",
      "Wall time: 2.55 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Fit the model to the M50 data\n",
    "svd.fit(M50_df)\n",
    "\n",
    "# Predict ratings for the Test set and evaluate\n",
    "test_predictions = test_df.apply(lambda row: svd.predict(row['userId'], row['movieId']), axis=1)\n",
    "\n",
    "# Remove None values and corresponding actual ratings\n",
    "actual_ratings = test_df['rating'][test_predictions.notna()]\n",
    "test_predictions = test_predictions.dropna()\n",
    "\n",
    "print('Test RMSE (M50):', rmse(actual_ratings, test_predictions))\n",
    "print('Test MAE (M50):', mae(actual_ratings, test_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE (M50): 1.3597788921469673\n",
      "Test MAE (M50): 1.015072585570547\n",
      "CPU times: user 17.7 s, sys: 574 ms, total: 18.2 s\n",
      "Wall time: 17.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Fit the model to the M100 data\n",
    "svd.fit(M100_df)\n",
    "\n",
    "# Predict ratings for the Test set and evaluate\n",
    "test_predictions = test_df.apply(lambda row: svd.predict(row['userId'], row['movieId']), axis=1)\n",
    "# Remove None values and corresponding actual ratings\n",
    "actual_ratings = test_df['rating'][test_predictions.notna()]\n",
    "test_predictions = test_predictions.dropna()\n",
    "\n",
    "print('Test RMSE (M50):', rmse(actual_ratings, test_predictions))\n",
    "print('Test MAE (M50):', mae(actual_ratings, test_predictions))\n",
    "\n",
    "# # Fit the model to the M400 data\n",
    "# svd.fit(M400_df)\n",
    "\n",
    "# # Predict ratings for the Test set and evaluate\n",
    "# test_predictions = test_df.apply(lambda row: svd.predict(row['userId'], row['movieId']), axis=1)\n",
    "# print('Test RMSE (M400):', rmse(test_df['rating'], test_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE (M50): 0.9970642086398543\n",
      "Test MAE (M50): 0.7348708569627388\n",
      "CPU times: user 1min 14s, sys: 2.59 s, total: 1min 17s\n",
      "Wall time: 1min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Fit the model to the M400 data\n",
    "svd.fit(M400_df)\n",
    "\n",
    "# Predict ratings for the Test set and evaluate\n",
    "test_predictions = test_df.apply(lambda row: svd.predict(row['userId'], row['movieId']), axis=1)\n",
    "# Remove None values and corresponding actual ratings\n",
    "actual_ratings = test_df['rating'][test_predictions.notna()]\n",
    "test_predictions = test_predictions.dropna()\n",
    "\n",
    "print('Test RMSE (M50):', rmse(actual_ratings, test_predictions))\n",
    "print('Test MAE (M50):', mae(actual_ratings, test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN values in each column:\n",
      "userId       0\n",
      "movieId      0\n",
      "rating       0\n",
      "timestamp    0\n",
      "dtype: int64\n",
      "Number of infinity values in each column:\n",
      "userId       0\n",
      "movieId      0\n",
      "rating       0\n",
      "timestamp    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bt/7ws71xxn45bffcbhj7ddvm080000gn/T/ipykernel_33636/987083771.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  M50_df.fillna(M50_df.mean(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Check for NaN values\n",
    "print(\"Number of NaN values in each column:\")\n",
    "print(M50_df.isnull().sum())\n",
    "\n",
    "# If there are NaN values, decide how to handle them\n",
    "# Here's an example of filling NaNs with the mean of the column\n",
    "M50_df.fillna(M50_df.mean(), inplace=True)\n",
    "\n",
    "# Check for infinity values\n",
    "print(\"Number of infinity values in each column:\")\n",
    "print(np.isinf(M50_df).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "219           NaN\n",
       "245           NaN\n",
       "294      3.979521\n",
       "306           NaN\n",
       "548           NaN\n",
       "           ...   \n",
       "98227         NaN\n",
       "98506         NaN\n",
       "98707         NaN\n",
       "99501         NaN\n",
       "99587         NaN\n",
       "Length: 610, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219     NaN\n",
      "245     NaN\n",
      "306     NaN\n",
      "548     NaN\n",
      "596     NaN\n",
      "         ..\n",
      "98227   NaN\n",
      "98506   NaN\n",
      "98707   NaN\n",
      "99501   NaN\n",
      "99587   NaN\n",
      "Length: 560, dtype: float64\n",
      "\n",
      "\n",
      "\n",
      "219     NaN\n",
      "245     NaN\n",
      "306     NaN\n",
      "548     NaN\n",
      "596     NaN\n",
      "         ..\n",
      "98227   NaN\n",
      "98506   NaN\n",
      "98707   NaN\n",
      "99501   NaN\n",
      "99587   NaN\n",
      "Length: 560, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(test_predictions[test_predictions.isna()]) # Print NaN values\n",
    "print(\"\\n\\n\")\n",
    "print(test_predictions[~np.isfinite(test_predictions)]) # Print infinity values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVD:\n",
    "    def __init__(self, num_factors, learning_rate, num_epochs):\n",
    "        # Initializing the instance variables with given arguments\n",
    "        self.num_factors = num_factors\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_epochs = num_epochs\n",
    "\n",
    "    def fit(self, user_item_ratings):\n",
    "        # Initializing the user and movie latent factors matrices with random numbers\n",
    "        self.user_factors = np.random.randn(user_item_ratings.userId.nunique(), self.num_factors)\n",
    "        self.movie_factors = np.random.randn(user_item_ratings.movieId.nunique(), self.num_factors)\n",
    "        \n",
    "        # Creating dictionaries to map user and movie IDs to their respective indices in the factor matrices\n",
    "        self.user_index = {user_id: idx for idx, user_id in enumerate(user_item_ratings.userId.unique())}\n",
    "        self.movie_index = {movie_id: idx for idx, movie_id in enumerate(user_item_ratings.movieId.unique())}\n",
    "\n",
    "        # Loop over epochs\n",
    "        for epoch in range(self.num_epochs):\n",
    "            # Loop over all user-item-rating rows in the DataFrame\n",
    "            for idx, row in user_item_ratings.iterrows():\n",
    "                user_id = row['userId']\n",
    "                movie_id = row['movieId']\n",
    "                rating = row['rating']\n",
    "\n",
    "\n",
    "                # Getting the user and movie indices for the current user-item pair\n",
    "                user_idx = self.user_index[user_id]\n",
    "                movie_idx = self.movie_index[movie_id]\n",
    "\n",
    "                # Computing the predicted rating as the dot product of the user and movie factors\n",
    "                prediction = np.dot(self.user_factors[user_idx], self.movie_factors[movie_idx])\n",
    "                # Computing the error as the difference between the actual and predicted ratings\n",
    "                error = rating - prediction\n",
    "\n",
    "                # Updating the user and movie factor vectors in the direction that minimizes the error\n",
    "                self.user_factors[user_idx] += self.learning_rate * error * self.movie_factors[movie_idx]\n",
    "                self.movie_factors[movie_idx] += self.learning_rate * error * self.user_factors[user_idx]\n",
    "\n",
    "    def predict(self, user_id, movie_id):\n",
    "        # Getting the user and movie indices for the given user-item pair\n",
    "        user_idx = self.user_index.get(user_id, -1)\n",
    "        movie_idx = self.movie_index.get(movie_id, -1)\n",
    "\n",
    "        # If either the user or the movie is not present in the training data, return None\n",
    "        if user_idx == -1 or movie_idx == -1:\n",
    "            return None\n",
    "\n",
    "        # Otherwise, return the predicted rating as the dot product of the user and movie factors\n",
    "        return np.dot(self.user_factors[user_idx], self.movie_factors[movie_idx])\n",
    "\n",
    "# Creating an instance of the SVD class with desired parameters\n",
    "num_factors = 10\n",
    "learning_rate = 0.01\n",
    "num_epochs = 10\n",
    "\n",
    "svd = SVD(num_factors, learning_rate, num_epochs)\n",
    "\n",
    "# Fitting the model to the training data (supposing you have a DataFrame `df`)\n",
    "# svd.fit(df)\n",
    "\n",
    "# Predicting the rating for a given user-item pair\n",
    "# svd.predict(user_id, movie_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:9\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Train the model on the train set\n",
    "model_SVD = SVD(num_factors=35, learning_rate=0.001, num_epochs=100)\n",
    "model_SVD.fit(train_df)\n",
    "\n",
    "# Predict and evaluate on the test set\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for _, (user_id, movie_id, rating) in test_df.iterrows():\n",
    "    prediction = model_SVD.predict(user_id, movie_id)\n",
    "    \n",
    "    if prediction is not None:\n",
    "        y_true.append(rating)\n",
    "        y_pred.append(prediction)\n",
    "\n",
    "rmse_value = rmse(y_true, y_pred)\n",
    "print(f\"Root Mean Squared Error: {rmse_value}\")\n",
    "print(f\"Mean Absolute Error: {mae(y_true, y_pred)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN values in each column:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'M50_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/tnathu-ai/VSCode/recommender-system/SVD/notebook/SVD copy.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/tnathu-ai/VSCode/recommender-system/SVD/notebook/SVD%20copy.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Check for NaN values\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/tnathu-ai/VSCode/recommender-system/SVD/notebook/SVD%20copy.ipynb#X20sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mNumber of NaN values in each column:\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/tnathu-ai/VSCode/recommender-system/SVD/notebook/SVD%20copy.ipynb#X20sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(M50_df\u001b[39m.\u001b[39misnull()\u001b[39m.\u001b[39msum())\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/tnathu-ai/VSCode/recommender-system/SVD/notebook/SVD%20copy.ipynb#X20sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# If there are NaN values, decide how to handle them\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/tnathu-ai/VSCode/recommender-system/SVD/notebook/SVD%20copy.ipynb#X20sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# Here's an example of filling NaNs with the mean of the column\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/tnathu-ai/VSCode/recommender-system/SVD/notebook/SVD%20copy.ipynb#X20sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m M50_df\u001b[39m.\u001b[39mfillna(M50_df\u001b[39m.\u001b[39mmean(), inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'M50_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Check for NaN values\n",
    "print(\"Number of NaN values in each column:\")\n",
    "print(M50_df.isnull().sum())\n",
    "\n",
    "# If there are NaN values, decide how to handle them\n",
    "# Here's an example of filling NaNs with the mean of the column\n",
    "M50_df.fillna(M50_df.mean(), inplace=True)\n",
    "\n",
    "# Check for infinity values\n",
    "print(\"Number of infinity values in each column:\")\n",
    "print(np.isinf(M50_df).sum())\n",
    "\n",
    "# If there are infinity values, decide how to handle them\n",
    "# Here's an example of replacing infinities with a large number\n",
    "M50_df.replace([np.inf, -np.inf], 1e12, inplace=True)\n",
    "\n",
    "# If there are still errors, you might need to check for and handle extremely large values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1e+03 ns, sys: 0 ns, total: 1e+03 ns\n",
      "Wall time: 4.05 Âµs\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/tnathu-ai/VSCode/recommender-system/SVD/notebook/SVD copy.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/tnathu-ai/VSCode/recommender-system/SVD/notebook/SVD%20copy.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Predict ratings for the Test set and evaluate\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/tnathu-ai/VSCode/recommender-system/SVD/notebook/SVD%20copy.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m test_predictions \u001b[39m=\u001b[39m test_df\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m row: svd\u001b[39m.\u001b[39mpredict(row[\u001b[39m'\u001b[39m\u001b[39muserId\u001b[39m\u001b[39m'\u001b[39m], row[\u001b[39m'\u001b[39m\u001b[39mmovieId\u001b[39m\u001b[39m'\u001b[39m]), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/tnathu-ai/VSCode/recommender-system/SVD/notebook/SVD%20copy.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTest RMSE (M50):\u001b[39m\u001b[39m'\u001b[39m, rmse(test_df[\u001b[39m'\u001b[39;49m\u001b[39mrating\u001b[39;49m\u001b[39m'\u001b[39;49m], test_predictions))\n",
      "\u001b[1;32m/Users/tnathu-ai/VSCode/recommender-system/SVD/notebook/SVD copy.ipynb Cell 13\u001b[0m in \u001b[0;36mrmse\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/tnathu-ai/VSCode/recommender-system/SVD/notebook/SVD%20copy.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrmse\u001b[39m(y_true, y_pred):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/tnathu-ai/VSCode/recommender-system/SVD/notebook/SVD%20copy.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     mse \u001b[39m=\u001b[39m mean_squared_error(y_true, y_pred)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/tnathu-ai/VSCode/recommender-system/SVD/notebook/SVD%20copy.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m sqrt(mse)\n",
      "File \u001b[0;32m~/.conda/envs/Advanced_Programming_for_Data_Science/lib/python3.10/site-packages/sklearn/metrics/_regression.py:438\u001b[0m, in \u001b[0;36mmean_squared_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmean_squared_error\u001b[39m(\n\u001b[1;32m    379\u001b[0m     y_true, y_pred, \u001b[39m*\u001b[39m, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, multioutput\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39muniform_average\u001b[39m\u001b[39m\"\u001b[39m, squared\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    380\u001b[0m ):\n\u001b[1;32m    381\u001b[0m     \u001b[39m\"\"\"Mean squared error regression loss.\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \n\u001b[1;32m    383\u001b[0m \u001b[39m    Read more in the :ref:`User Guide <mean_squared_error>`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[39m    0.825...\u001b[39;00m\n\u001b[1;32m    437\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 438\u001b[0m     y_type, y_true, y_pred, multioutput \u001b[39m=\u001b[39m _check_reg_targets(\n\u001b[1;32m    439\u001b[0m         y_true, y_pred, multioutput\n\u001b[1;32m    440\u001b[0m     )\n\u001b[1;32m    441\u001b[0m     check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    442\u001b[0m     output_errors \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39maverage((y_true \u001b[39m-\u001b[39m y_pred) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, weights\u001b[39m=\u001b[39msample_weight)\n",
      "File \u001b[0;32m~/.conda/envs/Advanced_Programming_for_Data_Science/lib/python3.10/site-packages/sklearn/metrics/_regression.py:96\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[1;32m     94\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[1;32m     95\u001b[0m y_true \u001b[39m=\u001b[39m check_array(y_true, ensure_2d\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[0;32m---> 96\u001b[0m y_pred \u001b[39m=\u001b[39m check_array(y_pred, ensure_2d\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[1;32m     98\u001b[0m \u001b[39mif\u001b[39;00m y_true\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m     99\u001b[0m     y_true \u001b[39m=\u001b[39m y_true\u001b[39m.\u001b[39mreshape((\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m))\n",
      "File \u001b[0;32m~/.conda/envs/Advanced_Programming_for_Data_Science/lib/python3.10/site-packages/sklearn/utils/validation.py:800\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    794\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    795\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    796\u001b[0m             \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    797\u001b[0m         )\n\u001b[1;32m    799\u001b[0m     \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 800\u001b[0m         _assert_all_finite(array, allow_nan\u001b[39m=\u001b[39;49mforce_all_finite \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    802\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_samples \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    803\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m~/.conda/envs/Advanced_Programming_for_Data_Science/lib/python3.10/site-packages/sklearn/utils/validation.py:114\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    108\u001b[0m         allow_nan\n\u001b[1;32m    109\u001b[0m         \u001b[39mand\u001b[39;00m np\u001b[39m.\u001b[39misinf(X)\u001b[39m.\u001b[39many()\n\u001b[1;32m    110\u001b[0m         \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_nan\n\u001b[1;32m    111\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39misfinite(X)\u001b[39m.\u001b[39mall()\n\u001b[1;32m    112\u001b[0m     ):\n\u001b[1;32m    113\u001b[0m         type_err \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39minfinity\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m allow_nan \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mNaN, infinity\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 114\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    115\u001b[0m             msg_err\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    116\u001b[0m                 type_err, msg_dtype \u001b[39mif\u001b[39;00m msg_dtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m X\u001b[39m.\u001b[39mdtype\n\u001b[1;32m    117\u001b[0m             )\n\u001b[1;32m    118\u001b[0m         )\n\u001b[1;32m    119\u001b[0m \u001b[39m# for object dtype data, we only check for NaNs (GH-13254)\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[39melif\u001b[39;00m X\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mdtype(\u001b[39m\"\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_nan:\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "%time\n",
    "# Fit the model to the M50 data\n",
    "svd.fit(M50_df)\n",
    "# Predict ratings for the Test set and evaluate\n",
    "test_predictions = test_df.apply(lambda row: svd.predict(row['userId'], row['movieId']), axis=1)\n",
    "print('Test RMSE (M50):', rmse(test_df['rating'], test_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
