{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "import pandas as pd\n",
    "\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from math import sqrt\n",
    "import openai\n",
    "import os\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from openai.error import RateLimitError\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100836 entries, 0 to 100835\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   userId     100836 non-null  int64  \n",
      " 1   movieId    100836 non-null  int64  \n",
      " 2   rating     100836 non-null  float64\n",
      " 3   timestamp  100836 non-null  int64  \n",
      "dtypes: float64(1), int64(3)\n",
      "memory usage: 3.1 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1        1     4.0  964982703\n",
       "1       1        3     4.0  964981247\n",
       "2       1        6     4.0  964982224"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loads the data\n",
    "df = pd.read_csv('../data/ml-latest-small/ratings.csv')\n",
    "df.info()\n",
    "df.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --------> OBSERVATIONS:\n",
    "\n",
    "+ movieId: A unique identifier for the movie.\n",
    "+ title: The title of the movie, along with its release year in parentheses.\n",
    "+ genres: The genres associated with the movie, separated by pipe characters (|)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique users: 610\n",
      "\n",
      "Number of unique movies: 9724\n",
      "\n",
      "Number of unique ratings: 10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# unique users\n",
    "print(f'Number of unique users: {df.userId.unique().shape[0]}\\n')\n",
    "\n",
    "# unique movies\n",
    "print(f'Number of unique movies: {df.movieId.unique().shape[0]}\\n')\n",
    "\n",
    "# unique ratings\n",
    "print(f'Number of unique ratings: {df.rating.unique().shape[0]}\\n')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Any infinities in the data with NaN?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for missing values and infinities\n",
    "df.isnull().sum()\n",
    "df.isnull().values.any()\n",
    "# check for infinities\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df.isnull().values.any()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splits the data into a training set and a test set using a user-stratified train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M50 set:\n",
      "        userId  movieId  rating   timestamp\n",
      "1569       16       47     3.5  1377477814\n",
      "1570       16       50     4.0  1377476781\n",
      "1571       16      111     4.5  1377477446\n",
      "1572       16      204     2.0  1377476617\n",
      "1573       16      260     3.0  1377476936\n",
      "...       ...      ...     ...         ...\n",
      "98661     607     4022     4.0   997847173\n",
      "98662     607     4023     3.0   997847173\n",
      "98663     607     4054     3.0   997847173\n",
      "98664     607     4069     3.0   997847203\n",
      "98665     607     5060     3.0   963079131\n",
      "\n",
      "[10316 rows x 4 columns]\n",
      "M100 set:\n",
      "        userId  movieId  rating   timestamp\n",
      "300         4       21     3.0   986935199\n",
      "301         4       32     2.0   945173447\n",
      "302         4       45     3.0   986935047\n",
      "303         4       47     2.0   945173425\n",
      "304         4       52     3.0   964622786\n",
      "...       ...      ...     ...         ...\n",
      "99492     608    51903     2.5  1189477736\n",
      "99493     608    51935     4.0  1189563886\n",
      "99494     608    52245     3.0  1189563917\n",
      "99495     608    53996     5.0  1189380659\n",
      "99496     608    54503     4.5  1189368725\n",
      "\n",
      "[15623 rows x 4 columns]\n",
      "M400 set:\n",
      "         userId  movieId  rating   timestamp\n",
      "0            1        1     4.0   964982703\n",
      "1            1        3     4.0   964981247\n",
      "2            1        6     4.0   964982224\n",
      "3            1       47     5.0   964983815\n",
      "4            1       50     5.0   964982931\n",
      "...        ...      ...     ...         ...\n",
      "100831     610   166534     4.0  1493848402\n",
      "100832     610   168248     5.0  1493850091\n",
      "100833     610   168250     5.0  1494273047\n",
      "100834     610   168252     5.0  1493846352\n",
      "100835     610   170875     3.0  1493846415\n",
      "\n",
      "[66659 rows x 4 columns]\n",
      "Test set:\n",
      "        userId  movieId  rating   timestamp\n",
      "1772       18        1     3.5  1455209816\n",
      "1773       18        2     3.0  1455617462\n",
      "1774       18        6     4.0  1460138360\n",
      "1775       18       16     4.5  1461311583\n",
      "1776       18       32     4.0  1455209840\n",
      "...       ...      ...     ...         ...\n",
      "97359     605    74282     4.5  1277096867\n",
      "97360     605    74530     3.0  1277176182\n",
      "97361     605    76093     4.0  1277175655\n",
      "97362     605    76175     2.5  1277176136\n",
      "97363     605    78105     3.5  1277176533\n",
      "\n",
      "[8238 rows x 4 columns]\n",
      "Training set:\n",
      "         userId  movieId  rating   timestamp\n",
      "21452      140     4234     3.0  1012505945\n",
      "22899      156     2080     1.0   951113118\n",
      "58090      380   182639     4.0  1536874706\n",
      "79604      495     5254     3.5  1458636268\n",
      "100382     610    69134     3.0  1493848172\n",
      "...        ...      ...     ...         ...\n",
      "49818      318   136024     3.0  1455886225\n",
      "66934      432     5507     1.5  1315242710\n",
      "74191      474     4012     2.0  1046887657\n",
      "80857      510      497     1.5  1141158809\n",
      "40375      274    51709     3.5  1285897528\n",
      "\n",
      "[80668 rows x 4 columns]\n",
      "Test set:\n",
      "       userId  movieId  rating   timestamp\n",
      "0          1     1920     4.0   964981780\n",
      "1          1      457     5.0   964981909\n",
      "2          1     2648     4.0   964983414\n",
      "3          1      316     3.0   964982310\n",
      "4          1      661     5.0   964982838\n",
      "...      ...      ...     ...         ...\n",
      "5247     610     4020     3.5  1479542683\n",
      "5248     610    90600     3.5  1493847740\n",
      "5249     610    57669     5.0  1493845166\n",
      "5250     610     6287     3.0  1493847091\n",
      "5251     610     6620     4.0  1493845340\n",
      "\n",
      "[5252 rows x 4 columns]\n",
      "All-But-One Training set:\n",
      "         userId  movieId  rating   timestamp\n",
      "0            1        1     4.0   964982703\n",
      "1            1        3     4.0   964981247\n",
      "2            1        6     4.0   964982224\n",
      "3            1       47     5.0   964983815\n",
      "4            1       50     5.0   964982931\n",
      "...        ...      ...     ...         ...\n",
      "100831     610   166534     4.0  1493848402\n",
      "100832     610   168248     5.0  1493850091\n",
      "100833     610   168250     5.0  1494273047\n",
      "100834     610   168252     5.0  1493846352\n",
      "100835     610   170875     3.0  1493846415\n",
      "\n",
      "[100226 rows x 4 columns]\n",
      "All-But-One Test set:\n",
      "        userId  movieId  rating   timestamp\n",
      "219         1     3578     5.0   964980668\n",
      "245         2    77455     3.0  1445714941\n",
      "294         3     6835     5.0  1306463670\n",
      "306         4      106     4.0   986848784\n",
      "548         5      527     5.0   847434960\n",
      "...       ...      ...     ...         ...\n",
      "98227     606     7131     3.0  1171813499\n",
      "98506     607      423     3.0   963080410\n",
      "98707     608      188     3.5  1117503407\n",
      "99501     609      137     3.0   847221054\n",
      "99587     610      903     5.0  1479542931\n",
      "\n",
      "[610 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "def split_data_by_rated_items(df, test_size, given_n):\n",
    "    train_df, test_df = train_test_split(df, test_size=test_size, random_state=42, stratify=df['userId'])\n",
    "\n",
    "    # For each user in the test set, keep only 'given_n' rated items if they have rated that many,\n",
    "    # otherwise keep all the items they have rated.\n",
    "    test_df = test_df.groupby('userId').apply(lambda x: x.sample(min(len(x), given_n), random_state=42))\n",
    "\n",
    "    return train_df, test_df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "def split_data_by_unique_users(df):\n",
    "    unique_users = df['userId'].unique()\n",
    "    np.random.shuffle(unique_users)\n",
    "\n",
    "    # Get the user IDs for each set\n",
    "    M50_users = unique_users[:50]\n",
    "    M100_users = unique_users[50:150]\n",
    "    M400_users = unique_users[150:550]\n",
    "    test_users = unique_users[550:]\n",
    "\n",
    "    # Split the DataFrame into the different sets based on the user IDs\n",
    "    M50_df = df[df['userId'].isin(M50_users)]\n",
    "    M100_df = df[df['userId'].isin(M100_users)]\n",
    "    M400_df = df[df['userId'].isin(M400_users)]\n",
    "    test_df = df[df['userId'].isin(test_users)]\n",
    "\n",
    "    return M50_df, M100_df, M400_df, test_df\n",
    "\n",
    "\n",
    "def all_but_one(df):\n",
    "    # For each user, select one rating and split it into a separate DataFrame\n",
    "    test_df = df.groupby('userId').sample(n=1, random_state=42)\n",
    "    train_df = df.drop(test_df.index)\n",
    "    \n",
    "    return train_df, test_df\n",
    "\n",
    "# Call the function\n",
    "M50_df, M100_df, M400_df, test_df = split_data_by_unique_users(df)\n",
    "\n",
    "print('M50 set:\\n', M50_df)\n",
    "print('M100 set:\\n', M100_df)\n",
    "print('M400 set:\\n', M400_df)\n",
    "print('Test set:\\n', test_df)\n",
    "\n",
    "# Call the functions\n",
    "train_df_given_10, test_df_given_10 = split_data_by_rated_items(df, test_size=0.2, given_n=10)  # Modify test_size and given_n as needed\n",
    "print('Training set:\\n', train_df_given_10)\n",
    "print('Test set:\\n', test_df_given_10)\n",
    "\n",
    "train_df, test_df = all_but_one(df)\n",
    "print('All-But-One Training set:\\n', train_df)\n",
    "print('All-But-One Test set:\\n', test_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1        1     4.0  964982703\n",
       "1       1        3     4.0  964981247\n",
       "2       1        6     4.0  964982224"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "+ RMSE\n",
    "+ MAE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rmse: root mean squared error\n",
    "# def rmse(y_true, y_pred):\n",
    "#     mse = mean_squared_error(y_true, y_pred)\n",
    "#     return sqrt(mse)\n",
    "\n",
    "# rmse from scratch\n",
    "def rmse(y_true, y_pred):\n",
    "    error = 0\n",
    "    for true, pred in zip(y_true, y_pred):\n",
    "        error += (true - pred) ** 2\n",
    "    error /= len(y_true)\n",
    "    return sqrt(error)\n",
    "\n",
    "# mae: mean absolute error\n",
    "def mae(y_true, y_pred):\n",
    "    return np.mean(np.abs(np.array(y_true) - np.array(y_pred)))\n",
    "\n",
    "# f1 score: harmonic mean of precision and recall\n",
    "def f1_score(precisions, recalls):\n",
    "    f1_scores = dict()\n",
    "    for uid in precisions.keys():\n",
    "        p, r = precisions[uid], recalls[uid]\n",
    "        f1_scores[uid] = 2*(p*r) / (p + r) if (p + r) != 0 else 0\n",
    "    return f1_scores\n",
    "\n",
    "# Precision@k: https://github.com/RUCAIBox/RecBole/blob/master/recbole/evaluator/metrics.py\n",
    "def precision_at_k(predictions, k=10, threshold=3.5):\n",
    "    user_est_true = defaultdict(list)\n",
    "    for uid, _, true_r, est in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "\n",
    "    precisions = dict()\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "        n_rel_and_rec_k = sum((true_r >= threshold) for (_, true_r) in user_ratings[:k])\n",
    "        precisions[uid] = n_rel_and_rec_k / k\n",
    "\n",
    "    return precisions\n",
    "\n",
    "# Recall@k: https://github.com/RUCAIBox/RecBole/blob/master/recbole/evaluator/metrics.py\n",
    "def recall_at_k(predictions, k=10, threshold=3.5):\n",
    "    user_est_true = defaultdict(list)\n",
    "    for uid, _, true_r, est in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "\n",
    "    recalls = dict()\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "        n_rel_and_rec_k = sum((true_r >= threshold) for (_, true_r) in user_ratings[:k])\n",
    "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 1\n",
    "\n",
    "    return recalls\n",
    "\n",
    "# NDCG@k\n",
    "def ndcg_at_k(predictions, k=10):\n",
    "    user_est_true = defaultdict(list)\n",
    "    for uid, _, true_r, est in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "\n",
    "    ndcg_values = []\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "        dcg = sum((rel / np.log2(ind + 2)) for ind, (est, rel) in enumerate(user_ratings[:k]))\n",
    "        idcg = sum((rel / np.log2(ind + 2)) for ind, (est, rel) in enumerate(sorted(user_ratings, key=lambda x: x[1], reverse=True)[:k]))\n",
    "        ndcg_values.append(dcg / idcg if idcg > 0.0 else 0.0)\n",
    "\n",
    "    return np.mean(ndcg_values)\n",
    "\n",
    "# evaluate function:\n",
    "def evaluate(predictions, k=10, threshold=3.5):\n",
    "    precisions = precision_at_k(predictions, k=k, threshold=threshold)\n",
    "    recalls = recall_at_k(predictions, k=k, threshold=threshold)\n",
    "    ndcg = ndcg_at_k(predictions, k=k)\n",
    "    \n",
    "    return {\n",
    "        'RMSE': rmse([true_r for uid, _, true_r, _ in predictions], [est for _, _, true_r, est in predictions]),\n",
    "        'MAE': mae([true_r for uid, _, true_r, _ in predictions], [est for _, _, true_r, est in predictions]),\n",
    "        'Precision@k': sum(prec for prec in precisions.values()) / len(precisions),\n",
    "        'Recall@k': sum(rec for rec in recalls.values()) / len(recalls),\n",
    "        'NDCG': ndcg,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "openai.organization = \"org-ppCCXZWpTaByE4cI4jMbZjBx\"\n",
    "# openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "# openai.Model.list()\n",
    "openai.api_key =\"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidRequestError",
     "evalue": "'$.prompt' is invalid. Please check the API reference: https://platform.openai.com/docs/api-reference.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 52\u001b[0m\n\u001b[1;32m     49\u001b[0m     movies_to_predict \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mchoice(unrated_movies, size\u001b[39m=\u001b[39m\u001b[39mmin\u001b[39m(MOVIES_TO_PREDICT, \u001b[39mlen\u001b[39m(unrated_movies)), replace\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     51\u001b[0m     \u001b[39mfor\u001b[39;00m movie \u001b[39min\u001b[39;00m movies_to_predict:\n\u001b[0;32m---> 52\u001b[0m         rating_prediction \u001b[39m=\u001b[39m predict_rating(user, movie)\n\u001b[1;32m     53\u001b[0m         user_movie_ratings[user][movie] \u001b[39m=\u001b[39m rating_prediction\n\u001b[1;32m     55\u001b[0m \u001b[39m# Testing phase\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[28], line 25\u001b[0m, in \u001b[0;36mpredict_rating\u001b[0;34m(user_id, movie_id)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39mwhile\u001b[39;00m retries \u001b[39m<\u001b[39m MAX_RETRIES:\n\u001b[1;32m     23\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m         \u001b[39m# response = openai.Completion.create(model=\"gpt-3.5-turbo\", messages=prompt, max_tokens=5)\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m         response \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mCompletion\u001b[39m.\u001b[39;49mcreate(model\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mgpt-3.5-turbo\u001b[39;49m\u001b[39m\"\u001b[39;49m,prompt\u001b[39m=\u001b[39;49mprompt,max_tokens\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m)\n\u001b[1;32m     27\u001b[0m         \u001b[39m# Extract and parse the rating prediction\u001b[39;00m\n\u001b[1;32m     28\u001b[0m         predicted_rating \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m(response[\u001b[39m'\u001b[39m\u001b[39mchoices\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mmessage\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mstrip())\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/recommender-system/lib/python3.10/site-packages/openai/api_resources/completion.py:25\u001b[0m, in \u001b[0;36mCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/recommender-system/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    155\u001b[0m         url,\n\u001b[1;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/recommender-system/lib/python3.10/site-packages/openai/api_requestor.py:226\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    206\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    207\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    214\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    215\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m    216\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[1;32m    217\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[1;32m    218\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    224\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    225\u001b[0m     )\n\u001b[0;32m--> 226\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[1;32m    227\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/recommender-system/lib/python3.10/site-packages/openai/api_requestor.py:620\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    613\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    614\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    615\u001b[0m         )\n\u001b[1;32m    616\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[1;32m    617\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    618\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    619\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 620\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[1;32m    621\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    622\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[1;32m    623\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    624\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    625\u001b[0m         ),\n\u001b[1;32m    626\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    627\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/recommender-system/lib/python3.10/site-packages/openai/api_requestor.py:683\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    681\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[1;32m    682\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[0;32m--> 683\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[1;32m    684\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[1;32m    685\u001b[0m     )\n\u001b[1;32m    686\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mInvalidRequestError\u001b[0m: '$.prompt' is invalid. Please check the API reference: https://platform.openai.com/docs/api-reference."
     ]
    }
   ],
   "source": [
    "# Constants\n",
    "MAX_RETRIES = 5\n",
    "RETRY_DELAY = 5  # in seconds\n",
    "\n",
    "def predict_rating(user_id, movie_id):\n",
    "    \"\"\"Predict the rating a user would give a movie based on GPT model.\"\"\"\n",
    "    prompt = {\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": f\"Predict the rating (from 0.5 to 5.0 stars in half-star increments) that user with ID {user_id} would give to movie with ID {movie_id}?\"}]\n",
    "    }\n",
    "    retries = 0\n",
    "\n",
    "    while retries < MAX_RETRIES:\n",
    "        try:\n",
    "            # response = openai.Completion.create(model=\"gpt-3.5-turbo\", messages=prompt, max_tokens=5)\n",
    "            response = openai.Completion.create(model=\"gpt-3.5-turbo\",prompt=prompt,max_tokens=5)\n",
    "\n",
    "            # Extract and parse the rating prediction\n",
    "            predicted_rating = float(response['choices'][0]['message']['content'].strip())\n",
    "            return predicted_rating\n",
    "\n",
    "        except RateLimitError:\n",
    "            if retries < MAX_RETRIES - 1:\n",
    "                time.sleep(RETRY_DELAY)\n",
    "                retries += 1\n",
    "                RETRY_DELAY *= 2  # Exponential backoff\n",
    "            else:\n",
    "                print(f\"RateLimitError: Max retries reached for user_id {user_id} and movie_id {movie_id}.\")\n",
    "                return None\n",
    "\n",
    "# Training phase\n",
    "user_movie_ratings = defaultdict(dict)\n",
    "unique_users = train_df['userId'].unique()\n",
    "unique_movies = df['movieId'].unique()\n",
    "\n",
    "MOVIES_TO_PREDICT = 50  # Limiting number of movies to predict per user due to potential long runtime\n",
    "\n",
    "for user in unique_users:\n",
    "    unrated_movies = np.setdiff1d(unique_movies, train_df[train_df['userId'] == user]['movieId'].values)\n",
    "    movies_to_predict = np.random.choice(unrated_movies, size=min(MOVIES_TO_PREDICT, len(unrated_movies)), replace=False)\n",
    "\n",
    "    for movie in movies_to_predict:\n",
    "        rating_prediction = predict_rating(user, movie)\n",
    "        user_movie_ratings[user][movie] = rating_prediction\n",
    "\n",
    "# Testing phase\n",
    "actual_ratings = []\n",
    "predicted_ratings = []\n",
    "\n",
    "for index, row in test_df.iterrows():\n",
    "    user = row['userId']\n",
    "    movie = row['movieId']\n",
    "    actual_rating = row['rating']\n",
    "    predicted_rating = user_movie_ratings.get(user, {}).get(movie, 3.0)  # Default to 3.0 if not found\n",
    "    actual_ratings.append(actual_rating)\n",
    "    predicted_ratings.append(predicted_rating)\n",
    "\n",
    "# Compute RMSE and MAE on the test set\n",
    "print(f\"RMSE on test set: {rmse(actual_ratings, predicted_ratings)}\")\n",
    "print(f\"MAE on test set: {mae(actual_ratings, predicted_ratings)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidRequestError",
     "evalue": "This is a chat model and not supported in the v1/completions endpoint. Did you mean to use v1/chat/completions?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 55\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[39m# Example Usage\u001b[39;00m\n\u001b[1;32m     54\u001b[0m ratings_matrix \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((\u001b[39m100\u001b[39m, \u001b[39m100\u001b[39m))\n\u001b[0;32m---> 55\u001b[0m recommended_movies \u001b[39m=\u001b[39m get_movie_recommendations(\u001b[39m5\u001b[39;49m, ratings_matrix)\n\u001b[1;32m     56\u001b[0m \u001b[39mprint\u001b[39m(recommended_movies)\n",
      "Cell \u001b[0;32mIn[31], line 40\u001b[0m, in \u001b[0;36mget_movie_recommendations\u001b[0;34m(user_id, ratings_matrix)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[39mfor\u001b[39;00m movie \u001b[39min\u001b[39;00m movies_to_predict:\n\u001b[1;32m     39\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 40\u001b[0m         prediction \u001b[39m=\u001b[39m predict_rating(user_id, movie)\n\u001b[1;32m     41\u001b[0m         \u001b[39mif\u001b[39;00m prediction \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39m1\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m prediction \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m5\u001b[39m:\n\u001b[1;32m     42\u001b[0m             predicted_ratings[movie] \u001b[39m=\u001b[39m prediction\n",
      "Cell \u001b[0;32mIn[31], line 13\u001b[0m, in \u001b[0;36mpredict_rating\u001b[0;34m(user_id, movie_id)\u001b[0m\n\u001b[1;32m      8\u001b[0m prompt \u001b[39m=\u001b[39m (\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBased on historical data patterns of movie ratings from users, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      9\u001b[0m           \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpredict the rating on a scale from 1 to 5 that user \u001b[39m\u001b[39m{\u001b[39;00muser_id\u001b[39m}\u001b[39;00m\u001b[39m would give to movie \u001b[39m\u001b[39m{\u001b[39;00mmovie_id\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     10\u001b[0m           \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mProvide a numeric answer between 1 and 5.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 13\u001b[0m     response \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mCompletion\u001b[39m.\u001b[39;49mcreate(model\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mgpt-3.5-turbo\u001b[39;49m\u001b[39m\"\u001b[39;49m, prompt\u001b[39m=\u001b[39;49mprompt, max_tokens\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m)\n\u001b[1;32m     14\u001b[0m     response_text \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mchoices[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mtext\u001b[39m.\u001b[39mstrip()\n\u001b[1;32m     16\u001b[0m     \u001b[39m# Check for a valid numeric response\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/recommender-system/lib/python3.10/site-packages/openai/api_resources/completion.py:25\u001b[0m, in \u001b[0;36mCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/recommender-system/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    155\u001b[0m         url,\n\u001b[1;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/recommender-system/lib/python3.10/site-packages/openai/api_requestor.py:226\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    206\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    207\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    214\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    215\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m    216\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[1;32m    217\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[1;32m    218\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    224\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    225\u001b[0m     )\n\u001b[0;32m--> 226\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[1;32m    227\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/recommender-system/lib/python3.10/site-packages/openai/api_requestor.py:620\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    613\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    614\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    615\u001b[0m         )\n\u001b[1;32m    616\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[1;32m    617\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    618\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    619\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 620\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[1;32m    621\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    622\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[1;32m    623\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    624\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    625\u001b[0m         ),\n\u001b[1;32m    626\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    627\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/recommender-system/lib/python3.10/site-packages/openai/api_requestor.py:683\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    681\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[1;32m    682\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[0;32m--> 683\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[1;32m    684\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[1;32m    685\u001b[0m     )\n\u001b[1;32m    686\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mInvalidRequestError\u001b[0m: This is a chat model and not supported in the v1/completions endpoint. Did you mean to use v1/chat/completions?"
     ]
    }
   ],
   "source": [
    "# openai.api_key = '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'\n",
    "# prompt = {\n",
    "#         \"messages\": [{\"role\": \"user\", \"content\": f\"Predict the rating (from 0.5 to 5.0 stars in half-star increments) that user with ID {user_id} would give to movie with ID {movie_id}?\"}]\n",
    "#     }\n",
    "class RateLimitError(Exception):\n",
    "    pass\n",
    "\n",
    "def predict_rating(user_id, movie_id):\n",
    "    # Construct a more explicit prompt\n",
    "    prompt = (f\"Based on historical data patterns of movie ratings from users, \"\n",
    "              f\"predict the rating on a scale from 1 to 5 that user {user_id} would give to movie {movie_id}. \"\n",
    "              f\"Provide a numeric answer between 1 and 5.\")\n",
    "\n",
    "    try:\n",
    "        response = openai.Completion.create(model=\"gpt-3.5-turbo\", prompt=prompt, max_tokens=5)\n",
    "        response_text = response.choices[0].text.strip()\n",
    "        \n",
    "        # Check for a valid numeric response\n",
    "        if response_text.replace('.', '', 1).isdigit():\n",
    "            predicted_rating = float(response_text)\n",
    "            if 1 <= predicted_rating <= 5:\n",
    "                return predicted_rating\n",
    "            else:\n",
    "                return None\n",
    "        else:\n",
    "            print(f\"Unexpected response for movie {movie_id}: {response_text}\")\n",
    "            return None\n",
    "    except openai.error.OpenAIError as e:\n",
    "        if \"quota\" in str(e) or \"rate limit\" in str(e):\n",
    "            raise RateLimitError(\"Rate limit exceeded.\") from e\n",
    "        raise\n",
    "\n",
    "\n",
    "def get_movie_recommendations(user_id, ratings_matrix):\n",
    "    MOVIES_TO_PREDICT = 10\n",
    "    unrated_movies = np.where(ratings_matrix[user_id] == 0)[0]\n",
    "    movies_to_predict = np.random.choice(unrated_movies, size=min(MOVIES_TO_PREDICT, len(unrated_movies)), replace=False)\n",
    "    predicted_ratings = {}\n",
    "    \n",
    "    for movie in movies_to_predict:\n",
    "        try:\n",
    "            prediction = predict_rating(user_id, movie)\n",
    "            if prediction is not None and 1 <= prediction <= 5:\n",
    "                predicted_ratings[movie] = prediction\n",
    "        except RateLimitError:\n",
    "            print(\"Rate limit exceeded. Could not predict for all movies.\")\n",
    "            break\n",
    "    \n",
    "    recommended_movies = sorted([movie for movie in predicted_ratings if predicted_ratings[movie] is not None],\n",
    "                                key=predicted_ratings.get, reverse=True)[:5]\n",
    "    \n",
    "    return recommended_movies\n",
    "\n",
    "\n",
    "# test\n",
    "ratings_matrix = np.zeros((100, 100))\n",
    "recommended_movies = get_movie_recommendations(5, ratings_matrix)\n",
    "print(recommended_movies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time for M50 dataset\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'user_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/recommender-system/lib/python3.10/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/recommender-system/lib/python3.10/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/recommender-system/lib/python3.10/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'user_id'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[39m# Testing the function on different datasets\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExecution time for M50 dataset\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 22\u001b[0m openai_metrics_M50 \u001b[39m=\u001b[39m evaluate_openai_model(M50_df)\n\u001b[1;32m     23\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe evaluation metrics for the OpenAI model on M50 are: \u001b[39m\u001b[39m{\u001b[39;00mopenai_metrics_M50\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     25\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExecution time for M100 dataset\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[30], line 9\u001b[0m, in \u001b[0;36mevaluate_openai_model\u001b[0;34m(test_df)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39m# Predict ratings and store actual ratings\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[39mfor\u001b[39;00m _, row \u001b[39min\u001b[39;00m test_df\u001b[39m.\u001b[39miterrows():\n\u001b[0;32m----> 9\u001b[0m     predicted_rating \u001b[39m=\u001b[39m predict_rating(row[\u001b[39m'\u001b[39;49m\u001b[39muser_id\u001b[39;49m\u001b[39m'\u001b[39;49m], row[\u001b[39m'\u001b[39m\u001b[39mmovie_id\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     10\u001b[0m     \u001b[39mif\u001b[39;00m predicted_rating:\n\u001b[1;32m     11\u001b[0m         y_pred\u001b[39m.\u001b[39mappend(predicted_rating)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/recommender-system/lib/python3.10/site-packages/pandas/core/series.py:981\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    978\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n\u001b[1;32m    980\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m--> 981\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_value(key)\n\u001b[1;32m    983\u001b[0m \u001b[39mif\u001b[39;00m is_hashable(key):\n\u001b[1;32m    984\u001b[0m     \u001b[39m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[1;32m    985\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    986\u001b[0m         \u001b[39m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/recommender-system/lib/python3.10/site-packages/pandas/core/series.py:1089\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1086\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[label]\n\u001b[1;32m   1088\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1089\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(label)\n\u001b[1;32m   1090\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39m_get_values_for_loc(\u001b[39mself\u001b[39m, loc, label)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/recommender-system/lib/python3.10/site-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3804\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'user_id'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "def evaluate_openai_model(test_df):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    # Predict ratings and store actual ratings\n",
    "    for _, row in test_df.iterrows():\n",
    "        predicted_rating = predict_rating(row['user_id'], row['movie_id'])\n",
    "        if predicted_rating:\n",
    "            y_pred.append(predicted_rating)\n",
    "            y_true.append(row['rating'])\n",
    "\n",
    "    # Compute metrics\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "\n",
    "    return {'MAE': mae, 'RMSE': rmse}\n",
    "\n",
    "# Testing the function on different datasets\n",
    "print(f\"Execution time for M50 dataset\")\n",
    "openai_metrics_M50 = evaluate_openai_model(M50_df)\n",
    "print(f\"The evaluation metrics for the OpenAI model on M50 are: {openai_metrics_M50}\\n\")\n",
    "\n",
    "print(f\"Execution time for M100 dataset\")\n",
    "openai_metrics_M100 = evaluate_openai_model(M100_df)\n",
    "print(f\"The evaluation metrics for the OpenAI model on M100 are: {openai_metrics_M100}\\n\")\n",
    "\n",
    "print(f\"Execution time for M400 dataset\")\n",
    "openai_metrics_M400 = evaluate_openai_model(M400_df)\n",
    "print(f\"The evaluation metrics for the OpenAI model on M400 are: {openai_metrics_M400}\\n\")\n",
    "\n",
    "# Convert the metrics to DataFrame and concatenate\n",
    "df_M50_openai = pd.DataFrame([openai_metrics_M50])\n",
    "df_M50_openai['Dataset'] = 'M50'\n",
    "\n",
    "df_M100_openai = pd.DataFrame([openai_metrics_M100])\n",
    "df_M100_openai['Dataset'] = 'M100'\n",
    "\n",
    "df_M400_openai = pd.DataFrame([openai_metrics_M400])\n",
    "df_M400_openai['Dataset'] = 'M400'\n",
    "\n",
    "metrics_df_openai = pd.concat([df_M50_openai, df_M100_openai, df_M400_openai], ignore_index=True)\n",
    "\n",
    "# Reorder the columns\n",
    "cols = metrics_df_openai.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]  # Move the last column to first\n",
    "metrics_df_openai = metrics_df_openai[cols]\n",
    "\n",
    "metrics_df_openai\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVD\n",
    "\n",
    "+ \"cold-start handling\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVD:\n",
    "    def __init__(self, num_factors, learning_rate, num_epochs, top_n=10):\n",
    "        # Initializing the instance variables with given arguments\n",
    "        self.num_factors = num_factors\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_epochs = num_epochs\n",
    "        self.top_n = top_n  # number of movies to recommend for cold start\n",
    "\n",
    "    def fit(self, user_item_ratings):\n",
    "        # Initializing the user and movie latent factors matrices with random numbers\n",
    "        self.user_factors = np.random.randn(user_item_ratings.userId.nunique(), self.num_factors)\n",
    "        self.movie_factors = np.random.randn(user_item_ratings.movieId.nunique(), self.num_factors)\n",
    "        \n",
    "        # Creating dictionaries to map user and movie IDs to their respective indices in the factor matrices\n",
    "        self.user_index = {user_id: idx for idx, user_id in enumerate(user_item_ratings.userId.unique())}\n",
    "        self.movie_index = {movie_id: idx for idx, movie_id in enumerate(user_item_ratings.movieId.unique())}\n",
    "\n",
    "        # Calculate average rating for each movie\n",
    "        self.movie_avg_rating = user_item_ratings.groupby('movieId')['rating'].mean().to_dict()\n",
    "\n",
    "        # Get top-N movies based on average rating for cold start problem\n",
    "        sorted_movies_by_avg_rating = sorted(self.movie_avg_rating.items(), key=lambda x: x[1], reverse=True)\n",
    "        self.top_n_movies = [movie_id for movie_id, _ in sorted_movies_by_avg_rating[:self.top_n]]\n",
    "\n",
    "        # Loop over epochs\n",
    "        for epoch in range(self.num_epochs):\n",
    "            # Loop over all user-item-rating rows in the DataFrame\n",
    "            for idx, row in user_item_ratings.iterrows():\n",
    "                user_id = row['userId']\n",
    "                movie_id = row['movieId']\n",
    "                rating = row['rating']\n",
    "\n",
    "                # Getting the user and movie indices for the current user-item pair\n",
    "                user_idx = self.user_index[user_id]\n",
    "                movie_idx = self.movie_index[movie_id]\n",
    "\n",
    "                # Computing the predicted rating as the dot product of the user and movie factors\n",
    "                prediction = np.dot(self.user_factors[user_idx], self.movie_factors[movie_idx])\n",
    "                # Computing the error as the difference between the actual and predicted ratings\n",
    "                error = rating - prediction\n",
    "\n",
    "                # Updating the user and movie factor vectors in the direction that minimizes the error\n",
    "                self.user_factors[user_idx] += self.learning_rate * error * self.movie_factors[movie_idx]\n",
    "                self.movie_factors[movie_idx] += self.learning_rate * error * self.user_factors[user_idx]\n",
    "\n",
    "    def predict(self, user_id, movie_id):\n",
    "        # Getting the user and movie indices for the given user-item pair\n",
    "        user_idx = self.user_index.get(user_id, -1)\n",
    "        movie_idx = self.movie_index.get(movie_id, -1)\n",
    "\n",
    "        # If the user or the movie is not present in the training data, return the movie's average rating\n",
    "        if user_idx == -1 or movie_idx == -1:\n",
    "            return self.movie_avg_rating.get(movie_id)\n",
    "\n",
    "        # Otherwise, return the predicted rating as the dot product of the user and movie factors\n",
    "        return np.dot(self.user_factors[user_idx], self.movie_factors[movie_idx])\n",
    "\n",
    "    def recommend(self, user_id):\n",
    "        # If the user is not present in the training data, return top-N movies\n",
    "        if user_id not in self.user_index:\n",
    "            return self.top_n_movies\n",
    "\n",
    "        # Otherwise, predict the rating for each movie and return the top-N movies\n",
    "        user_ratings = {movie_id: self.predict(user_id, movie_id) for movie_id in self.movie_index.keys()}\n",
    "        sorted_user_ratings = sorted(user_ratings.items(), key=lambda x: x[1], reverse=True)\n",
    "        return [movie_id for movie_id, _ in sorted_user_ratings[:self.top_n]]\n",
    "    \n",
    "\n",
    "svd = SVD(num_factors=35, learning_rate=0.01, num_epochs=10, top_n=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(df, model):\n",
    "    import time\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    # Fit the model to the data\n",
    "    model.fit(df)\n",
    "\n",
    "    # Predict ratings for the Test set and evaluate\n",
    "    test_predictions = test_df.apply(lambda row: model.predict(row['userId'], row['movieId']), axis=1)\n",
    "    \n",
    "    # Remove None values and corresponding actual ratings\n",
    "    actual_ratings = test_df['rating'][test_predictions.notna()]\n",
    "    test_predictions = test_predictions.dropna()\n",
    "\n",
    "    svd_predictions = [(uid, iid, true_r, est) for uid, iid, true_r, est in zip(test_df['userId'], test_df['movieId'], actual_ratings, test_predictions)]\n",
    "    \n",
    "    # Compute metrics for the model\n",
    "    metrics = evaluate(svd_predictions)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    print(f\"Execution time for: {end_time - start_time} seconds\")\n",
    "    \n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Execution time for M50 dataset\")\n",
    "svd_metrics_M50 = evaluate_model(M50_df, svd)\n",
    "print(f\"The evaluation metrics for the SVD model are: {svd_metrics_M50}\\n\")\n",
    "\n",
    "print(f\"Execution time for M100 dataset\")\n",
    "svd_metrics_M100 = evaluate_model(M100_df, svd)\n",
    "print(f\"The evaluation metrics for the SVD model are: {svd_metrics_M100}\\n\")\n",
    "\n",
    "print(f\"Execution time for M400 dataset\")\n",
    "svd_metrics_M400 = evaluate_model(M400_df, svd)\n",
    "print(f\"The evaluation metrics for the SVD model are: {svd_metrics_M400}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# Convert the metrics to DataFrame\n",
    "df_M50 = pd.DataFrame([svd_metrics_M50])\n",
    "df_M50['Dataset'] = 'M50'\n",
    "\n",
    "df_M100 = pd.DataFrame([svd_metrics_M100])\n",
    "df_M100['Dataset'] = 'M100'\n",
    "\n",
    "df_M400 = pd.DataFrame([svd_metrics_M400])\n",
    "df_M400['Dataset'] = 'M400'\n",
    "\n",
    "# Concatenate the DataFrames\n",
    "metrics_df = pd.concat([df_M50, df_M100, df_M400], ignore_index=True)\n",
    "\n",
    "# Reorder the columns\n",
    "cols = metrics_df.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]  # Move the last column to first\n",
    "metrics_df = metrics_df[cols]\n",
    "\n",
    "metrics_df\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN based CF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN_CF:\n",
    "    def __init__(self, n_users, n_items, k=3, gamma=0, delta=25, epsilon=1e-9):\n",
    "        self.n_users = n_users\n",
    "        self.n_items = n_items\n",
    "        self.k = k\n",
    "        self.gamma = gamma\n",
    "        self.delta = delta\n",
    "        self.epsilon = epsilon\n",
    "        self.user_corrs = np.zeros((n_users, n_users))\n",
    "        self.item_corrs = np.zeros((n_items, n_items))\n",
    "\n",
    "    def fit(self, user_item_matrix):\n",
    "        # user-based\n",
    "        for i in range(self.n_users):\n",
    "            for j in range(self.n_users):\n",
    "                self.user_corrs[i, j] = self.pearson_corr(user_item_matrix[i], user_item_matrix[j])\n",
    "\n",
    "        # item-based\n",
    "        for i in range(self.n_items):\n",
    "            for j in range(self.n_items):\n",
    "                self.item_corrs[i, j] = self.pearson_corr(user_item_matrix[:, i], user_item_matrix[:, j])\n",
    "\n",
    "    def predict(self, user_item_matrix, mode='user'):\n",
    "        predictions = np.zeros((self.n_users, self.n_items))\n",
    "        if mode == 'user':\n",
    "            for i in range(self.n_users):\n",
    "                for j in range(self.n_items):\n",
    "                    if user_item_matrix[i, j] > 0:\n",
    "                        sim_users = np.argsort(self.user_corrs[i])[-(self.k + 1):-1]\n",
    "                        predictions[i, j] = self.predict_rating(user_item_matrix, sim_users, i, j, mode)\n",
    "        elif mode == 'item':\n",
    "            for i in range(self.n_users):\n",
    "                for j in range(self.n_items):\n",
    "                    if user_item_matrix[i, j] > 0:\n",
    "                        sim_items = np.argsort(self.item_corrs[j])[-(self.k + 1):-1]\n",
    "                        predictions[i, j] = self.predict_rating(user_item_matrix, sim_items, i, j, mode)\n",
    "        return predictions\n",
    "\n",
    "    def pearson_corr(self, vec_i, vec_j):\n",
    "        mask_i = vec_i > 0\n",
    "        mask_j = vec_j > 0\n",
    "        corrated_index = np.intersect1d(np.where(mask_i), np.where(mask_j))\n",
    "        if len(corrated_index) == 0:\n",
    "            return 0\n",
    "        mean_i = np.mean(vec_i[corrated_index])\n",
    "        mean_j = np.mean(vec_j[corrated_index])\n",
    "        sub_i = vec_i[corrated_index] - mean_i\n",
    "        sub_j = vec_j[corrated_index] - mean_j\n",
    "        return np.sum(sub_i * sub_j) / (np.sqrt(np.sum(np.square(sub_i))) * np.sqrt(np.sum(np.square(sub_j))) + self.epsilon)\n",
    "\n",
    "    def predict_rating(self, user_item_matrix, sim_indices, i, j, mode):\n",
    "        if mode == 'user':\n",
    "            sim_ratings = user_item_matrix[sim_indices, j]\n",
    "            sim_means = np.array([np.mean(user_item_matrix[k][user_item_matrix[k]>0]) for k in sim_indices])\n",
    "            sim_vals = self.user_corrs[i][sim_indices]\n",
    "        elif mode == 'item':\n",
    "            sim_ratings = user_item_matrix[i, sim_indices]\n",
    "            sim_means = np.array([np.mean(user_item_matrix[:, k][user_item_matrix[:, k]>0]) for k in sim_indices])\n",
    "            sim_vals = self.item_corrs[j][sim_indices]\n",
    "        if np.sum(sim_vals) == 0:\n",
    "            return np.mean(sim_ratings)\n",
    "        else:\n",
    "            return np.mean(sim_ratings) + np.sum(sim_vals * (sim_ratings - sim_means)) / np.sum(sim_vals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_matrix(df, nrows, ncols):\n",
    "    matrix = np.zeros((nrows, ncols))\n",
    "    for row in df.itertuples():\n",
    "        matrix[row.userId, row.movieId] = row.rating\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Create mappings for userIds and movieIds to contiguous indices\n",
    "user_mapping = {user_id: i for i, user_id in enumerate(M100_df['userId'].unique())}\n",
    "movie_mapping = {movie_id: i for i, movie_id in enumerate(M100_df['movieId'].unique())}\n",
    "\n",
    "# Create reverse mappings for later use\n",
    "reverse_user_mapping = {i: user_id for user_id, i in user_mapping.items()}\n",
    "reverse_movie_mapping = {i: movie_id for movie_id, i in movie_mapping.items()}\n",
    "\n",
    "# Apply the mappings to the dataframes\n",
    "M100_df['userId'] = M100_df['userId'].map(user_mapping)\n",
    "M100_df['movieId'] = M100_df['movieId'].map(movie_mapping)\n",
    "\n",
    "test_df['userId'] = test_df['userId'].map(user_mapping)\n",
    "test_df['movieId'] = test_df['movieId'].map(movie_mapping)\n",
    "\n",
    "# Drop rows with NaN userId or movieId\n",
    "test_df.dropna(subset=['userId', 'movieId'], inplace=True)\n",
    "\n",
    "# Convert userId and movieId to integer\n",
    "test_df['userId'] = test_df['userId'].astype(int)\n",
    "test_df['movieId'] = test_df['movieId'].astype(int)\n",
    "\n",
    "\n",
    "n_users = M100_df['userId'].nunique()\n",
    "n_items = M100_df['movieId'].nunique()\n",
    "\n",
    "train_matrix = df_to_matrix(M100_df, n_users, n_items)\n",
    "test_matrix = df_to_matrix(test_df, n_users, n_items)\n",
    "\n",
    "knn_cf = KNN_CF(n_users, n_items, k=3)\n",
    "\n",
    "# Fit the model to the M100 data\n",
    "knn_cf.fit(train_matrix)\n",
    "\n",
    "# Predict ratings for the Test set and evaluate\n",
    "user_based_predictions = knn_cf.predict(test_matrix, mode='user')\n",
    "test_predictions = user_based_predictions[test_matrix.nonzero()]\n",
    "actual_ratings = test_matrix[test_matrix.nonzero()]\n",
    "\n",
    "knn_predictions = [(uid, iid, true_r, est) for uid, iid, true_r, est in zip(test_df['userId'], test_df['movieId'], actual_ratings, test_predictions)]\n",
    "# Compute metrics for the KNN model\n",
    "knn_metrics_M100 = evaluate(knn_predictions)\n",
    "\n",
    "# create a dataframe for the results \n",
    "knn_results = pd.DataFrame(knn_metrics_M100, index=[0])\n",
    "# add first column of the dataframe as the dataset name\n",
    "knn_results.insert(0, 'dataset', 'M100')\n",
    "knn_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "# Create mappings for userIds and movieIds to contiguous indices\n",
    "user_mapping = {user_id: i for i, user_id in enumerate(M50_df['userId'].unique())}\n",
    "movie_mapping = {movie_id: i for i, movie_id in enumerate(M50_df['movieId'].unique())}\n",
    "\n",
    "# Create reverse mappings for later use\n",
    "reverse_user_mapping = {i: user_id for user_id, i in user_mapping.items()}\n",
    "reverse_movie_mapping = {i: movie_id for movie_id, i in movie_mapping.items()}\n",
    "\n",
    "# Apply the mappings to the dataframes\n",
    "M50_df['userId'] = M50_df['userId'].map(user_mapping)\n",
    "M50_df['movieId'] = M50_df['movieId'].map(movie_mapping)\n",
    "\n",
    "test_df['userId'] = test_df['userId'].map(user_mapping)\n",
    "test_df['movieId'] = test_df['movieId'].map(movie_mapping)\n",
    "\n",
    "# Drop rows with NaN userId or movieId\n",
    "test_df.dropna(subset=['userId', 'movieId'], inplace=True)\n",
    "\n",
    "# Convert userId and movieId to integer\n",
    "test_df['userId'] = test_df['userId'].astype(int)\n",
    "test_df['movieId'] = test_df['movieId'].astype(int)\n",
    "\n",
    "\n",
    "n_users = M50_df['userId'].nunique()\n",
    "n_items = M50_df['movieId'].nunique()\n",
    "\n",
    "train_matrix = df_to_matrix(M50_df, n_users, n_items)\n",
    "test_matrix = df_to_matrix(test_df, n_users, n_items)\n",
    "\n",
    "knn_cf = KNN_CF(n_users, n_items, k=3)\n",
    "\n",
    "# Fit the model to the M100 data\n",
    "knn_cf.fit(train_matrix)\n",
    "\n",
    "# Predict ratings for the Test set and evaluate\n",
    "user_based_predictions = knn_cf.predict(test_matrix, mode='user')\n",
    "test_predictions = user_based_predictions[test_matrix.nonzero()]\n",
    "actual_ratings = test_matrix[test_matrix.nonzero()]\n",
    "\n",
    "knn_predictions = [(uid, iid, true_r, est) for uid, iid, true_r, est in zip(test_df['userId'], test_df['movieId'], actual_ratings, test_predictions)]\n",
    "# Compute metrics for the KNN model\n",
    "knn_results_M50 = evaluate(knn_predictions)\n",
    "\n",
    "# create a dataframe to concatenate the results\n",
    "knn_results_M50 = pd.DataFrame(knn_results_M50, index=[0])\n",
    "# add first column of the dataframe as the dataset name\n",
    "knn_results_M50.insert(0, 'dataset', 'M50')\n",
    "knn_results_M50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    if len(y_true) == 0:\n",
    "        raise ValueError(\"y_true is empty.\")\n",
    "    error = 0\n",
    "    for true, pred in zip(y_true, y_pred):\n",
    "        error += (true - pred) ** 2\n",
    "    error /= len(y_true)\n",
    "    return sqrt(error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "# Create mappings for userIds and movieIds to contiguous indices\n",
    "user_mapping = {user_id: i for i, user_id in enumerate(M400_df['userId'].unique())}\n",
    "movie_mapping = {movie_id: i for i, movie_id in enumerate(M400_df['movieId'].unique())}\n",
    "\n",
    "# Create reverse mappings for later use\n",
    "reverse_user_mapping = {i: user_id for user_id, i in user_mapping.items()}\n",
    "reverse_movie_mapping = {i: movie_id for movie_id, i in movie_mapping.items()}\n",
    "\n",
    "# Apply the mappings to the dataframes\n",
    "M400_df['userId'] = M400_df['userId'].map(user_mapping)\n",
    "M400_df['movieId'] = M400_df['movieId'].map(movie_mapping)\n",
    "\n",
    "test_df['userId'] = test_df['userId'].map(user_mapping)\n",
    "test_df['movieId'] = test_df['movieId'].map(movie_mapping)\n",
    "\n",
    "# Drop rows with NaN userId or movieId\n",
    "test_df.dropna(subset=['userId', 'movieId'], inplace=True)\n",
    "\n",
    "# Convert userId and movieId to integer\n",
    "test_df['userId'] = test_df['userId'].astype(int)\n",
    "test_df['movieId'] = test_df['movieId'].astype(int)\n",
    "\n",
    "\n",
    "n_users = M400_df['userId'].nunique()\n",
    "n_items = M400_df['movieId'].nunique()\n",
    "\n",
    "train_matrix = df_to_matrix(M400_df, n_users, n_items)\n",
    "test_matrix = df_to_matrix(test_df, n_users, n_items)\n",
    "\n",
    "knn_cf = KNN_CF(n_users, n_items, k=3)\n",
    "\n",
    "# Fit the model to the M100 data\n",
    "knn_cf.fit(train_matrix)\n",
    "\n",
    "# Predict ratings for the Test set and evaluate\n",
    "user_based_predictions = knn_cf.predict(test_matrix, mode='user')\n",
    "test_predictions = user_based_predictions[test_matrix.nonzero()]\n",
    "actual_ratings = test_matrix[test_matrix.nonzero()]\n",
    "\n",
    "knn_predictions = [(uid, iid, true_r, est) for uid, iid, true_r, est in zip(test_df['userId'], test_df['movieId'], actual_ratings, test_predictions)]\n",
    "# Compute metrics for the KNN model\n",
    "knn_metrics_M100 = evaluate(knn_predictions)\n",
    "\n",
    "# create a dataframe to concatenate the results\n",
    "knn_results_M400 = pd.DataFrame(knn_metrics_M100, index=[0])\n",
    "# add first column of the dataframe as the dataset name\n",
    "knn_results_M400.insert(0, 'dataset', 'M400')\n",
    "knn_results_M400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
