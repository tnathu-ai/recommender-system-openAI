{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import openai\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import sys\n",
    "import re\n",
    "import time\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "\n",
    "# Add the path to the constants file to the system path\n",
    "sys.path.append('../../')\n",
    "from constants import *\n",
    "from evaluation_utils import *\n",
    "from ChatCompletion_OpenAI_API import *\n",
    "\n",
    "# OpenAI API Key\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "# Get the current directory of the notebook\n",
    "current_dir = os.path.dirname(os.path.abspath(\"../../data/amazon-beauty/rating_prediction.ipynb\"))\n",
    "print(f\"current directory: {current_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RMSE & MAE evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "actual_ratings = [4, 4]  # Ground truth ratings\n",
    "predicted_ratings = [3, 5]  # Predicted ratings\n",
    "rmse, mae = calculate_rmse_and_mae(actual_ratings, predicted_ratings)\n",
    "print(\"RMSE: \", rmse)\n",
    "print(\"MAE: \", mae)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the path to data file\n",
    "data_path = os.path.join(current_dir, 'merged_data.csv')\n",
    "print(f'data path: {data_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "data = pd.read_csv(data_path)\n",
    "# get necessary columns\n",
    "data = data[['title', 'rating', 'reviewText', 'reviewerID']]\n",
    "# get sample data of NUM_SAMPLES rows\n",
    "data.info()\n",
    "data.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero-shot (OpenAI API)\n",
    "\n",
    "+ We used the ``.drop_duplicates()`` method to get unique pairs of \"title\" and \"reviewText\". The predictions are then based on both the title and the corresponding review text for each unique pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "predict_ratings_zero_shot_and_save(data,\n",
    "                                       columns_for_training=['title', 'reviewText'],\n",
    "                                       columns_for_prediction=['title'],\n",
    "                                       pause_every_n_users=PAUSE_EVERY_N_USERS,\n",
    "                                       sleep_time=SLEEP_TIME,\n",
    "                                       save_path='../../data/amazon-beauty/reviewText_small_predictions_zero_shot.csv')\n",
    "# read csv file\n",
    "merged_data_with_predictions = pd.read_csv('../../data/amazon-beauty/reviewText_small_predictions_zero_shot.csv')\n",
    "merged_data_with_predictions.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the rating prediction model\n",
    "\n",
    "product_titles = merged_data_with_predictions['title']\n",
    "actual_ratings = merged_data_with_predictions['rating']\n",
    "predicted_ratings = merged_data_with_predictions['predicted_rating']\n",
    "\n",
    "# Remove None predictions if any\n",
    "actual_ratings_filtered, predicted_ratings_filtered = zip(*[(actual, predicted) for actual, predicted in zip(actual_ratings, predicted_ratings) if predicted is not None])\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(actual_ratings_filtered, predicted_ratings_filtered))\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse}')\n",
    "\n",
    "# Calculate MAE\n",
    "mae = mean_absolute_error(actual_ratings_filtered, predicted_ratings_filtered)\n",
    "print(f'Mean Absolute Error (MAE): {mae}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Few-shot (OpenAI API)\n",
    "\n",
    "\n",
    "+ For each user, we'll use 4 of their ratings as training data to predict ratings for the rest of their products. Finally, we'll evaluate the predictions against the actual ratings to calculate the overall RMSE and MAE.\n",
    "\n",
    "+ The rating_history_str now includes both the title and the review text for each of the training data rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "predict_ratings_few_shot_and_save(data,\n",
    "                                      columns_for_training=['title', 'reviewText'],\n",
    "                                      columns_for_prediction=['title'],\n",
    "                                      obs_per_user=None,\n",
    "                                      pause_every_n_users=PAUSE_EVERY_N_USERS,\n",
    "                                      sleep_time=SLEEP_TIME,\n",
    "                                      save_path='../../data/amazon-beauty/reviewText_small_predictions_few_shot.csv.csv')\n",
    "                                      \n",
    "# load data from ../../data/amazon-beauty/small_predictions_few_shot.csv file\n",
    "small_predictions_few_shot = pd.read_csv('../../data/amazon-beauty/reviewText_small_predictions_few_shot.csv')\n",
    "small_predictions_few_shot.head(NUM_EXAMPLES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert few_shot_predicted_rating column to list\n",
    "predicted_ratings = small_predictions_few_shot['few_shot_predicted_rating'].tolist()\n",
    "# convert actual_rating column to list\n",
    "actual_ratings = small_predictions_few_shot['actual_rating'].tolist()\n",
    "filtered_list = [(actual, predicted) for actual, predicted in zip(actual_ratings, predicted_ratings) if predicted is not None]\n",
    "\n",
    "if not filtered_list:\n",
    "    print(\"No valid predictions available for evaluation.\")\n",
    "else:\n",
    "    actual_ratings_filtered, predicted_ratings_filtered = zip(*filtered_list)\n",
    "    # Evaluate the model's performance\n",
    "    rmse = np.sqrt(mean_squared_error(actual_ratings_filtered, predicted_ratings_filtered))\n",
    "    print(f'Root Mean Squared Error (RMSE): {rmse}')\n",
    "\n",
    "    mae = mean_absolute_error(actual_ratings_filtered, predicted_ratings_filtered)\n",
    "    print(f'Mean Absolute Error (MAE): {mae}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 observation per reviewer - Few-shot OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "predict_ratings_few_shot_and_save(data,\n",
    "                                      columns_for_training=['title', 'reviewText'],\n",
    "                                      columns_for_prediction=['title'],\n",
    "                                      obs_per_user=1,\n",
    "                                      pause_every_n_users=PAUSE_EVERY_N_USERS,\n",
    "                                      sleep_time=SLEEP_TIME,\n",
    "                                      save_path='../../data/amazon-beauty/reviewText_small_1_test_predictions_few_shot.csv')\n",
    "\n",
    "small_predictions_few_shot = pd.read_csv('../../data/amazon-beauty/reviewText_small_1_test_predictions_few_shot.csv')\n",
    "small_predictions_few_shot.head(NUM_EXAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# convert few_shot_predicted_rating column to list\n",
    "predicted_ratings = small_predictions_few_shot['few_shot_predicted_rating'].tolist()\n",
    "# convert actual_rating column to list\n",
    "actual_ratings = small_predictions_few_shot['actual_rating'].tolist()\n",
    "filtered_list = [(actual, predicted) for actual, predicted in zip(actual_ratings, predicted_ratings) if predicted is not None]\n",
    "\n",
    "if not filtered_list:\n",
    "    print(\"No valid predictions available for evaluation.\")\n",
    "else:\n",
    "    actual_ratings_filtered, predicted_ratings_filtered = zip(*filtered_list)\n",
    "    # Evaluate the model's performance\n",
    "    rmse = np.sqrt(mean_squared_error(actual_ratings_filtered, predicted_ratings_filtered))\n",
    "    print(f'Root Mean Squared Error (RMSE): {rmse}')\n",
    "\n",
    "    mae = mean_absolute_error(actual_ratings_filtered, predicted_ratings_filtered)\n",
    "    print(f'Mean Absolute Error (MAE): {mae}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limitations:\n",
    "\n",
    "The model might not fully understand the nuanced relationships between products based on titles alone. Additional context or features might be needed for more accurate predictions.\n",
    "This approach might be computationally expensive and slower than traditional matrix factorization or deep learning-based recommendation models, especially for a small number of users.\n",
    "\n",
    "# References\n",
    "\n",
    "+ https://platform.openai.com/docs/api-reference/authentication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Advanced_Programming_for_Data_Science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
