{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current directory: /Users/tnathu-ai/VSCode/recommender-system/recommender-system-openAI/rec-sys/data/amazon-beauty\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import openai\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import sys\n",
    "import re\n",
    "\n",
    "# Add the path to the constants file to the system path\n",
    "sys.path.append('../../')\n",
    "from constants import RANDOM_STATE, OPENAI_API_KEY\n",
    "\n",
    "# OpenAI API Key\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "# OpenAI GPT Model parameters\n",
    "GPT_MODEL_NAME = \"gpt-3.5-turbo\"\n",
    "TEMPERATURE = 0\n",
    "\n",
    "# Get the current directory of the notebook\n",
    "current_dir = os.path.dirname(os.path.abspath(\"../../data/amazon-beauty/rating_prediction.ipynb\"))\n",
    "print(f\"current directory: {current_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RMSE & MAE evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  1.0\n",
      "MAE:  1.0\n"
     ]
    }
   ],
   "source": [
    "# calculate RMSE and MAE manually\n",
    "def calculate_rmse_and_mae(actual_ratings, predicted_ratings):\n",
    "    differences = [actual - predicted for actual, predicted in zip(actual_ratings, predicted_ratings)]\n",
    "    \n",
    "    # RMSE\n",
    "    squared_differences = [diff ** 2 for diff in differences]\n",
    "    mean_squared_difference = sum(squared_differences) / len(squared_differences)\n",
    "    rmse = mean_squared_difference ** 0.5\n",
    "\n",
    "    # MAE\n",
    "    absolute_differences = [abs(diff) for diff in differences]\n",
    "    mae = sum(absolute_differences) / len(absolute_differences)\n",
    "\n",
    "    return rmse, mae\n",
    "\n",
    "# Test\n",
    "actual_ratings = [4, 4]  # Ground truth ratings\n",
    "predicted_ratings = [3, 5]  # Predicted ratings\n",
    "rmse, mae = calculate_rmse_and_mae(actual_ratings, predicted_ratings)\n",
    "print(\"RMSE: \", rmse)\n",
    "print(\"MAE: \", mae)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data path: /Users/tnathu-ai/VSCode/recommender-system/recommender-system-openAI/rec-sys/data/amazon-beauty/merged_data.csv\n"
     ]
    }
   ],
   "source": [
    "# Construct the path to data file\n",
    "data_path = os.path.join(current_dir, 'merged_data.csv')\n",
    "print(f'data path: {data_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 34 entries, 0 to 33\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   rating      34 non-null     float64\n",
      " 1   reviewerID  34 non-null     object \n",
      " 2   asin        34 non-null     object \n",
      " 3   reviewText  34 non-null     object \n",
      " 4   summary     34 non-null     object \n",
      " 5   title       34 non-null     object \n",
      "dtypes: float64(1), object(5)\n",
      "memory usage: 1.7+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>rating</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewerID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reach Dentotape Waxed Dental Floss with Extra ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>best floss i've used. does not break as easily...</td>\n",
       "      <td>ANV9L0JU6BNL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Reach Dentotape Waxed Dental Floss with Extra ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>best floss i've used. does not break as easily...</td>\n",
       "      <td>ANV9L0JU6BNL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Citre Shine Moisture Burst Shampoo - 16 fl oz</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Doesnt smell</td>\n",
       "      <td>A2TU781PWGS09X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  rating  \\\n",
       "0  Reach Dentotape Waxed Dental Floss with Extra ...     5.0   \n",
       "1  Reach Dentotape Waxed Dental Floss with Extra ...     5.0   \n",
       "2      Citre Shine Moisture Burst Shampoo - 16 fl oz     2.0   \n",
       "\n",
       "                                          reviewText      reviewerID  \n",
       "0  best floss i've used. does not break as easily...    ANV9L0JU6BNL  \n",
       "1  best floss i've used. does not break as easily...    ANV9L0JU6BNL  \n",
       "2                                       Doesnt smell  A2TU781PWGS09X  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data\n",
    "amazon_data = pd.read_csv(data_path)\n",
    "# get sample data of NUM_SAMPLES rows\n",
    "amazon_data.info()\n",
    "# get neccessary columns\n",
    "amazon_data = amazon_data[['title', 'rating', 'reviewText', 'reviewerID']]\n",
    "amazon_data.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple statistical methods (mean calculations) \n",
    "\n",
    "+ **Zero-Shot Prediction (zero_shot_predict function):**\n",
    "This method calculates the average rating for a given product title from the `amazon_data` DataFrame.\n",
    "It does not take into account any user-specific information and predicts the rating based on the average rating of the product across all users.\n",
    "\n",
    "+ **Few-Shot Prediction (few_shot_predict function):**\n",
    "This method calculates the average rating for a given product title by a specific user from the `amazon_data` DataFrame.\n",
    "It predicts the rating based on the average rating of the product by that specific user, thus incorporating user-specific information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-Shot RMSE: 0.8911327886790068, MAE: 0.5294117647058824\n",
      "Few-Shot RMSE: 0.0, MAE: 0.0\n",
      "CPU times: user 24.1 ms, sys: 3.46 ms, total: 27.5 ms\n",
      "Wall time: 24.9 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>rating</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>predicted_rating_zero_shot</th>\n",
       "      <th>predicted_rating_few_shot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reach Dentotape Waxed Dental Floss with Extra ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>best floss i've used. does not break as easily...</td>\n",
       "      <td>ANV9L0JU6BNL</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Reach Dentotape Waxed Dental Floss with Extra ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>best floss i've used. does not break as easily...</td>\n",
       "      <td>ANV9L0JU6BNL</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Citre Shine Moisture Burst Shampoo - 16 fl oz</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Doesnt smell</td>\n",
       "      <td>A2TU781PWGS09X</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  rating  \\\n",
       "0  Reach Dentotape Waxed Dental Floss with Extra ...     5.0   \n",
       "1  Reach Dentotape Waxed Dental Floss with Extra ...     5.0   \n",
       "2      Citre Shine Moisture Burst Shampoo - 16 fl oz     2.0   \n",
       "\n",
       "                                          reviewText      reviewerID  \\\n",
       "0  best floss i've used. does not break as easily...    ANV9L0JU6BNL   \n",
       "1  best floss i've used. does not break as easily...    ANV9L0JU6BNL   \n",
       "2                                       Doesnt smell  A2TU781PWGS09X   \n",
       "\n",
       "   predicted_rating_zero_shot  predicted_rating_few_shot  \n",
       "0                         5.0                        5.0  \n",
       "1                         5.0                        5.0  \n",
       "2                         3.5                        2.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "def zero_shot_predict(product_title):\n",
    "    # Get the average rating for the given title\n",
    "    avg_rating = amazon_data.loc[amazon_data['title'] == product_title, 'rating'].mean()\n",
    "    return avg_rating\n",
    "\n",
    "def few_shot_predict(product_title, user_id):\n",
    "    # Get the average rating for the given title by the specific user\n",
    "    avg_rating = amazon_data.loc[(amazon_data['title'] == product_title) & (amazon_data['reviewerID'] == user_id), 'rating'].mean()\n",
    "    return avg_rating\n",
    "\n",
    "# Applying predictions\n",
    "amazon_data['predicted_rating_zero_shot'] = amazon_data['title'].apply(zero_shot_predict)\n",
    "amazon_data['predicted_rating_few_shot'] = [few_shot_predict(row['title'], row['reviewerID']) for _, row in amazon_data.iterrows()]\n",
    "\n",
    "# Calculating RMSE and MAE for Zero-Shot\n",
    "rmse_zero_shot = mean_squared_error(amazon_data['rating'], amazon_data['predicted_rating_zero_shot'], squared=False)\n",
    "mae_zero_shot = mean_absolute_error(amazon_data['rating'], amazon_data['predicted_rating_zero_shot'])\n",
    "\n",
    "# Calculating RMSE and MAE for Few-Shot\n",
    "rmse_few_shot = mean_squared_error(amazon_data['rating'], amazon_data['predicted_rating_few_shot'], squared=False)\n",
    "mae_few_shot = mean_absolute_error(amazon_data['rating'], amazon_data['predicted_rating_few_shot'])\n",
    "\n",
    "print(f\"Zero-Shot RMSE: {rmse_zero_shot}, MAE: {mae_zero_shot}\")\n",
    "print(f\"Few-Shot RMSE: {rmse_few_shot}, MAE: {mae_few_shot}\")\n",
    "\n",
    "amazon_data.head(3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero-shot (GPT-3.5-turbo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = amazon_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import openai\n",
    "\n",
    "def predict_rating(title, model=GPT_MODEL_NAME, temperature=TEMPERATURE):\n",
    "    prompt = f\"How will users rate this product title: '{title}'? (1 being lowest and 5 being highest) Attention! Just give me back the exact whole number as a result, and you don't need a lot of text.\"\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        temperature=temperature,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are an Amazon Beauty products critic.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    rating_text = response.choices[0].message['content'].strip()\n",
    "    try:\n",
    "        # Extract the first numerical value from the response\n",
    "        rating = float(re.search(r'\\d+', rating_text).group())  # Only capture whole numbers\n",
    "        if not (1 <= rating <= 5):\n",
    "            raise ValueError(\"Rating out of bounds\")\n",
    "    except (ValueError, AttributeError):\n",
    "        print(f\"Unexpected response for '{product_title}': {rating_text}\")\n",
    "        rating = 0  # Set default value to 0 for unexpected responses\n",
    "\n",
    "    return rating\n",
    "\n",
    "\n",
    "# Iterate through the dataset and predict ratings\n",
    "predicted_ratings = []\n",
    "for title in data['title'].unique():\n",
    "    predicted_rating = predict_rating(title)\n",
    "    print(f\"Predicted rating for {title}: {predicted_rating}\")\n",
    "    predicted_ratings.append(predicted_rating)\n",
    "\n",
    "# Create a DataFrame with titles and predicted ratings\n",
    "predicted_ratings_df = pd.DataFrame({\n",
    "    'title': data['title'].unique(),\n",
    "    'zero_shot_predicted_rating': predicted_ratings\n",
    "})\n",
    "\n",
    "# Merge the predicted ratings with the original data\n",
    "merged_data_with_predictions = pd.merge(data, predicted_ratings_df, on='title')\n",
    "\n",
    "# Save the merged data with predictions to a new CSV file\n",
    "merged_data_with_predictions.to_csv('../../data/amazon-beauty/predictions_zero_shot.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the rating prediction model\n",
    "\n",
    "product_titles = merged_data_with_predictions['title']\n",
    "actual_ratings = merged_data_with_predictions['rating']\n",
    "\n",
    "# Remove None predictions if any\n",
    "actual_ratings_filtered, predicted_ratings_filtered = zip(*[(actual, predicted) for actual, predicted in zip(actual_ratings, predicted_ratings) if predicted is not None])\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(actual_ratings_filtered, predicted_ratings_filtered))\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse}')\n",
    "\n",
    "# Calculate MAE\n",
    "mae = mean_absolute_error(actual_ratings_filtered, predicted_ratings_filtered)\n",
    "print(f'Mean Absolute Error (MAE): {mae}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate RMSE and MAE manually using calculate_rmse_and_mae function\n",
    "rmse, mae = calculate_rmse_and_mae(\n",
    "    actual_ratings_filtered, predicted_ratings_filtered\n",
    ")\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"MAE: {mae}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Few-shot\n",
    "\n",
    "\n",
    "For each user, we'll use 4 of their ratings as training data to predict ratings for the rest of their products. Finally, we'll evaluate the predictions against the actual ratings to calculate the overall RMSE and MAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def predict_rating_few_shot(product_title, rating_history, model=GPT_MODEL_NAME, temperature=TEMPERATURE):\n",
    "    \"\"\"\n",
    "    Predict the rating of a product based on user's past rating history using the GPT model.\n",
    "    \n",
    "    Parameters:\n",
    "    - product_title (str): The title of the product for which rating needs to be predicted.\n",
    "    - rating_history (str): A string representation of user's past product ratings.\n",
    "    - model (str): The GPT model version to use.\n",
    "    - temperature (float): Sampling temperature for the model response. \n",
    "    \n",
    "    Returns:\n",
    "    - float: Predicted rating for the product or None if the response is not valid.\n",
    "    \"\"\"\n",
    "    # Construct the prompt to ask the model\n",
    "    prompt = (f\"Here is user rating history: {rating_history}; \"\n",
    "              f\"Based on the above rating history, please predict user's rating for the product: '{product_title}', \"\n",
    "              \"(1 being lowest and 5 being highest.). \"\n",
    "              \"Attention! Just give me back the exact whole number as a result, and you don't need a lot of text.\")\n",
    "    \n",
    "    # Make the API call\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        temperature=temperature,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a product critic.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    rating_text = response.choices[0].message['content'].strip()\n",
    "    try:\n",
    "        # Extract the first numerical value from the response\n",
    "        rating = float(re.search(r'\\d+?', rating_text).group())\n",
    "        if not (0.5 <= rating <= 5.0):\n",
    "            raise ValueError(\"Rating out of bounds\")\n",
    "    except (ValueError, AttributeError):\n",
    "        print(f\"Unexpected response for '{product_title}': {rating_text}\")\n",
    "        rating = 0  # Set default value to 0 for unexpected responses\n",
    "\n",
    "    return rating\n",
    "\n",
    "predicted_ratings = []\n",
    "actual_ratings = []\n",
    "\n",
    "# For each user in the dataset\n",
    "for reviewerID in data['reviewerID'].unique():\n",
    "    user_data = data[data['reviewerID'] == reviewerID]\n",
    "    \n",
    "    # Check if the user has at least 5 ratings\n",
    "    if len(user_data) >= 5:\n",
    "        train_data = user_data.sample(4, random_state=RANDOM_STATE)\n",
    "        test_data = user_data.drop(train_data.index)\n",
    "\n",
    "        # For each product in the testing set, use the training data to predict a rating\n",
    "        for _, test_row in test_data.iterrows():\n",
    "            rating_history_str = ', '.join([f\"{row['title']} ({row['rating']} stars)\" for _, row in train_data.iterrows()])\n",
    "            predicted_rating = predict_rating_few_shot(test_row['title'], rating_history_str)\n",
    "            \n",
    "            predicted_ratings.append(predicted_rating)\n",
    "            actual_ratings.append(test_row['rating'])\n",
    "\n",
    "# Save the predicted ratings to a new CSV file\n",
    "predicted_ratings_df = pd.DataFrame({\n",
    "    'few_shot_predicted_rating': predicted_ratings,\n",
    "    'actual_rating': actual_ratings\n",
    "})\n",
    "# predicted_ratings_df.to_csv('../../data/amazon-beauty/predictions_few_shot.csv', index=False)\n",
    "\n",
    "predicted_ratings_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_list = [(actual, predicted) for actual, predicted in zip(actual_ratings, predicted_ratings) if predicted is not None]\n",
    "\n",
    "if not filtered_list:\n",
    "    print(\"No valid predictions available for evaluation.\")\n",
    "else:\n",
    "    actual_ratings_filtered, predicted_ratings_filtered = zip(*filtered_list)\n",
    "    # Evaluate the model's performance\n",
    "    rmse = np.sqrt(mean_squared_error(actual_ratings_filtered, predicted_ratings_filtered))\n",
    "    print(f'Root Mean Squared Error (RMSE): {rmse}')\n",
    "\n",
    "    mae = mean_absolute_error(actual_ratings_filtered, predicted_ratings_filtered)\n",
    "    print(f'Mean Absolute Error (MAE): {mae}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demonstrate the output of 4 random historical ratings\n",
    "predicted_ratings = []\n",
    "for title in data['title'].unique():\n",
    "    # Randomly sample 4 rows from the entire dataset\n",
    "    rating_history_samples = data.sample(4)\n",
    "    rating_history_str = ', '.join([f\"{row['title']} ({row['rating']} stars)\" for _, row in rating_history_samples.iterrows()])\n",
    "\n",
    "rating_history_str\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "+ https://platform.openai.com/docs/api-reference/authentication"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Advanced_Programming_for_Data_Science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
