{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rec-sys directory: /Users/tnathu-ai/VSCode/recommender-system/recommender-system-openAI/rec-sys/notebook\n",
      "Data directory: /Users/tnathu-ai/VSCode/recommender-system/recommender-system-openAI/rec-sys/notebook/../data\n",
      "Data path: /Users/tnathu-ai/VSCode/recommender-system/recommender-system-openAI/rec-sys/notebook/../data/ml-1m/merged_data.dat\n",
      "Data path: /Users/tnathu-ai/VSCode/recommender-system/recommender-system-openAI/rec-sys/notebook/../data/ml-1m/merged_data.dat\n",
      "Data path: /Users/tnathu-ai/VSCode/recommender-system/recommender-system-openAI/rec-sys/notebook/../data/ml-1m/merged_data.dat\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import openai\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.sparse import csr_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import openai\n",
    "# Add the path to the constants file to the system path\n",
    "sys.path.append('../../../')\n",
    "from constants import *\n",
    "from evaluation_utils import *\n",
    "from path_utils import *\n",
    "from ChatCompletion_OpenAI_API import *\n",
    "from CF_utils import *\n",
    "\n",
    "# OpenAI API Key\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "# source code folder path\n",
    "rec_sys_dir = get_rec_sys_directory()\n",
    "print(f\"Rec-sys directory: {rec_sys_dir}\")\n",
    "\n",
    "# data folder path\n",
    "DATA_DIR = os.path.join(rec_sys_dir, '../data')\n",
    "print(f\"Data directory: {DATA_DIR}\")\n",
    "\n",
    "# data path\n",
    "data_path = os.path.join(DATA_DIR, 'ml-1m/merged_data.dat')\n",
    "print(f'Data path: {data_path}')\n",
    "\n",
    "# output\n",
    "\n",
    "CF_output_path = os.path.join(DATA_DIR, 'ml-1m/output/CF_output_path_2_ratings_per_user.dat')\n",
    "print(f'Data path: {data_path}')\n",
    "\n",
    "CF_RERUN_PATH = os.path.join(DATA_DIR, 'ml-1m/output/rerun_CF_output_path_2_ratings_per_user.dat')\n",
    "print(f'Data path: {data_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and Merge Data\n",
    "def load_and_merge_data(movies_path, ratings_path, users_path):\n",
    "    # Load each file\n",
    "    movies = pd.read_csv(movies_path, delimiter='::', engine= 'python', header=None, names=['MovieID', 'Title', 'Genres'], encoding='ISO-8859-1')\n",
    "    ratings = pd.read_csv(ratings_path, delimiter='::', engine= 'python', header=None, names=['UserID', 'MovieID', 'Rating', 'Timestamp'], encoding='ISO-8859-1')\n",
    "    users = pd.read_csv(users_path,delimiter='::', engine= 'python', header=None, names=['UserID', 'Gender', 'Age', 'Occupation', 'Zip-code'], encoding='ISO-8859-1')\n",
    "    # Merge datasets\n",
    "    merged_data = pd.merge(pd.merge(ratings, users, on='UserID'), movies, on='MovieID')\n",
    "    return merged_data\n",
    "\n",
    "\n",
    "# Filter Users with â‰¥ 5 Ratings\n",
    "def filter_users(data):\n",
    "    user_rating_counts = data['UserID'].value_counts()\n",
    "    valid_users = user_rating_counts[user_rating_counts >= 5].index.tolist()\n",
    "    return data[data['UserID'].isin(valid_users)]\n",
    "\n",
    "\n",
    "# Calculate Pearson Correlation Coefficient\n",
    "# source RMIT courses\n",
    "def pearson_correlation(interaction_matrix):\n",
    "    \"\"\"\n",
    "    Compute the Pearson Correlation Coefficient matrix for the user-item interaction matrix.\n",
    "\n",
    "    Args:\n",
    "    interaction_matrix (csr_matrix): A sparse matrix where rows represent users and columns represent items.\n",
    "                                     The values in the matrix are the ratings given by users to items.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: A 2D array representing the Pearson Correlation Coefficients between each pair of users.\n",
    "    \"\"\"\n",
    "    # Convert sparse matrix to dense format for processing\n",
    "    dense_matrix = interaction_matrix.toarray()\n",
    "    \n",
    "    # Get the number of users\n",
    "    n_users = dense_matrix.shape[0]\n",
    "\n",
    "    # Initialize the Pearson Correlation matrix\n",
    "    pearson_corr_matrix = np.zeros((n_users, n_users))\n",
    "\n",
    "    # Small constant to avoid division by zero\n",
    "    EPSILON = 1e-9\n",
    "\n",
    "    # Iterate over each pair of users\n",
    "    for i in range(n_users):\n",
    "        for j in range(n_users):\n",
    "            # Get the rating vectors for the current pair of users\n",
    "            user_i_vec = dense_matrix[i, :]\n",
    "            user_j_vec = dense_matrix[j, :]\n",
    "\n",
    "            # Masks for rated items\n",
    "            mask_i = user_i_vec > 0\n",
    "            mask_j = user_j_vec > 0\n",
    "\n",
    "            # Find indices of corrated items\n",
    "            corrated_index = np.intersect1d(np.where(mask_i)[0], np.where(mask_j)[0])\n",
    "\n",
    "            # Skip if no items are corrated\n",
    "            if len(corrated_index) == 0:\n",
    "                continue\n",
    "\n",
    "            # Compute the mean rating for each user over corrated items\n",
    "            mean_user_i = np.mean(user_i_vec[corrated_index])\n",
    "            mean_user_j = np.mean(user_j_vec[corrated_index])\n",
    "\n",
    "            # Compute the deviations from the mean\n",
    "            user_i_sub_mean = user_i_vec[corrated_index] - mean_user_i\n",
    "            user_j_sub_mean = user_j_vec[corrated_index] - mean_user_j\n",
    "\n",
    "            # Calculate the components for Pearson correlation\n",
    "            r_ui_sub_r_i_sq = np.square(user_i_sub_mean)\n",
    "            r_uj_sub_r_j_sq = np.square(user_j_sub_mean)\n",
    "\n",
    "            r_ui_sum_sqrt = np.sqrt(np.sum(r_ui_sub_r_i_sq))\n",
    "            r_uj_sum_sqrt = np.sqrt(np.sum(r_uj_sub_r_j_sq))\n",
    "\n",
    "            # Calculate Pearson correlation\n",
    "            sim = np.sum(user_i_sub_mean * user_j_sub_mean) / (r_ui_sum_sqrt * r_uj_sum_sqrt + EPSILON)\n",
    "\n",
    "            # Store the similarity in the matrix\n",
    "            pearson_corr_matrix[i, j] = sim\n",
    "\n",
    "    return pearson_corr_matrix\n",
    "\n",
    "\n",
    "# Find Valid Neighbors\n",
    "def get_valid_neighbors(pcc_matrix, threshold=0.6):\n",
    "    valid_neighbors = {}\n",
    "    for i, row in enumerate(pcc_matrix):\n",
    "        valid_neighbors[i] = np.where(row > threshold)[0]\n",
    "    return valid_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ratings_with_collaborative_filtering_and_save(data, \n",
    "                                                          pcc_matrix, \n",
    "                                                          user_column_name='UserID', \n",
    "                                                          movie_column_name='Title', \n",
    "                                                          movie_id_column='MovieID',\n",
    "                                                          rating_column_name='Rating', \n",
    "                                                          num_ratings_per_user=1, \n",
    "                                                          num_similar_users=4, \n",
    "                                                          save_path='cf_predictions.csv', \n",
    "                                                          seed=RANDOM_STATE):\n",
    "    results = []\n",
    "\n",
    "    # Get user IDs after filtering\n",
    "    users = data[user_column_name].unique()\n",
    "\n",
    "    # Random seed for reproducibility\n",
    "    random.seed(seed)\n",
    "\n",
    "    for user_id in users:\n",
    "        # Get the user's row index in the pcc_matrix\n",
    "        user_idx = user_id - 1  # Adjusting for zero-based index\n",
    "\n",
    "        # Find the top similar users based on Pearson Correlation Coefficient\n",
    "        similar_users_idx = np.argsort(-pcc_matrix[user_idx])[:num_similar_users + 1]  # Including the user itself\n",
    "        similar_users_idx = similar_users_idx[similar_users_idx != user_idx][:num_similar_users]  # Exclude the user itself\n",
    "\n",
    "        # Print the IDs of the similar users and their historical ratings\n",
    "        print(f\"User {user_id} - Similar Users: {[idx + 1 for idx in similar_users_idx]}\")\n",
    "        similar_users_ratings = \"\"\n",
    "        for idx in similar_users_idx:\n",
    "            similar_user_id = idx + 1  # Adjusting for zero-based index\n",
    "            similar_user_data = data[data[user_column_name] == similar_user_id]\n",
    "            historical_ratings = similar_user_data.head(num_ratings_per_user)\n",
    "            for _, row in historical_ratings.iterrows():\n",
    "                rating_info = f\"* title: {row[movie_column_name]} - Rating: {row[rating_column_name]} stars\"\n",
    "                print(f\"Similar User {similar_user_id} - Historical Rating: {rating_info}\")\n",
    "                similar_users_ratings += rating_info + \"\\n\"\n",
    "\n",
    "        # Select a random movie title from the main user's data\n",
    "        user_data = data[data[user_column_name] == user_id]\n",
    "        random_movie_row = user_data.sample(n=1, random_state=seed).iloc[0]\n",
    "        random_movie_title = random_movie_row[movie_column_name]\n",
    "        random_movie_id = random_movie_row[movie_id_column]\n",
    "        actual_rating = random_movie_row[rating_column_name]\n",
    "\n",
    "        # Generate the combined text for prediction\n",
    "        combined_text = f\"title: {random_movie_title}\"\n",
    "\n",
    "        # Get the predicted rating using ChatGPT\n",
    "        predicted_rating = predict_rating_combined_ChatCompletion(\n",
    "            combined_text, \n",
    "            approach=\"CF\", \n",
    "            similar_users_ratings=similar_users_ratings\n",
    "        )\n",
    "\n",
    "        # Append the results\n",
    "        results.append([user_id, random_movie_id, random_movie_title, actual_rating, predicted_rating])\n",
    "\n",
    "    # Save results to CSV\n",
    "    results_df = pd.DataFrame(results, columns=['user_id', 'item_id', 'title', 'actual_rating', 'predicted_rating'])\n",
    "    results_df.to_csv(save_path, index=False)\n",
    "    print(f\"Predictions saved to {save_path}\")\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Zip-code</th>\n",
       "      <th>Title</th>\n",
       "      <th>Genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978298413</td>\n",
       "      <td>M</td>\n",
       "      <td>56</td>\n",
       "      <td>16</td>\n",
       "      <td>70072</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>1193</td>\n",
       "      <td>4</td>\n",
       "      <td>978220179</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>32793</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID  MovieID  Rating  Timestamp Gender  Age  Occupation Zip-code  \\\n",
       "0       1     1193       5  978300760      F    1          10    48067   \n",
       "1       2     1193       5  978298413      M   56          16    70072   \n",
       "2      12     1193       4  978220179      M   25          12    32793   \n",
       "\n",
       "                                    Title Genres  \n",
       "0  One Flew Over the Cuckoo's Nest (1975)  Drama  \n",
       "1  One Flew Over the Cuckoo's Nest (1975)  Drama  \n",
       "2  One Flew Over the Cuckoo's Nest (1975)  Drama  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(data_path)\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create User-Item Interaction Matrix\n",
    "interaction_matrix = pd.pivot_table(data, index='UserID', columns='MovieID', values='Rating').fillna(0)\n",
    "csr_interaction_matrix = csr_matrix(interaction_matrix.values)\n",
    "\n",
    "# Calculate Pearson Correlation Coefficient Matrix\n",
    "pcc_matrix = pearson_correlation(csr_interaction_matrix)\n",
    "\n",
    "pcc_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csr_interaction_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "cf_predictions = predict_ratings_with_collaborative_filtering_and_save(data, \n",
    "                                                                       pcc_matrix, \n",
    "                                                                       save_path=CF_output_path,\n",
    "                                                                       num_ratings_per_user=2,\n",
    "                                                                       num_similar_users=4, )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the data\n",
    "data = pd.read_csv(CF_output_path)\n",
    "\n",
    "# Display the original data types\n",
    "print(\"Original Data Types:\")\n",
    "print(data.dtypes)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Attempt to convert ratings to float and add a flag for conversion failure\n",
    "data['is_rating_float'] = pd.to_numeric(data['predicted_rating'], errors='coerce').notna()\n",
    "\n",
    "# Filter rows where ratings are not float\n",
    "non_float_ratings = data[data['is_rating_float'] == False]\n",
    "\n",
    "# total number of rows with non-float ratings\n",
    "print(f\"Total number of rows with non-float ratings: {len(non_float_ratings)}\")\n",
    "\n",
    "# Display rows with non-float ratings\n",
    "print(\"Rows with non-float ratings:\")\n",
    "non_float_ratings.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the original CF predictions\n",
    "cf_data = pd.read_csv(CF_output_path)\n",
    "cf_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_and_rerun_failed_cf_predictions(data, \n",
    "                                             pcc_matrix, \n",
    "                                             user_column_name='user_id', \n",
    "                                             movie_column_name='title', \n",
    "                                             movie_id_column='item_id',\n",
    "                                             rating_column_name='actual_rating', \n",
    "                                             num_ratings_per_user=1, \n",
    "                                             num_similar_users=4, \n",
    "                                             save_path='cf_predictions.csv', \n",
    "                                             rerun_save_path='cf_rerun_predictions.csv', \n",
    "                                             seed=RANDOM_STATE):\n",
    "    \"\"\"\n",
    "    Identify failed predictions in CF data and rerun them.\n",
    "\n",
    "    Args:\n",
    "    - data: DataFrame containing the original CF predictions.\n",
    "    - pcc_matrix: Pearson Correlation Coefficient matrix.\n",
    "    - Other arguments for controlling various aspects of the prediction function.\n",
    "\n",
    "    Returns:\n",
    "    - Updated DataFrame with rerun predictions.\n",
    "    \"\"\"\n",
    "    # Ensure the original data has the necessary columns\n",
    "    if rating_column_name not in data.columns:\n",
    "        raise KeyError(f\"Column '{rating_column}' not found in the data.\")\n",
    "\n",
    "    # Identify rows with failed predictions\n",
    "    failed_rows = data[pd.to_numeric(data['predicted_rating'], errors='coerce').isna()]\n",
    "\n",
    "    if len(failed_rows) > 0:\n",
    "        print(f\"Re-running predictions for {len(failed_rows)} failed cases.\")\n",
    "\n",
    "        # Call prediction function on failed data\n",
    "        rerun_data = predict_ratings_with_collaborative_filtering_and_save(\n",
    "            failed_rows, pcc_matrix,\n",
    "            user_column_name=user_column_name,\n",
    "            movie_column_name=movie_column_name,\n",
    "            movie_id_column=movie_id_column,\n",
    "            rating_column_name=rating_column_name,\n",
    "            num_ratings_per_user=num_ratings_per_user,\n",
    "            num_similar_users=num_similar_users,\n",
    "            save_path=rerun_save_path,\n",
    "            seed=seed\n",
    "        )\n",
    "\n",
    "        # Update original data with new predictions\n",
    "        data.loc[failed_rows.index, 'predicted_rating'] = rerun_data['predicted_rating']\n",
    "\n",
    "    # Save the updated data\n",
    "    data.to_csv(save_path, index=False)\n",
    "    print(f\"Updated predictions saved to {save_path}\")\n",
    "\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "# Load the original CF predictions\n",
    "cf_data = pd.read_csv(CF_output_path)\n",
    "\n",
    "\n",
    "# Identify and rerun failed predictions\n",
    "updated_cf_data = identify_and_rerun_failed_cf_predictions(\n",
    "    cf_data, pcc_matrix,\n",
    "    save_path=CF_output_path,\n",
    "    rating_column_name='actual_rating', \n",
    "    rerun_save_path=CF_RERUN_PATH\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate updated CF model predictions\n",
    "evaluate_model_predictions_rmse_mae(\n",
    "    data_path=CF_output_path,\n",
    "    num_examples=NUM_EXAMPLES,\n",
    "    actual_ratings_column='actual_rating',\n",
    "    predicted_ratings_column='predicted_rating'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
