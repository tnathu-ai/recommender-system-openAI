{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Process data for CF\n",
    "\n",
    "+ Read and Merge Data: Load the ratings.dat, users.dat, and movies.dat files, and merge them into a single DataFrame.\n",
    "+ Filter Users with ≥ 5 Ratings: Filter out users who have less than 5 ratings.\n",
    "+ Calculate Pearson Correlation and Find Valid Neighbors: Use the pearson_correlation function to calculate the Pearson Correlation Coefficient matrix and then identify users who have valid neighbors based on a threshold.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rec-sys directory: /Users/tnathu-ai/VSCode/recommender-system/recommender-system-openAI/rec-sys/notebook\n",
      "Data directory: /Users/tnathu-ai/VSCode/recommender-system/recommender-system-openAI/rec-sys/notebook/../data\n",
      "Data path: /Users/tnathu-ai/VSCode/recommender-system/recommender-system-openAI/rec-sys/notebook/../data/ml-1m/movies.dat\n",
      "Data path: /Users/tnathu-ai/VSCode/recommender-system/recommender-system-openAI/rec-sys/notebook/../data/ml-1m/ratings.dat\n",
      "Data path: /Users/tnathu-ai/VSCode/recommender-system/recommender-system-openAI/rec-sys/notebook/../data/ml-1m/users.dat\n",
      "Data path: /Users/tnathu-ai/VSCode/recommender-system/recommender-system-openAI/rec-sys/notebook/../data/ml-1m/merged_data.dat\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "import os\n",
    "import sys\n",
    "# Add the path to the constants file to the system path\n",
    "sys.path.append('../../../')\n",
    "from path_utils import *\n",
    "\n",
    "# source code folder path\n",
    "rec_sys_dir = get_rec_sys_directory()\n",
    "print(f\"Rec-sys directory: {rec_sys_dir}\")\n",
    "\n",
    "# data folder path\n",
    "DATA_DIR = os.path.join(rec_sys_dir, '../data')\n",
    "print(f\"Data directory: {DATA_DIR}\")\n",
    "\n",
    "# data path\n",
    "movies_path = os.path.join(DATA_DIR, 'ml-1m/movies.dat')\n",
    "print(f'Data path: {movies_path}')\n",
    "ratings_path = os.path.join(DATA_DIR, 'ml-1m/ratings.dat')\n",
    "print(f'Data path: {ratings_path}')\n",
    "users_path = os.path.join(DATA_DIR, 'ml-1m/users.dat')\n",
    "print(f'Data path: {users_path}')\n",
    "\n",
    "data_path = os.path.join(DATA_DIR, 'ml-1m/merged_data.dat')\n",
    "print(f'Data path: {data_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Read and Merge Data\n",
    "def load_and_merge_data(movies_path, ratings_path, users_path):\n",
    "    # Load each file\n",
    "    movies = pd.read_csv(movies_path, delimiter='::', engine= 'python', header=None, names=['MovieID', 'Title', 'Genres'], encoding='ISO-8859-1')\n",
    "    ratings = pd.read_csv(ratings_path, delimiter='::', engine= 'python', header=None, names=['UserID', 'MovieID', 'Rating', 'Timestamp'], encoding='ISO-8859-1')\n",
    "    users = pd.read_csv(users_path,delimiter='::', engine= 'python', header=None, names=['UserID', 'Gender', 'Age', 'Occupation', 'Zip-code'], encoding='ISO-8859-1')\n",
    "\n",
    "    # Merge datasets\n",
    "    merged_data = pd.merge(pd.merge(ratings, users, on='UserID'), movies, on='MovieID')\n",
    "    return merged_data\n",
    "\n",
    "# Step 2: Filter Users with ≥ 5 Ratings\n",
    "def filter_users(data):\n",
    "    user_rating_counts = data['UserID'].value_counts()\n",
    "    valid_users = user_rating_counts[user_rating_counts >= 5].index.tolist()\n",
    "    return data[data['UserID'].isin(valid_users)]\n",
    "\n",
    "# Step 3: Calculate Pearson Correlation\n",
    "\n",
    "# source RMIT courses\n",
    "def pearson_correlation(interaction_matrix):\n",
    "    \"\"\"\n",
    "    Compute the Pearson Correlation Coefficient matrix for the user-item interaction matrix.\n",
    "\n",
    "    Args:\n",
    "    interaction_matrix (csr_matrix): A sparse matrix where rows represent users and columns represent items.\n",
    "                                     The values in the matrix are the ratings given by users to items.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: A 2D array representing the Pearson Correlation Coefficients between each pair of users.\n",
    "    \"\"\"\n",
    "    # Convert sparse matrix to dense format for processing\n",
    "    dense_matrix = interaction_matrix.toarray()\n",
    "    \n",
    "    # Get the number of users\n",
    "    n_users = dense_matrix.shape[0]\n",
    "\n",
    "    # Initialize the Pearson Correlation matrix\n",
    "    pearson_corr_matrix = np.zeros((n_users, n_users))\n",
    "\n",
    "    # Small constant to avoid division by zero\n",
    "    EPSILON = 1e-9\n",
    "\n",
    "    # Iterate over each pair of users\n",
    "    for i in range(n_users):\n",
    "        for j in range(n_users):\n",
    "            # Get the rating vectors for the current pair of users\n",
    "            user_i_vec = dense_matrix[i, :]\n",
    "            user_j_vec = dense_matrix[j, :]\n",
    "\n",
    "            # Masks for rated items\n",
    "            mask_i = user_i_vec > 0\n",
    "            mask_j = user_j_vec > 0\n",
    "\n",
    "            # Find indices of corrated items\n",
    "            corrated_index = np.intersect1d(np.where(mask_i)[0], np.where(mask_j)[0])\n",
    "\n",
    "            # Skip if no items are corrated\n",
    "            if len(corrated_index) == 0:\n",
    "                continue\n",
    "\n",
    "            # Compute the mean rating for each user over corrated items\n",
    "            mean_user_i = np.mean(user_i_vec[corrated_index])\n",
    "            mean_user_j = np.mean(user_j_vec[corrated_index])\n",
    "\n",
    "            # Compute the deviations from the mean\n",
    "            user_i_sub_mean = user_i_vec[corrated_index] - mean_user_i\n",
    "            user_j_sub_mean = user_j_vec[corrated_index] - mean_user_j\n",
    "\n",
    "            # Calculate the components for Pearson correlation\n",
    "            r_ui_sub_r_i_sq = np.square(user_i_sub_mean)\n",
    "            r_uj_sub_r_j_sq = np.square(user_j_sub_mean)\n",
    "\n",
    "            r_ui_sum_sqrt = np.sqrt(np.sum(r_ui_sub_r_i_sq))\n",
    "            r_uj_sum_sqrt = np.sqrt(np.sum(r_uj_sub_r_j_sq))\n",
    "\n",
    "            # Calculate Pearson correlation\n",
    "            sim = np.sum(user_i_sub_mean * user_j_sub_mean) / (r_ui_sum_sqrt * r_uj_sum_sqrt + EPSILON)\n",
    "\n",
    "            # Store the similarity in the matrix\n",
    "            pearson_corr_matrix[i, j] = sim\n",
    "\n",
    "    return pearson_corr_matrix\n",
    "\n",
    "\n",
    "# Step 3: Find Valid Neighbors\n",
    "def get_valid_neighbors(pcc_matrix, threshold=0.6):\n",
    "    valid_neighbors = {}\n",
    "    for i, row in enumerate(pcc_matrix):\n",
    "        valid_neighbors[i] = np.where(row > threshold)[0]\n",
    "    return valid_neighbors\n",
    "\n",
    "\n",
    "\n",
    "# Load and merge data\n",
    "data = load_and_merge_data(movies_path, ratings_path, users_path)\n",
    "\n",
    "# Filter users with at least 5 ratings\n",
    "filtered_data = filter_users(data)\n",
    "\n",
    "# Create User-Item Interaction Matrix\n",
    "interaction_matrix = pd.pivot_table(filtered_data, index='UserID', columns='MovieID', values='Rating').fillna(0)\n",
    "csr_interaction_matrix = csr_matrix(interaction_matrix.values)\n",
    "\n",
    "# Calculate Pearson Correlation Coefficient Matrix\n",
    "pcc_matrix = pearson_correlation(csr_interaction_matrix)\n",
    "\n",
    "# Find Valid Neighbors\n",
    "valid_neighbors = get_valid_neighbors(pcc_matrix)\n",
    "\n",
    "# Print some summary\n",
    "print(f\"Total users after filtering: {len(filtered_data['UserID'].unique())}\")\n",
    "print(f\"Total users with valid neighbors: {len(valid_neighbors)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saved the merged data in data_path\n",
    "data.to_csv(data_path, index=False)\n",
    "print(f\"Saved merged data in {data_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
