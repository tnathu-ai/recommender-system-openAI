{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Process data for CF\n",
    "\n",
    "+ Read and Merge Data: Load the ratings.dat, users.dat, and movies.dat files, and merge them into a single DataFrame.\n",
    "+ Filter Users with ≥ 5 Ratings: Filter out users who have less than 5 ratings.\n",
    "+ Calculate Pearson Correlation  \n",
    "+ Find Valid Neighbors: Use the pearson_correlation function to calculate the Pearson Correlation Coefficient matrix and then identify users who have valid neighbors based on a threshold (>=0.6).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rec-sys directory: /Users/tnathu-ai/VSCode/recommender-system/recommender-system-openAI/rec-sys/notebook\n",
      "Data directory: /Users/tnathu-ai/VSCode/recommender-system/recommender-system-openAI/rec-sys/notebook/../data\n",
      "Data path: /Users/tnathu-ai/VSCode/recommender-system/recommender-system-openAI/rec-sys/notebook/../data/ml-1m/movies.dat\n",
      "Data path: /Users/tnathu-ai/VSCode/recommender-system/recommender-system-openAI/rec-sys/notebook/../data/ml-1m/ratings.dat\n",
      "Data path: /Users/tnathu-ai/VSCode/recommender-system/recommender-system-openAI/rec-sys/notebook/../data/ml-1m/users.dat\n",
      "Data path: /Users/tnathu-ai/VSCode/recommender-system/recommender-system-openAI/rec-sys/notebook/../data/ml-1m/merged_data.dat\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "import os\n",
    "import sys\n",
    "# Add the path to the constants file to the system path\n",
    "sys.path.append('../../../')\n",
    "from path_utils import *\n",
    "\n",
    "# source code folder path\n",
    "rec_sys_dir = get_rec_sys_directory()\n",
    "print(f\"Rec-sys directory: {rec_sys_dir}\")\n",
    "\n",
    "# data folder path\n",
    "DATA_DIR = os.path.join(rec_sys_dir, '../data')\n",
    "print(f\"Data directory: {DATA_DIR}\")\n",
    "\n",
    "# data path\n",
    "movies_path = os.path.join(DATA_DIR, 'ml-1m/movies.dat')\n",
    "print(f'Data path: {movies_path}')\n",
    "ratings_path = os.path.join(DATA_DIR, 'ml-1m/ratings.dat')\n",
    "print(f'Data path: {ratings_path}')\n",
    "users_path = os.path.join(DATA_DIR, 'ml-1m/users.dat')\n",
    "print(f'Data path: {users_path}')\n",
    "\n",
    "data_path = os.path.join(DATA_DIR, 'ml-1m/merged_data.dat')\n",
    "print(f'Data path: {data_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total users after filtering: 6040\n",
      "Total users with valid neighbors: 6040\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 1: Read and Merge Data\n",
    "def load_and_merge_data(movies_path, ratings_path, users_path):\n",
    "    # Load each file\n",
    "    movies = pd.read_csv(movies_path, delimiter='::', engine= 'python', header=None, names=['MovieID', 'Title', 'Genres'], encoding='ISO-8859-1')\n",
    "    ratings = pd.read_csv(ratings_path, delimiter='::', engine= 'python', header=None, names=['UserID', 'MovieID', 'Rating', 'Timestamp'], encoding='ISO-8859-1')\n",
    "    users = pd.read_csv(users_path,delimiter='::', engine= 'python', header=None, names=['UserID', 'Gender', 'Age', 'Occupation', 'Zip-code'], encoding='ISO-8859-1')\n",
    "\n",
    "    # Merge datasets\n",
    "    merged_data = pd.merge(pd.merge(ratings, users, on='UserID'), movies, on='MovieID')\n",
    "    return merged_data\n",
    "\n",
    "# Step 2: Filter Users with ≥ 5 Ratings\n",
    "def filter_users(data):\n",
    "    user_rating_counts = data['UserID'].value_counts()\n",
    "    valid_users = user_rating_counts[user_rating_counts >= 5].index.tolist()\n",
    "    return data[data['UserID'].isin(valid_users)]\n",
    "\n",
    "# Step 3: Calculate Pearson Correlation\n",
    "\n",
    "# source RMIT courses\n",
    "def pearson_correlation(interaction_matrix):\n",
    "    \"\"\"\n",
    "    Compute the Pearson Correlation Coefficient matrix for the user-item interaction matrix.\n",
    "\n",
    "    Args:\n",
    "    interaction_matrix (csr_matrix): A sparse matrix where rows represent users and columns represent items.\n",
    "                                     The values in the matrix are the ratings given by users to items.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: A 2D array representing the Pearson Correlation Coefficients between each pair of users.\n",
    "    \"\"\"\n",
    "    # Convert sparse matrix to dense format for processing\n",
    "    dense_matrix = interaction_matrix.toarray()\n",
    "    \n",
    "    # Get the number of users\n",
    "    n_users = dense_matrix.shape[0]\n",
    "\n",
    "    # Initialize the Pearson Correlation matrix\n",
    "    pearson_corr_matrix = np.zeros((n_users, n_users))\n",
    "\n",
    "    # Small constant to avoid division by zero\n",
    "    EPSILON = 1e-9\n",
    "\n",
    "    # Iterate over each pair of users\n",
    "    for i in range(n_users):\n",
    "        for j in range(n_users):\n",
    "            # Get the rating vectors for the current pair of users\n",
    "            user_i_vec = dense_matrix[i, :]\n",
    "            user_j_vec = dense_matrix[j, :]\n",
    "\n",
    "            # Masks for rated items\n",
    "            mask_i = user_i_vec > 0\n",
    "            mask_j = user_j_vec > 0\n",
    "\n",
    "            # Find indices of corrated items\n",
    "            corrated_index = np.intersect1d(np.where(mask_i)[0], np.where(mask_j)[0])\n",
    "\n",
    "            # Skip if no items are corrated\n",
    "            if len(corrated_index) == 0:\n",
    "                continue\n",
    "\n",
    "            # Compute the mean rating for each user over corrated items\n",
    "            mean_user_i = np.mean(user_i_vec[corrated_index])\n",
    "            mean_user_j = np.mean(user_j_vec[corrated_index])\n",
    "\n",
    "            # Compute the deviations from the mean\n",
    "            user_i_sub_mean = user_i_vec[corrated_index] - mean_user_i\n",
    "            user_j_sub_mean = user_j_vec[corrated_index] - mean_user_j\n",
    "\n",
    "            # Calculate the components for Pearson correlation\n",
    "            r_ui_sub_r_i_sq = np.square(user_i_sub_mean)\n",
    "            r_uj_sub_r_j_sq = np.square(user_j_sub_mean)\n",
    "\n",
    "            r_ui_sum_sqrt = np.sqrt(np.sum(r_ui_sub_r_i_sq))\n",
    "            r_uj_sum_sqrt = np.sqrt(np.sum(r_uj_sub_r_j_sq))\n",
    "\n",
    "            # Calculate Pearson correlation\n",
    "            sim = np.sum(user_i_sub_mean * user_j_sub_mean) / (r_ui_sum_sqrt * r_uj_sum_sqrt + EPSILON)\n",
    "\n",
    "            # Store the similarity in the matrix\n",
    "            pearson_corr_matrix[i, j] = sim\n",
    "\n",
    "    return pearson_corr_matrix\n",
    "\n",
    "\n",
    "# Step 3: Find Valid Neighbors\n",
    "def get_valid_neighbors(pcc_matrix, threshold=0.6):\n",
    "    valid_neighbors = {}\n",
    "    for i, row in enumerate(pcc_matrix):\n",
    "        valid_neighbors[i] = np.where(row > threshold)[0]\n",
    "    return valid_neighbors\n",
    "\n",
    "\n",
    "\n",
    "# Load and merge data\n",
    "data = load_and_merge_data(movies_path, ratings_path, users_path)\n",
    "\n",
    "# Filter users with at least 5 ratings\n",
    "filtered_data = filter_users(data)\n",
    "\n",
    "# Create User-Item Interaction Matrix\n",
    "interaction_matrix = pd.pivot_table(filtered_data, index='UserID', columns='MovieID', values='Rating').fillna(0)\n",
    "csr_interaction_matrix = csr_matrix(interaction_matrix.values)\n",
    "\n",
    "# Calculate Pearson Correlation Coefficient Matrix\n",
    "pcc_matrix = pearson_correlation(csr_interaction_matrix)\n",
    "\n",
    "# Find Valid Neighbors\n",
    "valid_neighbors = get_valid_neighbors(pcc_matrix)\n",
    "\n",
    "# Print some summary\n",
    "print(f\"Total users after filtering: {len(filtered_data['UserID'].unique())}\")\n",
    "print(f\"Total users with valid neighbors: {len(valid_neighbors)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved merged data in /Users/tnathu-ai/VSCode/recommender-system/recommender-system-openAI/rec-sys/notebook/../data/ml-1m/merged_data.dat\n"
     ]
    }
   ],
   "source": [
    "# saved the merged data in data_path\n",
    "data.to_csv(data_path, index=False)\n",
    "print(f\"Saved merged data in {data_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Zip-code</th>\n",
       "      <th>Title</th>\n",
       "      <th>Genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978298413</td>\n",
       "      <td>M</td>\n",
       "      <td>56</td>\n",
       "      <td>16</td>\n",
       "      <td>70072</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>1193</td>\n",
       "      <td>4</td>\n",
       "      <td>978220179</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>32793</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID  MovieID  Rating  Timestamp Gender  Age  Occupation Zip-code  \\\n",
       "0       1     1193       5  978300760      F    1          10    48067   \n",
       "1       2     1193       5  978298413      M   56          16    70072   \n",
       "2      12     1193       4  978220179      M   25          12    32793   \n",
       "\n",
       "                                    Title Genres  \n",
       "0  One Flew Over the Cuckoo's Nest (1975)  Drama  \n",
       "1  One Flew Over the Cuckoo's Nest (1975)  Drama  \n",
       "2  One Flew Over the Cuckoo's Nest (1975)  Drama  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic Statistics:\n",
      "             UserID       MovieID        Rating     Timestamp           Age  \\\n",
      "count  1.000209e+06  1.000209e+06  1.000209e+06  1.000209e+06  1.000209e+06   \n",
      "mean   3.024512e+03  1.865540e+03  3.581564e+00  9.722437e+08  2.973831e+01   \n",
      "std    1.728413e+03  1.096041e+03  1.117102e+00  1.215256e+07  1.175198e+01   \n",
      "min    1.000000e+00  1.000000e+00  1.000000e+00  9.567039e+08  1.000000e+00   \n",
      "25%    1.506000e+03  1.030000e+03  3.000000e+00  9.653026e+08  2.500000e+01   \n",
      "50%    3.070000e+03  1.835000e+03  4.000000e+00  9.730180e+08  2.500000e+01   \n",
      "75%    4.476000e+03  2.770000e+03  4.000000e+00  9.752209e+08  3.500000e+01   \n",
      "max    6.040000e+03  3.952000e+03  5.000000e+00  1.046455e+09  5.600000e+01   \n",
      "\n",
      "         Occupation  \n",
      "count  1.000209e+06  \n",
      "mean   8.036138e+00  \n",
      "std    6.531336e+00  \n",
      "min    0.000000e+00  \n",
      "25%    2.000000e+00  \n",
      "50%    7.000000e+00  \n",
      "75%    1.400000e+01  \n",
      "max    2.000000e+01  \n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Function to plot basic statistics and EDA\n",
    "def plot_eda(data):\n",
    "    # Basic statistics\n",
    "    print(\"Basic Statistics:\")\n",
    "    print(data.describe())\n",
    "\n",
    "    # Distribution of ratings\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.countplot(data['Rating'])\n",
    "    plt.title('Distribution of Ratings')\n",
    "    plt.xlabel('Rating')\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()\n",
    "\n",
    "    # Number of ratings per user\n",
    "    user_ratings = data.groupby('UserID').size()\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.histplot(user_ratings, bins=30, kde=True)\n",
    "    plt.title('Number of Ratings per User')\n",
    "    plt.xlabel('Number of Ratings')\n",
    "    plt.ylabel('Count of Users')\n",
    "    plt.show()\n",
    "\n",
    "    # Number of ratings per movie\n",
    "    movie_ratings = data.groupby('MovieID').size()\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.histplot(movie_ratings, bins=30, kde=True)\n",
    "    plt.title('Number of Ratings per Movie')\n",
    "    plt.xlabel('Number of Ratings')\n",
    "    plt.ylabel('Count of Movies')\n",
    "    plt.show()\n",
    "\n",
    "# Plot EDA\n",
    "plot_eda(filtered_data)\n",
    "\n",
    "# %%\n",
    "# saved the merged data in data_path\n",
    "data.to_csv(data_path, index=False)\n",
    "print(f\"Saved merged data in {data_path}\")\n",
    "\n",
    "# Additional EDA: Top 10 most rated movies\n",
    "top_movies = data.groupby('Title').size().sort_values(ascending=False).head(10)\n",
    "plt.figure(figsize=(10, 6))\n",
    "top_movies.plot(kind='barh')\n",
    "plt.title('Top 10 Most Rated Movies')\n",
    "plt.xlabel('Number of Ratings')\n",
    "plt.ylabel('Movie Title')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()\n",
    "\n",
    "# Additional EDA: User rating distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(user_ratings, bins=30, kde=False)\n",
    "plt.title('User Rating Distribution')\n",
    "plt.xlabel('Number of Ratings per User')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Additional EDA: Movie rating distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(movie_ratings, bins=30, kde=False)\n",
    "plt.title('Movie Rating Distribution')\n",
    "plt.xlabel('Number of Ratings per Movie')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
