{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import openai\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "# Add the path to the constants file to the system path\n",
    "sys.path.append('../../')\n",
    "from constants import *\n",
    "from evaluation_utils import *\n",
    "from path_utils import *\n",
    "from ChatCompletion_OpenAI_API import *\n",
    "\n",
    "# OpenAI API Key\n",
    "openai.api_key = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rec-sys directory: /Users/tnathu-ai/VSCode/recommender-system/recommender-system-openAI/rec-sys\n",
      "Data directory: /Users/tnathu-ai/VSCode/recommender-system/recommender-system-openAI/rec-sys/data\n",
      "Data path: /Users/tnathu-ai/VSCode/recommender-system/recommender-system-openAI/rec-sys/data/movie-ml-latest-small/merged_data.csv\n",
      "Zero shot save path: /Users/tnathu-ai/VSCode/recommender-system/recommender-system-openAI/rec-sys/data/movie-ml-latest-small/title_large_predictions_zero_shot.csv\n",
      "Few shot save path: /Users/tnathu-ai/VSCode/recommender-system/recommender-system-openAI/rec-sys/data/movie-ml-latest-small/title_large_1_test_predictions_few_shot.csv\n"
     ]
    }
   ],
   "source": [
    "# source code folder path\n",
    "rec_sys_dir = get_rec_sys_directory()\n",
    "print(f\"Rec-sys directory: {rec_sys_dir}\")\n",
    "\n",
    "# data folder path\n",
    "DATA_DIR = os.path.join(rec_sys_dir, 'data')\n",
    "print(f\"Data directory: {DATA_DIR}\")\n",
    "\n",
    "# data path\n",
    "data_path = os.path.join(DATA_DIR, 'movie-ml-latest-small/merged_data.csv')\n",
    "print(f'Data path: {data_path}')\n",
    "\n",
    "# zero shot save path\n",
    "ZERO_SHOT_SAVE_PATH = os.path.join(DATA_DIR, 'movie-ml-latest-small/title_large_predictions_zero_shot.csv')\n",
    "print(f'Zero shot save path: {ZERO_SHOT_SAVE_PATH}')\n",
    "\n",
    "# few shot save path\n",
    "FEW_SHOT_1_OBS_SAVE_PATH = os.path.join(DATA_DIR, 'movie-ml-latest-small/title_large_1_test_predictions_few_shot.csv')\n",
    "print(f'Few shot save path: {FEW_SHOT_1_OBS_SAVE_PATH}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3405 entries, 0 to 3404\n",
      "Data columns (total 8 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   movieId  3405 non-null   int64  \n",
      " 1   imdbId   3405 non-null   int64  \n",
      " 2   tmdbId   3405 non-null   float64\n",
      " 3   title    3405 non-null   object \n",
      " 4   genres   3405 non-null   object \n",
      " 5   userId   3405 non-null   int64  \n",
      " 6   rating   3405 non-null   float64\n",
      " 7   tag      3405 non-null   object \n",
      "dtypes: float64(2), int64(3), object(3)\n",
      "memory usage: 212.9+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>imdbId</th>\n",
       "      <th>tmdbId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>userId</th>\n",
       "      <th>rating</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>114709</td>\n",
       "      <td>862.0</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "      <td>336</td>\n",
       "      <td>4.0</td>\n",
       "      <td>pixar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>114709</td>\n",
       "      <td>862.0</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "      <td>474</td>\n",
       "      <td>4.0</td>\n",
       "      <td>pixar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>114709</td>\n",
       "      <td>862.0</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "      <td>567</td>\n",
       "      <td>3.5</td>\n",
       "      <td>fun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>113497</td>\n",
       "      <td>8844.0</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "      <td>62</td>\n",
       "      <td>4.0</td>\n",
       "      <td>fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>113497</td>\n",
       "      <td>8844.0</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "      <td>62</td>\n",
       "      <td>4.0</td>\n",
       "      <td>magic board game</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId  imdbId  tmdbId             title  \\\n",
       "0        1  114709   862.0  Toy Story (1995)   \n",
       "1        1  114709   862.0  Toy Story (1995)   \n",
       "2        1  114709   862.0  Toy Story (1995)   \n",
       "3        2  113497  8844.0    Jumanji (1995)   \n",
       "4        2  113497  8844.0    Jumanji (1995)   \n",
       "\n",
       "                                        genres  userId  rating  \\\n",
       "0  Adventure|Animation|Children|Comedy|Fantasy     336     4.0   \n",
       "1  Adventure|Animation|Children|Comedy|Fantasy     474     4.0   \n",
       "2  Adventure|Animation|Children|Comedy|Fantasy     567     3.5   \n",
       "3                   Adventure|Children|Fantasy      62     4.0   \n",
       "4                   Adventure|Children|Fantasy      62     4.0   \n",
       "\n",
       "                tag  \n",
       "0             pixar  \n",
       "1             pixar  \n",
       "2               fun  \n",
       "3           fantasy  \n",
       "4  magic board game  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# get statistic and first few data of NUM_SAMPLES rows\n",
    "data.info()\n",
    "data.head(NUM_EXAMPLES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "MOVIELENS_CONTENT_SYSTEM = \"MovieLens movies critic\"\n",
    "\n",
    "@retry_decorator\n",
    "def predict_rating_combined_ChatCompletion(combined_text, \n",
    "                                           model=GPT_MODEL_NAME, \n",
    "                                           temperature=TEMPERATURE, \n",
    "                                           approach=\"zero-shot\", \n",
    "                                           rating_history=None, \n",
    "                                           similar_users_ratings=None, \n",
    "                                           seed=RANDOM_STATE, \n",
    "                                           system_content=MOVIELENS_CONTENT_SYSTEM):\n",
    "    \"\"\"\n",
    "    Predicts product ratings using different approaches with the GPT model.\n",
    "    \"\"\"\n",
    "    # Validation\n",
    "    if approach == \"few-shot\" and rating_history is None:\n",
    "        raise ValueError(\"Rating history is required for the few-shot approach.\")\n",
    "    if approach == \"CF\" and similar_users_ratings is None:\n",
    "        raise ValueError(\"Similar users' ratings are required for the collaborative filtering approach.\")\n",
    "    if not system_content:\n",
    "        raise ValueError(\"System content is required.\")\n",
    "\n",
    "    # Check and reduce length of combined_text\n",
    "    combined_text = check_and_reduce_length(combined_text, MAX_TOKENS_CHAT_GPT // 3, TOKENIZER)\n",
    "    prompt = f\"How will user rate this {combined_text}? (1 being lowest and 5 being highest) Attention! Just give me back the exact number as a result, and you don't need a lot of text.\"\n",
    "\n",
    "    # Construct the prompt based on the approach\n",
    "    if approach == \"few-shot\":\n",
    "        rating_history = check_and_reduce_length(rating_history, MAX_TOKENS_CHAT_GPT // 3, TOKENIZER)\n",
    "        prompt += f\"\\n\\nHere is user rating history:\\n{rating_history}\"\n",
    "\n",
    "    elif approach == \"CF\":\n",
    "        similar_users_ratings = check_and_reduce_length(similar_users_ratings, MAX_TOKENS_CHAT_GPT // 3, TOKENIZER)\n",
    "        prompt += f\"\\n\\nHere are the rating history from users who are similar to this user:\\n{similar_users_ratings}\"\n",
    "\n",
    "    # Adding end of the prompt\n",
    "    prompt += \"\\n\\nBased on the above information, please predict user's rating for the product: (1 being lowest and 5 being highest, The output should be like: (x stars, xx%), do not explain the reason.)\"\n",
    "\n",
    "    print(f\"Constructed Prompt for {approach} approach:\\n\")\n",
    "    # meaningful print for prompt\n",
    "    print(f'The prompt:\\n**********\\n{prompt}\\n**********\\n')\n",
    "\n",
    "    try:\n",
    "        # Create the API call\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=model,\n",
    "            temperature=temperature,\n",
    "            max_tokens=MAX_TOKENS_CHAT_GPT,\n",
    "            seed=seed,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_content},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred during API call: {e}\")\n",
    "        return None, str(e)  # Include the error message with the response\n",
    "\n",
    "    # Extract the system fingerprint and print it\n",
    "    system_fingerprint = response.get('system_fingerprint')\n",
    "    print(f\"\\n\\nSystem Fingerprint: {system_fingerprint}\")\n",
    "\n",
    "    # Extract and return the rating\n",
    "    rating_text = response.choices[0].message['content'].strip()\n",
    "    print(f'\\nAPI call response: \"{rating_text}\"')\n",
    "    extracted_rating = extract_numeric_rating(rating_text)\n",
    "    return extracted_rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero-shot (OpenAI API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructed Prompt for zero-shot approach:\n",
      "\n",
      "The prompt:\n",
      "**********\n",
      "How will user rate this title: Toy Story (1995)? (1 being lowest and 5 being highest) Attention! Just give me back the exact number as a result, and you don't need a lot of text.\n",
      "\n",
      "Based on the above information, please predict user's rating for the product: (1 being lowest and 5 being highest, The output should be like: (x stars, xx%), do not explain the reason.)\n",
      "**********\n",
      "\n",
      "\n",
      "\n",
      "System Fingerprint: fp_eeff13170a\n",
      "\n",
      "API call response: \"5\"\n",
      "Processing item 1/3405\n",
      "\n",
      "Details: Toy Story (1995)\n",
      "\n",
      "Predicted Rating: 5.0 stars\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "Constructed Prompt for zero-shot approach:\n",
      "\n",
      "The prompt:\n",
      "**********\n",
      "How will user rate this title: Toy Story (1995)? (1 being lowest and 5 being highest) Attention! Just give me back the exact number as a result, and you don't need a lot of text.\n",
      "\n",
      "Based on the above information, please predict user's rating for the product: (1 being lowest and 5 being highest, The output should be like: (x stars, xx%), do not explain the reason.)\n",
      "**********\n",
      "\n",
      "\n",
      "\n",
      "System Fingerprint: fp_eeff13170a\n",
      "\n",
      "API call response: \"5\"\n",
      "Processing item 2/3405\n",
      "\n",
      "Details: Toy Story (1995)\n",
      "\n",
      "Predicted Rating: 5.0 stars\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "Constructed Prompt for zero-shot approach:\n",
      "\n",
      "The prompt:\n",
      "**********\n",
      "How will user rate this title: Toy Story (1995)? (1 being lowest and 5 being highest) Attention! Just give me back the exact number as a result, and you don't need a lot of text.\n",
      "\n",
      "Based on the above information, please predict user's rating for the product: (1 being lowest and 5 being highest, The output should be like: (x stars, xx%), do not explain the reason.)\n",
      "**********\n",
      "\n",
      "\n",
      "\n",
      "System Fingerprint: fp_eeff13170a\n",
      "\n",
      "API call response: \"5\"\n",
      "Processing item 3/3405\n",
      "\n",
      "Details: Toy Story (1995)\n",
      "\n",
      "Predicted Rating: 5.0 stars\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "Constructed Prompt for zero-shot approach:\n",
      "\n",
      "The prompt:\n",
      "**********\n",
      "How will user rate this title: Jumanji (1995)? (1 being lowest and 5 being highest) Attention! Just give me back the exact number as a result, and you don't need a lot of text.\n",
      "\n",
      "Based on the above information, please predict user's rating for the product: (1 being lowest and 5 being highest, The output should be like: (x stars, xx%), do not explain the reason.)\n",
      "**********\n",
      "\n",
      "\n",
      "\n",
      "System Fingerprint: fp_eeff13170a\n",
      "\n",
      "API call response: \"4\"\n",
      "Processing item 4/3405\n",
      "\n",
      "Details: Jumanji (1995)\n",
      "\n",
      "Predicted Rating: 4.0 stars\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "Constructed Prompt for zero-shot approach:\n",
      "\n",
      "The prompt:\n",
      "**********\n",
      "How will user rate this title: Jumanji (1995)? (1 being lowest and 5 being highest) Attention! Just give me back the exact number as a result, and you don't need a lot of text.\n",
      "\n",
      "Based on the above information, please predict user's rating for the product: (1 being lowest and 5 being highest, The output should be like: (x stars, xx%), do not explain the reason.)\n",
      "**********\n",
      "\n",
      "Error occurred during API call: Rate limit reached for gpt-3.5-turbo-1106 in organization org-ppCCXZWpTaByE4cI4jMbZjBx on tokens per min (TPM): Limit 40000, Used 37267, Requested 4096. Please try again in 2.044s. Visit https://platform.openai.com/account/rate-limits to learn more.\n",
      "Processing item 5/3405\n",
      "\n",
      "Details: Jumanji (1995)\n",
      "\n",
      "Predicted Rating: (None, 'Rate limit reached for gpt-3.5-turbo-1106 in organization org-ppCCXZWpTaByE4cI4jMbZjBx on tokens per min (TPM): Limit 40000, Used 37267, Requested 4096. Please try again in 2.044s. Visit https://platform.openai.com/account/rate-limits to learn more.') stars\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "Constructed Prompt for zero-shot approach:\n",
      "\n",
      "The prompt:\n",
      "**********\n",
      "How will user rate this title: Jumanji (1995)? (1 being lowest and 5 being highest) Attention! Just give me back the exact number as a result, and you don't need a lot of text.\n",
      "\n",
      "Based on the above information, please predict user's rating for the product: (1 being lowest and 5 being highest, The output should be like: (x stars, xx%), do not explain the reason.)\n",
      "**********\n",
      "\n",
      "Error occurred during API call: Rate limit reached for gpt-3.5-turbo-1106 in organization org-ppCCXZWpTaByE4cI4jMbZjBx on tokens per min (TPM): Limit 40000, Used 37081, Requested 4096. Please try again in 1.765s. Visit https://platform.openai.com/account/rate-limits to learn more.\n",
      "Processing item 6/3405\n",
      "\n",
      "Details: Jumanji (1995)\n",
      "\n",
      "Predicted Rating: (None, 'Rate limit reached for gpt-3.5-turbo-1106 in organization org-ppCCXZWpTaByE4cI4jMbZjBx on tokens per min (TPM): Limit 40000, Used 37081, Requested 4096. Please try again in 1.765s. Visit https://platform.openai.com/account/rate-limits to learn more.') stars\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "Constructed Prompt for zero-shot approach:\n",
      "\n",
      "The prompt:\n",
      "**********\n",
      "How will user rate this title: Jumanji (1995)? (1 being lowest and 5 being highest) Attention! Just give me back the exact number as a result, and you don't need a lot of text.\n",
      "\n",
      "Based on the above information, please predict user's rating for the product: (1 being lowest and 5 being highest, The output should be like: (x stars, xx%), do not explain the reason.)\n",
      "**********\n",
      "\n",
      "Error occurred during API call: Rate limit reached for gpt-3.5-turbo-1106 in organization org-ppCCXZWpTaByE4cI4jMbZjBx on tokens per min (TPM): Limit 40000, Used 36926, Requested 4096. Please try again in 1.533s. Visit https://platform.openai.com/account/rate-limits to learn more.\n",
      "Processing item 7/3405\n",
      "\n",
      "Details: Jumanji (1995)\n",
      "\n",
      "Predicted Rating: (None, 'Rate limit reached for gpt-3.5-turbo-1106 in organization org-ppCCXZWpTaByE4cI4jMbZjBx on tokens per min (TPM): Limit 40000, Used 36926, Requested 4096. Please try again in 1.533s. Visit https://platform.openai.com/account/rate-limits to learn more.') stars\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "Constructed Prompt for zero-shot approach:\n",
      "\n",
      "The prompt:\n",
      "**********\n",
      "How will user rate this title: Father of the Bride Part II (1995)? (1 being lowest and 5 being highest) Attention! Just give me back the exact number as a result, and you don't need a lot of text.\n",
      "\n",
      "Based on the above information, please predict user's rating for the product: (1 being lowest and 5 being highest, The output should be like: (x stars, xx%), do not explain the reason.)\n",
      "**********\n",
      "\n",
      "Error occurred during API call: Rate limit reached for gpt-3.5-turbo-1106 in organization org-ppCCXZWpTaByE4cI4jMbZjBx on tokens per min (TPM): Limit 40000, Used 36743, Requested 4096. Please try again in 1.258s. Visit https://platform.openai.com/account/rate-limits to learn more.\n",
      "Processing item 8/3405\n",
      "\n",
      "Details: Father of the Bride Part II (1995)\n",
      "\n",
      "Predicted Rating: (None, 'Rate limit reached for gpt-3.5-turbo-1106 in organization org-ppCCXZWpTaByE4cI4jMbZjBx on tokens per min (TPM): Limit 40000, Used 36743, Requested 4096. Please try again in 1.258s. Visit https://platform.openai.com/account/rate-limits to learn more.') stars\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "Constructed Prompt for zero-shot approach:\n",
      "\n",
      "The prompt:\n",
      "**********\n",
      "How will user rate this title: Father of the Bride Part II (1995)? (1 being lowest and 5 being highest) Attention! Just give me back the exact number as a result, and you don't need a lot of text.\n",
      "\n",
      "Based on the above information, please predict user's rating for the product: (1 being lowest and 5 being highest, The output should be like: (x stars, xx%), do not explain the reason.)\n",
      "**********\n",
      "\n",
      "Error occurred during API call: Rate limit reached for gpt-3.5-turbo-1106 in organization org-ppCCXZWpTaByE4cI4jMbZjBx on tokens per min (TPM): Limit 40000, Used 36536, Requested 4096. Please try again in 948ms. Visit https://platform.openai.com/account/rate-limits to learn more.\n",
      "Processing item 9/3405\n",
      "\n",
      "Details: Father of the Bride Part II (1995)\n",
      "\n",
      "Predicted Rating: (None, 'Rate limit reached for gpt-3.5-turbo-1106 in organization org-ppCCXZWpTaByE4cI4jMbZjBx on tokens per min (TPM): Limit 40000, Used 36536, Requested 4096. Please try again in 948ms. Visit https://platform.openai.com/account/rate-limits to learn more.') stars\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "Constructed Prompt for zero-shot approach:\n",
      "\n",
      "The prompt:\n",
      "**********\n",
      "How will user rate this title: Sabrina (1995)? (1 being lowest and 5 being highest) Attention! Just give me back the exact number as a result, and you don't need a lot of text.\n",
      "\n",
      "Based on the above information, please predict user's rating for the product: (1 being lowest and 5 being highest, The output should be like: (x stars, xx%), do not explain the reason.)\n",
      "**********\n",
      "\n",
      "Error occurred during API call: Rate limit reached for gpt-3.5-turbo-1106 in organization org-ppCCXZWpTaByE4cI4jMbZjBx on tokens per min (TPM): Limit 40000, Used 36404, Requested 4096. Please try again in 750ms. Visit https://platform.openai.com/account/rate-limits to learn more.\n",
      "Processing item 10/3405\n",
      "\n",
      "Details: Sabrina (1995)\n",
      "\n",
      "Predicted Rating: (None, 'Rate limit reached for gpt-3.5-turbo-1106 in organization org-ppCCXZWpTaByE4cI4jMbZjBx on tokens per min (TPM): Limit 40000, Used 36404, Requested 4096. Please try again in 750ms. Visit https://platform.openai.com/account/rate-limits to learn more.') stars\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "Pausing for 60 seconds...\n",
      "Constructed Prompt for zero-shot approach:\n",
      "\n",
      "The prompt:\n",
      "**********\n",
      "How will user rate this title: American President, The (1995)? (1 being lowest and 5 being highest) Attention! Just give me back the exact number as a result, and you don't need a lot of text.\n",
      "\n",
      "Based on the above information, please predict user's rating for the product: (1 being lowest and 5 being highest, The output should be like: (x stars, xx%), do not explain the reason.)\n",
      "**********\n",
      "\n",
      "\n",
      "\n",
      "System Fingerprint: fp_eeff13170a\n",
      "\n",
      "API call response: \"4\"\n",
      "Processing item 11/3405\n",
      "\n",
      "Details: American President, The (1995)\n",
      "\n",
      "Predicted Rating: 4.0 stars\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "Constructed Prompt for zero-shot approach:\n",
      "\n",
      "The prompt:\n",
      "**********\n",
      "How will user rate this title: American President, The (1995)? (1 being lowest and 5 being highest) Attention! Just give me back the exact number as a result, and you don't need a lot of text.\n",
      "\n",
      "Based on the above information, please predict user's rating for the product: (1 being lowest and 5 being highest, The output should be like: (x stars, xx%), do not explain the reason.)\n",
      "**********\n",
      "\n",
      "\n",
      "\n",
      "System Fingerprint: fp_eeff13170a\n",
      "\n",
      "API call response: \"4\"\n",
      "Processing item 12/3405\n",
      "\n",
      "Details: American President, The (1995)\n",
      "\n",
      "Predicted Rating: 4.0 stars\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "Constructed Prompt for zero-shot approach:\n",
      "\n",
      "The prompt:\n",
      "**********\n",
      "How will user rate this title: Nixon (1995)? (1 being lowest and 5 being highest) Attention! Just give me back the exact number as a result, and you don't need a lot of text.\n",
      "\n",
      "Based on the above information, please predict user's rating for the product: (1 being lowest and 5 being highest, The output should be like: (x stars, xx%), do not explain the reason.)\n",
      "**********\n",
      "\n",
      "\n",
      "\n",
      "System Fingerprint: fp_eeff13170a\n",
      "\n",
      "API call response: \"4\"\n",
      "Processing item 13/3405\n",
      "\n",
      "Details: Nixon (1995)\n",
      "\n",
      "Predicted Rating: 4.0 stars\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "Constructed Prompt for zero-shot approach:\n",
      "\n",
      "The prompt:\n",
      "**********\n",
      "How will user rate this title: Nixon (1995)? (1 being lowest and 5 being highest) Attention! Just give me back the exact number as a result, and you don't need a lot of text.\n",
      "\n",
      "Based on the above information, please predict user's rating for the product: (1 being lowest and 5 being highest, The output should be like: (x stars, xx%), do not explain the reason.)\n",
      "**********\n",
      "\n",
      "\n",
      "\n",
      "System Fingerprint: fp_eeff13170a\n",
      "\n",
      "API call response: \"4\"\n",
      "Processing item 14/3405\n",
      "\n",
      "Details: Nixon (1995)\n",
      "\n",
      "Predicted Rating: 4.0 stars\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "Constructed Prompt for zero-shot approach:\n",
      "\n",
      "The prompt:\n",
      "**********\n",
      "How will user rate this title: Casino (1995)? (1 being lowest and 5 being highest) Attention! Just give me back the exact number as a result, and you don't need a lot of text.\n",
      "\n",
      "Based on the above information, please predict user's rating for the product: (1 being lowest and 5 being highest, The output should be like: (x stars, xx%), do not explain the reason.)\n",
      "**********\n",
      "\n",
      "Error occurred during API call: Rate limit reached for gpt-3.5-turbo-1106 in organization org-ppCCXZWpTaByE4cI4jMbZjBx on tokens per min (TPM): Limit 40000, Used 36229, Requested 4096. Please try again in 487ms. Visit https://platform.openai.com/account/rate-limits to learn more.\n",
      "Processing item 15/3405\n",
      "\n",
      "Details: Casino (1995)\n",
      "\n",
      "Predicted Rating: (None, 'Rate limit reached for gpt-3.5-turbo-1106 in organization org-ppCCXZWpTaByE4cI4jMbZjBx on tokens per min (TPM): Limit 40000, Used 36229, Requested 4096. Please try again in 487ms. Visit https://platform.openai.com/account/rate-limits to learn more.') stars\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "Constructed Prompt for zero-shot approach:\n",
      "\n",
      "The prompt:\n",
      "**********\n",
      "How will user rate this title: Sense and Sensibility (1995)? (1 being lowest and 5 being highest) Attention! Just give me back the exact number as a result, and you don't need a lot of text.\n",
      "\n",
      "Based on the above information, please predict user's rating for the product: (1 being lowest and 5 being highest, The output should be like: (x stars, xx%), do not explain the reason.)\n",
      "**********\n",
      "\n",
      "Error occurred during API call: Rate limit reached for gpt-3.5-turbo-1106 in organization org-ppCCXZWpTaByE4cI4jMbZjBx on tokens per min (TPM): Limit 40000, Used 36083, Requested 4096. Please try again in 268ms. Visit https://platform.openai.com/account/rate-limits to learn more.\n",
      "Processing item 16/3405\n",
      "\n",
      "Details: Sense and Sensibility (1995)\n",
      "\n",
      "Predicted Rating: (None, 'Rate limit reached for gpt-3.5-turbo-1106 in organization org-ppCCXZWpTaByE4cI4jMbZjBx on tokens per min (TPM): Limit 40000, Used 36083, Requested 4096. Please try again in 268ms. Visit https://platform.openai.com/account/rate-limits to learn more.') stars\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "Constructed Prompt for zero-shot approach:\n",
      "\n",
      "The prompt:\n",
      "**********\n",
      "How will user rate this title: Get Shorty (1995)? (1 being lowest and 5 being highest) Attention! Just give me back the exact number as a result, and you don't need a lot of text.\n",
      "\n",
      "Based on the above information, please predict user's rating for the product: (1 being lowest and 5 being highest, The output should be like: (x stars, xx%), do not explain the reason.)\n",
      "**********\n",
      "\n",
      "Error occurred during API call: Rate limit reached for gpt-3.5-turbo-1106 in organization org-ppCCXZWpTaByE4cI4jMbZjBx on tokens per min (TPM): Limit 40000, Used 35927, Requested 4096. Please try again in 34ms. Visit https://platform.openai.com/account/rate-limits to learn more.\n",
      "Processing item 17/3405\n",
      "\n",
      "Details: Get Shorty (1995)\n",
      "\n",
      "Predicted Rating: (None, 'Rate limit reached for gpt-3.5-turbo-1106 in organization org-ppCCXZWpTaByE4cI4jMbZjBx on tokens per min (TPM): Limit 40000, Used 35927, Requested 4096. Please try again in 34ms. Visit https://platform.openai.com/account/rate-limits to learn more.') stars\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "Constructed Prompt for zero-shot approach:\n",
      "\n",
      "The prompt:\n",
      "**********\n",
      "How will user rate this title: Copycat (1995)? (1 being lowest and 5 being highest) Attention! Just give me back the exact number as a result, and you don't need a lot of text.\n",
      "\n",
      "Based on the above information, please predict user's rating for the product: (1 being lowest and 5 being highest, The output should be like: (x stars, xx%), do not explain the reason.)\n",
      "**********\n",
      "\n",
      "\n",
      "\n",
      "System Fingerprint: fp_eeff13170a\n",
      "\n",
      "API call response: \"The user will rate \"Copycat (1995)\" as 4.\"\n",
      "No valid rating found in the response: The user will rate \"Copycat (1995)\" as 4.\n",
      "Processing item 18/3405\n",
      "\n",
      "Details: Copycat (1995)\n",
      "\n",
      "Predicted Rating: 0 stars\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "Constructed Prompt for zero-shot approach:\n",
      "\n",
      "The prompt:\n",
      "**********\n",
      "How will user rate this title: Leaving Las Vegas (1995)? (1 being lowest and 5 being highest) Attention! Just give me back the exact number as a result, and you don't need a lot of text.\n",
      "\n",
      "Based on the above information, please predict user's rating for the product: (1 being lowest and 5 being highest, The output should be like: (x stars, xx%), do not explain the reason.)\n",
      "**********\n",
      "\n",
      "Error occurred during API call: Rate limit reached for gpt-3.5-turbo-1106 in organization org-ppCCXZWpTaByE4cI4jMbZjBx on tokens per min (TPM): Limit 40000, Used 39490, Requested 4096. Please try again in 5.379s. Visit https://platform.openai.com/account/rate-limits to learn more.\n",
      "Processing item 19/3405\n",
      "\n",
      "Details: Leaving Las Vegas (1995)\n",
      "\n",
      "Predicted Rating: (None, 'Rate limit reached for gpt-3.5-turbo-1106 in organization org-ppCCXZWpTaByE4cI4jMbZjBx on tokens per min (TPM): Limit 40000, Used 39490, Requested 4096. Please try again in 5.379s. Visit https://platform.openai.com/account/rate-limits to learn more.') stars\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "Constructed Prompt for zero-shot approach:\n",
      "\n",
      "The prompt:\n",
      "**********\n",
      "How will user rate this title: Othello (1995)? (1 being lowest and 5 being highest) Attention! Just give me back the exact number as a result, and you don't need a lot of text.\n",
      "\n",
      "Based on the above information, please predict user's rating for the product: (1 being lowest and 5 being highest, The output should be like: (x stars, xx%), do not explain the reason.)\n",
      "**********\n",
      "\n",
      "Error occurred during API call: Rate limit reached for gpt-3.5-turbo-1106 in organization org-ppCCXZWpTaByE4cI4jMbZjBx on tokens per min (TPM): Limit 40000, Used 39336, Requested 4096. Please try again in 5.148s. Visit https://platform.openai.com/account/rate-limits to learn more.\n",
      "Processing item 20/3405\n",
      "\n",
      "Details: Othello (1995)\n",
      "\n",
      "Predicted Rating: (None, 'Rate limit reached for gpt-3.5-turbo-1106 in organization org-ppCCXZWpTaByE4cI4jMbZjBx on tokens per min (TPM): Limit 40000, Used 39336, Requested 4096. Please try again in 5.148s. Visit https://platform.openai.com/account/rate-limits to learn more.') stars\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "Pausing for 60 seconds...\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "predict_ratings_zero_shot_and_save(data,\n",
    "                                       columns_for_prediction=['title'],\n",
    "                                       user_column_name='userId',\n",
    "                                       pause_every_n_users=PAUSE_EVERY_N_USERS,\n",
    "                                       sleep_time=SLEEP_TIME,\n",
    "                                       save_path=ZERO_SHOT_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_predictions_rmse_mae(data_path, num_examples, actual_ratings_column, predicted_ratings_column):\n",
    "    \"\"\"\n",
    "    Evaluate model predictions with RMSE and MAE, and display a few prediction results.\n",
    "\n",
    "    Parameters:\n",
    "    - data_path (str): Path to the CSV file containing the model's predictions.\n",
    "    - num_examples (int): Number of examples to show for debugging purposes.\n",
    "    - actual_ratings_column (str): Name of the column in the CSV file containing actual ratings.\n",
    "    - predicted_ratings_column (str): Name of the column in the CSV file containing predicted ratings.\n",
    "    \"\"\"\n",
    "    # Read the data from the CSV file\n",
    "    data = pd.read_csv(data_path)\n",
    "\n",
    "    # Process predicted ratings to extract valid numerical values\n",
    "    data[predicted_ratings_column] = data[predicted_ratings_column].apply(lambda x: x if isinstance(x, float) else None)\n",
    "\n",
    "    # Extract the actual and predicted ratings\n",
    "    actual_ratings = data[actual_ratings_column].tolist()\n",
    "    predicted_ratings = data[predicted_ratings_column].tolist()\n",
    "\n",
    "    # Filter out invalid (None) predictions\n",
    "    filtered_ratings = [(actual, predicted) for actual, predicted in zip(actual_ratings, predicted_ratings) if predicted is not None]\n",
    "    \n",
    "    # Check if there are valid predictions for evaluation\n",
    "    if not filtered_ratings:\n",
    "        print(\"No valid predictions available for evaluation.\")\n",
    "        return\n",
    "\n",
    "    # Unpack the filtered actual and predicted ratings\n",
    "    actual_filtered, predicted_filtered = zip(*filtered_ratings)\n",
    "\n",
    "    # Calculate RMSE and MAE using the custom function\n",
    "    rmse, mae = calculate_rmse_and_mae(actual_filtered, predicted_filtered)\n",
    "\n",
    "    # Output the evaluation results\n",
    "    print(f'RMSE: {rmse}')\n",
    "    print(f'MAE: {mae}')\n",
    "\n",
    "    # Display the first few actual vs. predicted ratings for debugging\n",
    "    print(\"\\nFirst few actual vs predicted ratings:\")\n",
    "    for actual, predicted in actual_vs_predicted[:num_examples]:\n",
    "        print(f\"Actual: {actual}, Predicted: {predicted}\")\n",
    "\n",
    "evaluate_model_predictions_rmse_mae(\n",
    "    data_path=ZERO_SHOT_SAVE_PATH,\n",
    "    num_examples=NUM_EXAMPLES,\n",
    "    actual_ratings_column='rating',\n",
    "    predicted_ratings_column='zero_shot_predicted_rating'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Few-shot (OpenAI API)\n",
    "\n",
    "\n",
    "+ For each user, we'll use 4 of their ratings as training data to predict ratings for the rest of their products. Finally, we'll evaluate the predictions against the actual ratings to calculate the overall RMSE and MAE.\n",
    "\n",
    "+ The rating_history_str now includes both the title and the review text for each of the training data rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 observation per reviewer - Few-shot OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "predict_ratings_few_shot_and_save(data,\n",
    "                                      columns_for_training=['title'],\n",
    "                                       columns_for_prediction=['title'],\n",
    "                                       user_column_name='userId',\n",
    "                                       obs_per_user=1,\n",
    "                                       pause_every_n_users=PAUSE_EVERY_N_USERS,\n",
    "                                       sleep_time=SLEEP_TIME,\n",
    "                                       save_path=FEW_SHOT_1_OBS_SAVE_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model_predictions_rmse_mae(\n",
    "    data_path=FEW_SHOT_1_OBS_SAVE_PATH,\n",
    "    num_examples=NUM_EXAMPLES,\n",
    "    actual_ratings_column='actual_rating',\n",
    "    predicted_ratings_column='few_shot_predicted_rating'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limitations:\n",
    "\n",
    "The model might not fully understand the nuanced relationships between products based on titles alone. Additional context or features might be needed for more accurate predictions.\n",
    "This approach might be computationally expensive and slower than traditional matrix factorization or deep learning-based recommendation models, especially for a large number of users.\n",
    "\n",
    "# References\n",
    "\n",
    "+ https://platform.openai.com/docs/api-reference/authentication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Advanced_Programming_for_Data_Science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
