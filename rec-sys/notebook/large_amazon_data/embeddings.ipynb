{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "current directory: /Users/tnathu-ai/VSCode/recommender-system/recommender-system-openAI/rec-sys/data/amazon-beauty\n",
      "embedding model current directory: /Users/tnathu-ai/VSCode/recommender-system/recommender-system-openAI/rec-sys/models/embedding\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import openai\n",
    "import numpy as np\n",
    "from openai.embeddings_utils import (\n",
    "    get_embedding,\n",
    "    distances_from_embeddings,\n",
    "    tsne_components_from_embeddings,\n",
    "    chart_from_components,\n",
    "    indices_of_nearest_neighbors_from_distances,\n",
    ")\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Add the path to the constants file to the system path\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "from constants import (\n",
    "    RANDOM_STATE, \n",
    "    OPENAI_API_KEY,\n",
    "    EMBEDDING_MODEL\n",
    ")\n",
    "# OpenAI API Key\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "# Get the current directory of the notebook\n",
    "current_dir = os.path.dirname(os.path.abspath(\"../../data/amazon-beauty/parse_and_clean_meta_data.ipynb\"))\n",
    "# # Get the current directory of the notebook\n",
    "embedding_model_current_dir = os.path.dirname(os.path.abspath(\"../../models/embedding/parse_and_clean_meta_data.ipynb\"))\n",
    "print(f\"current directory: {current_dir}\")\n",
    "print(f\"embedding model current directory: {embedding_model_current_dir}\")\n",
    "\n",
    "n_examples = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data path: /Users/tnathu-ai/VSCode/recommender-system/recommender-system-openAI/rec-sys/data/amazon-beauty/large_merged_data.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>category</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>A2RYSCZOPEXOCQ</td>\n",
       "      <td>9790787006</td>\n",
       "      <td>I use a lot of perfume, I go through a new bot...</td>\n",
       "      <td>This is not going to be my favorite scent.</td>\n",
       "      <td>[]</td>\n",
       "      <td>Jenna Jameson Heartbreaker Perfume for women 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>A141OPVE376YFI</td>\n",
       "      <td>B000050B65</td>\n",
       "      <td>First, a little background.  I've switched bet...</td>\n",
       "      <td>Finally, a razor that lives up to the ads</td>\n",
       "      <td>[]</td>\n",
       "      <td>Norelco 6885XL Deluxe Quadra Action Cord/Cordl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>A141OPVE376YFI</td>\n",
       "      <td>B000050B65</td>\n",
       "      <td>First, a little background.  I've switched bet...</td>\n",
       "      <td>Finally, a razor that lives up to the ads</td>\n",
       "      <td>[]</td>\n",
       "      <td>Norelco 6885XL Deluxe Quadra Action Cord/Cordl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>A1TVTDKNMSQ7XU</td>\n",
       "      <td>B000050B6B</td>\n",
       "      <td>I've had many Norelco razors in my 50 years of...</td>\n",
       "      <td>Just like new.....</td>\n",
       "      <td>[]</td>\n",
       "      <td>Philips Norelco HQ5 Shaving Heads</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>A1TVTDKNMSQ7XU</td>\n",
       "      <td>B000050B6B</td>\n",
       "      <td>I've had many Norelco razors in my 50 years of...</td>\n",
       "      <td>Just like new.....</td>\n",
       "      <td>[]</td>\n",
       "      <td>Philips Norelco HQ5 Shaving Heads</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating      reviewerID        asin  \\\n",
       "0     1.0  A2RYSCZOPEXOCQ  9790787006   \n",
       "1     5.0  A141OPVE376YFI  B000050B65   \n",
       "2     5.0  A141OPVE376YFI  B000050B65   \n",
       "3     5.0  A1TVTDKNMSQ7XU  B000050B6B   \n",
       "4     5.0  A1TVTDKNMSQ7XU  B000050B6B   \n",
       "\n",
       "                                          reviewText  \\\n",
       "0  I use a lot of perfume, I go through a new bot...   \n",
       "1  First, a little background.  I've switched bet...   \n",
       "2  First, a little background.  I've switched bet...   \n",
       "3  I've had many Norelco razors in my 50 years of...   \n",
       "4  I've had many Norelco razors in my 50 years of...   \n",
       "\n",
       "                                      summary category  \\\n",
       "0  This is not going to be my favorite scent.       []   \n",
       "1   Finally, a razor that lives up to the ads       []   \n",
       "2   Finally, a razor that lives up to the ads       []   \n",
       "3                          Just like new.....       []   \n",
       "4                          Just like new.....       []   \n",
       "\n",
       "                                               title  \n",
       "0  Jenna Jameson Heartbreaker Perfume for women 3...  \n",
       "1  Norelco 6885XL Deluxe Quadra Action Cord/Cordl...  \n",
       "2  Norelco 6885XL Deluxe Quadra Action Cord/Cordl...  \n",
       "3                  Philips Norelco HQ5 Shaving Heads  \n",
       "4                  Philips Norelco HQ5 Shaving Heads  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct the path to data file\n",
    "data_path = os.path.join(current_dir, 'large_merged_data.csv')\n",
    "print(f'data path: {data_path}')\n",
    "# load data (full dataset available at http://groups.di.unipi.it/~gulli/AG_corpus_of_news_products.html)\n",
    "dataset_path = data_path\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "df.head(n_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Title: Jenna Jameson Heartbreaker Perfume for women 3.4 oz Eau De Parfum Spray\n",
      "Review: I use a lot of perfume, I go through a new bottle every couple of weeks, and I never bought the same scent twice. I`m still looking for my favorite scent. This is not going to be it. I`m going to use it, but definitely not purchase again. Someone else may like it, it just does not lure my scents. Bottle is a very pretty, red glass, and it smells classier, than the name suggests.\n",
      "\n",
      "I got this for evaluation, 50% off, in order that I might provide this review.\n",
      "\n",
      "* I originally gave this 3 stars, but as I tried to use this further, I found the smell being just completely wrong. I asked three friends separately, what they think of it, and each one said, that this smells manly. And that was the exact word I was looking for. First two girls did not want to take this from me for free, the third one took it, but stated that really just a little at a time can be used. I downgraded this to 1 star, as it was in fact unusable and I wasted money on it. All four of us are in our early to late twenties and none of us liked this perfume. This is the only one 1 star review I ever wrote.\n",
      "Rating: 1.0\n",
      "\n",
      "Title: Norelco 6885XL Deluxe Quadra Action Cord/Cordless Rechargeable Men's Shaver\n",
      "Review: First, a little background.  I've switched between Norelco electric razors and blades over the years, never quite satisfied with the shave I was getting.  Norelco has always said \"shaves as close as a blade or your money back\".  I've never found this to be true, but the razors were good enough that I didn't return them.  Most recently I used the Gilette Mach 3 razor which does a very good job.\n",
      "Now here's why I give the 6885XL (6886XL is apparently the same model, sold at Costco and other warehouse stores) 5 stars:\n",
      "- Closest shave yet.  This is the first electric razor I've used that shaves as close as a blade (including the Mach 3).  In fact, it shaves closer than a blade under my jaw and around my adam's apple.  I can't shave against the grain with a blade in those areas or my skin breaks out (and that's the only way to get the closest shave.)  With the 6885XL I don't have this problem and I get a really close shave.\n",
      "- It's quiet.  Previous electric razors were so noisy I had to shave in another bathroom so I wouldn't wake my wife.  Not so with this one.\n",
      "- Easy to clean.  Open the top and run hot water through it.  No more brushes (except for periodic maintenance).  An indicator will tell you when it's time to clean.\n",
      "Other features:\n",
      "- Charge remaining (in minutes) display.  This isn't particularly useful to me, but it seems reasonable accurate.\n",
      "- It comes with a stand that holds the razor upright on the counter or basin.  Much neater than the razor just laying around or stuffed in a cabinet.\n",
      "- Hard carrying case, for travel.\n",
      "- Automatically adjusts to different voltages.\n",
      "My wife about had a heart attack when I bought it.  However, it gives me the best shave ever (electric or blades).\n",
      "Rating: 5.0\n",
      "\n",
      "Title: Norelco 6885XL Deluxe Quadra Action Cord/Cordless Rechargeable Men's Shaver\n",
      "Review: First, a little background.  I've switched between Norelco electric razors and blades over the years, never quite satisfied with the shave I was getting.  Norelco has always said \"shaves as close as a blade or your money back\".  I've never found this to be true, but the razors were good enough that I didn't return them.  Most recently I used the Gilette Mach 3 razor which does a very good job.\n",
      "Now here's why I give the 6885XL (6886XL is apparently the same model, sold at Costco and other warehouse stores) 5 stars:\n",
      "- Closest shave yet.  This is the first electric razor I've used that shaves as close as a blade (including the Mach 3).  In fact, it shaves closer than a blade under my jaw and around my adam's apple.  I can't shave against the grain with a blade in those areas or my skin breaks out (and that's the only way to get the closest shave.)  With the 6885XL I don't have this problem and I get a really close shave.\n",
      "- It's quiet.  Previous electric razors were so noisy I had to shave in another bathroom so I wouldn't wake my wife.  Not so with this one.\n",
      "- Easy to clean.  Open the top and run hot water through it.  No more brushes (except for periodic maintenance).  An indicator will tell you when it's time to clean.\n",
      "Other features:\n",
      "- Charge remaining (in minutes) display.  This isn't particularly useful to me, but it seems reasonable accurate.\n",
      "- It comes with a stand that holds the razor upright on the counter or basin.  Much neater than the razor just laying around or stuffed in a cabinet.\n",
      "- Hard carrying case, for travel.\n",
      "- Automatically adjusts to different voltages.\n",
      "My wife about had a heart attack when I bought it.  However, it gives me the best shave ever (electric or blades).\n",
      "Rating: 5.0\n",
      "\n",
      "Title: Philips Norelco HQ5 Shaving Heads\n",
      "Review: I've had many Norelco razors in my 50 years of shaving with all being renewed\n",
      "with a fresh set of heads after a few years. Every Norelco I owned always failed\n",
      "the switch so be mindful of that if you want new heads.\n",
      "\n",
      "Switch OK? Then buy new heads and keep on shavin'\n",
      "Rating: 5.0\n",
      "\n",
      "Title: Philips Norelco HQ5 Shaving Heads\n",
      "Review: I've had many Norelco razors in my 50 years of shaving with all being renewed\n",
      "with a fresh set of heads after a few years. Every Norelco I owned always failed\n",
      "the switch so be mindful of that if you want new heads.\n",
      "\n",
      "Switch OK? Then buy new heads and keep on shavin'\n",
      "Rating: 5.0\n"
     ]
    }
   ],
   "source": [
    "# print the title, reviewText, and rating of each example\n",
    "for idx, row in df.head(n_examples).iterrows():\n",
    "    print(\"\")\n",
    "    print(f\"Title: {row['title']}\")\n",
    "    print(f\"Review: {row['reviewText']}\")\n",
    "    print(f\"Rating: {row['rating']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build cache to save embeddings (OpenAI API)\n",
    "\n",
    "+ Save our embeddings so we can re-use them later.\n",
    "+ The cache is a dictionary that maps tuples of `(text, model)` to an embedding, which is a list of floats. The cache is saved as a Python pickle file.\n",
    "+ The embedded vectors are a numerical representation of the input text's meaning, capturing both its inherent semantics and its context within the provided input. \n",
    "+ OpenAI embeddings are normalized to length 1, which means that:\n",
    "    + Cosine similarity can be computed slightly faster using just a dot product\n",
    "    + Cosine similarity and Euclidean distance will result in the identical rankings\n",
    "+ Aggregation process of embedding is not documented\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# establish a cache of embeddings to avoid recomputing\n",
    "# cache is a dict of tuples (text, model) -> embedding, saved as a pickle file\n",
    "\n",
    "# set path to embedding cache\n",
    "# Construct the path to data file\n",
    "embedding_cache_path = os.path.join(current_dir, 'amazon_embeddings_cache.pkl')\n",
    "\n",
    "# load the cache if it exists, and save a copy to disk\n",
    "try:\n",
    "    embedding_cache = pd.read_pickle(embedding_cache_path)\n",
    "except FileNotFoundError:\n",
    "    embedding_cache = {}\n",
    "with open(embedding_cache_path, \"wb\") as embedding_cache_file:\n",
    "    pickle.dump(embedding_cache, embedding_cache_file)\n",
    "\n",
    "# define a function to retrieve embeddings from the cache if present, and otherwise request via the API\n",
    "def embedding_from_string(\n",
    "    string: str,\n",
    "    model: str = EMBEDDING_MODEL,\n",
    "    embedding_cache=embedding_cache\n",
    ") -> list:\n",
    "    \"\"\"Return embedding of given string, using a cache to avoid recomputing.\"\"\"\n",
    "    if (string, model) not in embedding_cache.keys():\n",
    "        embedding_cache[(string, model)] = get_embedding(string, model)\n",
    "        with open(embedding_cache_path, \"wb\") as embedding_cache_file:\n",
    "            pickle.dump(embedding_cache, embedding_cache_file)\n",
    "    return embedding_cache[(string, model)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example string: Jenna Jameson Heartbreaker Perfume for women 3.4 oz Eau De Parfum Spray\n",
      "\n",
      "Example embedding: [-0.018199129030108452, 0.007970279082655907, -0.027546744793653488, -0.020601309835910797, 0.006847520358860493, 0.015914447605609894, -0.008583879098296165, -0.018721342086791992, -0.011932571418583393, -0.014726411551237106]...\n"
     ]
    }
   ],
   "source": [
    "# as an example, take the first title from the dataset\n",
    "example_string = df[\"title\"].values[0]\n",
    "print(f\"\\nExample string: {example_string}\")\n",
    "\n",
    "# print the first 10 dimensions of the embedding\n",
    "example_embedding = embedding_from_string(example_string)\n",
    "print(f\"\\nExample embedding: {example_embedding[:10]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommend similar products based on embeddings\n",
    "\n",
    "+ Get the similarity embeddings of all the product title\n",
    "+ Calculate the distance between a source title and all other products\n",
    "+ Print out the other products closest to the source title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_recommendations_from_strings(\n",
    "    strings: list[str],\n",
    "    index_of_source_string: int,\n",
    "    k_nearest_neighbors: int = 1,\n",
    "    model=EMBEDDING_MODEL,\n",
    ") -> list[int]:\n",
    "    \"\"\"Print out the k nearest neighbors of a given string.\"\"\"\n",
    "    # get embeddings for all strings\n",
    "    embeddings = [embedding_from_string(string, model=model) for string in strings]\n",
    "    # get the embedding of the source string\n",
    "    query_embedding = embeddings[index_of_source_string]\n",
    "    # get distances between the source embedding and other embeddings (function from embeddings_utils.py)\n",
    "    distances = distances_from_embeddings(query_embedding, embeddings, distance_metric=\"cosine\")\n",
    "    # get indices of nearest neighbors (function from embeddings_utils.py)\n",
    "    indices_of_nearest_neighbors = indices_of_nearest_neighbors_from_distances(distances)\n",
    "\n",
    "    # print out source string\n",
    "    query_string = strings[index_of_source_string]\n",
    "    print(f\"Source string: {query_string}\")\n",
    "    # print out its k nearest neighbors\n",
    "    k_counter = 0\n",
    "    for i in indices_of_nearest_neighbors:\n",
    "        # skip any strings that are identical matches to the starting string\n",
    "        if query_string == strings[i]:\n",
    "            continue\n",
    "        # stop after printing out k products\n",
    "        if k_counter >= k_nearest_neighbors:\n",
    "            break\n",
    "        k_counter += 1\n",
    "\n",
    "        # print out the similar strings and their distances\n",
    "        print(\n",
    "            f\"\"\"\n",
    "        --- Recommendation #{k_counter} (nearest neighbor {k_counter} of {k_nearest_neighbors}) ---\n",
    "        String: {strings[i]}\n",
    "        Distance: {distances[i]:0.3f}\"\"\"\n",
    "        )\n",
    "\n",
    "    return indices_of_nearest_neighbors\n",
    "\n",
    "product_titles = df[\"title\"].tolist()\n",
    "\n",
    "tony_blair_products = print_recommendations_from_strings(\n",
    "    strings=product_titles,  # let's base similarity off of the product title\n",
    "    index_of_source_string=0,  # let's look at products similar to the first one about\n",
    "    k_nearest_neighbors=5,  # let's look at the 5 most similar products\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate RMSE and MAE manually\n",
    "def calculate_rmse_and_mae(actual_ratings, predicted_ratings):\n",
    "    differences = [actual - predicted for actual, predicted in zip(actual_ratings, predicted_ratings)]\n",
    "    \n",
    "    # RMSE\n",
    "    squared_differences = [diff ** 2 for diff in differences]\n",
    "    mean_squared_difference = sum(squared_differences) / len(squared_differences)\n",
    "    rmse = mean_squared_difference ** 0.5\n",
    "\n",
    "    # MAE\n",
    "    absolute_differences = [abs(diff) for diff in differences]\n",
    "    mae = sum(absolute_differences) / len(absolute_differences)\n",
    "\n",
    "    return rmse, mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression using embedding\n",
    "\n",
    "+ Obtain embeddings for each unique user ID.\n",
    "+ For each data point, concatenate the title embedding with the user embedding to form a combined feature vector.\n",
    "+ Split the dataset into training and test sets.\n",
    "+ Train the model on the combined embeddings and predict the test set.\n",
    "+ Evaluate using RMSE and MAE metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI embedding performance: rmse=1.59, mae=1.13\n",
      "CPU times: user 370 ms, sys: 13.5 ms, total: 383 ms\n",
      "Wall time: 3.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(6))\n",
    "def get_embeddings(texts: list[str], model=\"text-embedding-ada-002\") -> list[list[float]]:\n",
    "    return [item[\"embedding\"] for item in openai.Embedding.create(input=texts, model=model)[\"data\"]]\n",
    "\n",
    "# Get embeddings for titles in batches\n",
    "batch_size = 100\n",
    "title_embeddings = []\n",
    "\n",
    "for i in range(0, len(df['title']), batch_size):\n",
    "    batch_texts = df['title'].iloc[i:i+batch_size].tolist()\n",
    "    title_embeddings.extend(get_embeddings(batch_texts))\n",
    "\n",
    "# Get embeddings for unique users\n",
    "unique_users = df['reviewerID'].unique().tolist()\n",
    "user_embeddings_dict = {}\n",
    "user_embeddings = get_embeddings(unique_users)\n",
    "for user, embedding in zip(unique_users, user_embeddings):\n",
    "    user_embeddings_dict[user] = embedding\n",
    "\n",
    "# Create combined embeddings: title_embedding + user_embedding\n",
    "combined_embeddings = []\n",
    "for idx, row in df.iterrows():\n",
    "    combined_embedding = title_embeddings[idx] + user_embeddings_dict[row['reviewerID']]\n",
    "    combined_embeddings.append(combined_embedding)\n",
    "\n",
    "X_openai = np.array(combined_embeddings)\n",
    "\n",
    "# Splitting the dataset\n",
    "X_train_openai, X_test_openai, y_train, y_test = train_test_split(X_openai, df['rating'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Train RandomForest on OpenAI embeddings\n",
    "rfr_openai = RandomForestRegressor(n_estimators=100)\n",
    "rfr_openai.fit(X_train_openai, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "preds_openai = rfr_openai.predict(X_test_openai)\n",
    "rmse_openai = np.sqrt(mean_squared_error(y_test, preds_openai))  # Calculating RMSE\n",
    "mae_openai = mean_absolute_error(y_test, preds_openai)\n",
    "\n",
    "print(f\"OpenAI embedding performance: rmse={rmse_openai:.4f}, mae={mae_openai:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "+ https://cookbook.openai.com/examples/recommendation_using_embeddings\n",
    "+ https://github.com/openai/openai-python/blob/main/openai/embeddings_utils.py\n",
    "+ https://help.openai.com/en/products/6824809-embeddings-frequently-asked-questions\n",
    "+ https://platform.openai.com/docs/guides/embeddings/use-cases"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
