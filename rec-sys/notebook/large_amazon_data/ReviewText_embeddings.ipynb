{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current directory: /Users/tnathu-ai/VSCode/recommender-system/recommender-system-openAI/rec-sys/data/amazon-beauty\n",
      "embedding model current directory: /Users/tnathu-ai/VSCode/recommender-system/recommender-system-openAI/rec-sys/models/embedding\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import openai\n",
    "import numpy as np\n",
    "from openai.embeddings_utils import (\n",
    "    get_embedding,\n",
    "    distances_from_embeddings,\n",
    "    tsne_components_from_embeddings,\n",
    "    chart_from_components,\n",
    "    indices_of_nearest_neighbors_from_distances,\n",
    ")\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Add the path to the constants file to the system path\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "from constants import *\n",
    "from evaluation_utils import *\n",
    "from embeddings import *\n",
    "\n",
    "# OpenAI API Key\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "# Get the current directory of the notebook\n",
    "current_dir = os.path.dirname(os.path.abspath(\"../../data/amazon-beauty/parse_and_clean_meta_data.ipynb\"))\n",
    "# # Get the current directory of the notebook\n",
    "embedding_model_current_dir = os.path.dirname(os.path.abspath(\"../../models/embedding/parse_and_clean_meta_data.ipynb\"))\n",
    "print(f\"current directory: {current_dir}\")\n",
    "print(f\"embedding model current directory: {embedding_model_current_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data path: /Users/tnathu-ai/VSCode/recommender-system/recommender-system-openAI/rec-sys/data/amazon-beauty/large_merged_data.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>category</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>A2RYSCZOPEXOCQ</td>\n",
       "      <td>9790787006</td>\n",
       "      <td>I use a lot of perfume, I go through a new bot...</td>\n",
       "      <td>This is not going to be my favorite scent.</td>\n",
       "      <td>[]</td>\n",
       "      <td>Jenna Jameson Heartbreaker Perfume for women 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>A141OPVE376YFI</td>\n",
       "      <td>B000050B65</td>\n",
       "      <td>First, a little background.  I've switched bet...</td>\n",
       "      <td>Finally, a razor that lives up to the ads</td>\n",
       "      <td>[]</td>\n",
       "      <td>Norelco 6885XL Deluxe Quadra Action Cord/Cordl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>A141OPVE376YFI</td>\n",
       "      <td>B000050B65</td>\n",
       "      <td>First, a little background.  I've switched bet...</td>\n",
       "      <td>Finally, a razor that lives up to the ads</td>\n",
       "      <td>[]</td>\n",
       "      <td>Norelco 6885XL Deluxe Quadra Action Cord/Cordl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>A1TVTDKNMSQ7XU</td>\n",
       "      <td>B000050B6B</td>\n",
       "      <td>I've had many Norelco razors in my 50 years of...</td>\n",
       "      <td>Just like new.....</td>\n",
       "      <td>[]</td>\n",
       "      <td>Philips Norelco HQ5 Shaving Heads</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>A1TVTDKNMSQ7XU</td>\n",
       "      <td>B000050B6B</td>\n",
       "      <td>I've had many Norelco razors in my 50 years of...</td>\n",
       "      <td>Just like new.....</td>\n",
       "      <td>[]</td>\n",
       "      <td>Philips Norelco HQ5 Shaving Heads</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating      reviewerID        asin  \\\n",
       "0     1.0  A2RYSCZOPEXOCQ  9790787006   \n",
       "1     5.0  A141OPVE376YFI  B000050B65   \n",
       "2     5.0  A141OPVE376YFI  B000050B65   \n",
       "3     5.0  A1TVTDKNMSQ7XU  B000050B6B   \n",
       "4     5.0  A1TVTDKNMSQ7XU  B000050B6B   \n",
       "\n",
       "                                          reviewText  \\\n",
       "0  I use a lot of perfume, I go through a new bot...   \n",
       "1  First, a little background.  I've switched bet...   \n",
       "2  First, a little background.  I've switched bet...   \n",
       "3  I've had many Norelco razors in my 50 years of...   \n",
       "4  I've had many Norelco razors in my 50 years of...   \n",
       "\n",
       "                                      summary category  \\\n",
       "0  This is not going to be my favorite scent.       []   \n",
       "1   Finally, a razor that lives up to the ads       []   \n",
       "2   Finally, a razor that lives up to the ads       []   \n",
       "3                          Just like new.....       []   \n",
       "4                          Just like new.....       []   \n",
       "\n",
       "                                               title  \n",
       "0  Jenna Jameson Heartbreaker Perfume for women 3...  \n",
       "1  Norelco 6885XL Deluxe Quadra Action Cord/Cordl...  \n",
       "2  Norelco 6885XL Deluxe Quadra Action Cord/Cordl...  \n",
       "3                  Philips Norelco HQ5 Shaving Heads  \n",
       "4                  Philips Norelco HQ5 Shaving Heads  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct the path to data file\n",
    "data_path = os.path.join(current_dir, 'large_merged_data.csv')\n",
    "print(f'data path: {data_path}')\n",
    "# load data (full dataset available at http://groups.di.unipi.it/~gulli/AG_corpus_of_news_products.html)\n",
    "dataset_path = data_path\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "df.head(NUM_EXAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Title: Jenna Jameson Heartbreaker Perfume for women 3.4 oz Eau De Parfum Spray\n",
      "Review: I use a lot of perfume, I go through a new bottle every couple of weeks, and I never bought the same scent twice. I`m still looking for my favorite scent. This is not going to be it. I`m going to use it, but definitely not purchase again. Someone else may like it, it just does not lure my scents. Bottle is a very pretty, red glass, and it smells classier, than the name suggests.\n",
      "\n",
      "I got this for evaluation, 50% off, in order that I might provide this review.\n",
      "\n",
      "* I originally gave this 3 stars, but as I tried to use this further, I found the smell being just completely wrong. I asked three friends separately, what they think of it, and each one said, that this smells manly. And that was the exact word I was looking for. First two girls did not want to take this from me for free, the third one took it, but stated that really just a little at a time can be used. I downgraded this to 1 star, as it was in fact unusable and I wasted money on it. All four of us are in our early to late twenties and none of us liked this perfume. This is the only one 1 star review I ever wrote.\n",
      "Rating: 1.0\n",
      "\n",
      "Title: Norelco 6885XL Deluxe Quadra Action Cord/Cordless Rechargeable Men's Shaver\n",
      "Review: First, a little background.  I've switched between Norelco electric razors and blades over the years, never quite satisfied with the shave I was getting.  Norelco has always said \"shaves as close as a blade or your money back\".  I've never found this to be true, but the razors were good enough that I didn't return them.  Most recently I used the Gilette Mach 3 razor which does a very good job.\n",
      "Now here's why I give the 6885XL (6886XL is apparently the same model, sold at Costco and other warehouse stores) 5 stars:\n",
      "- Closest shave yet.  This is the first electric razor I've used that shaves as close as a blade (including the Mach 3).  In fact, it shaves closer than a blade under my jaw and around my adam's apple.  I can't shave against the grain with a blade in those areas or my skin breaks out (and that's the only way to get the closest shave.)  With the 6885XL I don't have this problem and I get a really close shave.\n",
      "- It's quiet.  Previous electric razors were so noisy I had to shave in another bathroom so I wouldn't wake my wife.  Not so with this one.\n",
      "- Easy to clean.  Open the top and run hot water through it.  No more brushes (except for periodic maintenance).  An indicator will tell you when it's time to clean.\n",
      "Other features:\n",
      "- Charge remaining (in minutes) display.  This isn't particularly useful to me, but it seems reasonable accurate.\n",
      "- It comes with a stand that holds the razor upright on the counter or basin.  Much neater than the razor just laying around or stuffed in a cabinet.\n",
      "- Hard carrying case, for travel.\n",
      "- Automatically adjusts to different voltages.\n",
      "My wife about had a heart attack when I bought it.  However, it gives me the best shave ever (electric or blades).\n",
      "Rating: 5.0\n",
      "\n",
      "Title: Norelco 6885XL Deluxe Quadra Action Cord/Cordless Rechargeable Men's Shaver\n",
      "Review: First, a little background.  I've switched between Norelco electric razors and blades over the years, never quite satisfied with the shave I was getting.  Norelco has always said \"shaves as close as a blade or your money back\".  I've never found this to be true, but the razors were good enough that I didn't return them.  Most recently I used the Gilette Mach 3 razor which does a very good job.\n",
      "Now here's why I give the 6885XL (6886XL is apparently the same model, sold at Costco and other warehouse stores) 5 stars:\n",
      "- Closest shave yet.  This is the first electric razor I've used that shaves as close as a blade (including the Mach 3).  In fact, it shaves closer than a blade under my jaw and around my adam's apple.  I can't shave against the grain with a blade in those areas or my skin breaks out (and that's the only way to get the closest shave.)  With the 6885XL I don't have this problem and I get a really close shave.\n",
      "- It's quiet.  Previous electric razors were so noisy I had to shave in another bathroom so I wouldn't wake my wife.  Not so with this one.\n",
      "- Easy to clean.  Open the top and run hot water through it.  No more brushes (except for periodic maintenance).  An indicator will tell you when it's time to clean.\n",
      "Other features:\n",
      "- Charge remaining (in minutes) display.  This isn't particularly useful to me, but it seems reasonable accurate.\n",
      "- It comes with a stand that holds the razor upright on the counter or basin.  Much neater than the razor just laying around or stuffed in a cabinet.\n",
      "- Hard carrying case, for travel.\n",
      "- Automatically adjusts to different voltages.\n",
      "My wife about had a heart attack when I bought it.  However, it gives me the best shave ever (electric or blades).\n",
      "Rating: 5.0\n",
      "\n",
      "Title: Philips Norelco HQ5 Shaving Heads\n",
      "Review: I've had many Norelco razors in my 50 years of shaving with all being renewed\n",
      "with a fresh set of heads after a few years. Every Norelco I owned always failed\n",
      "the switch so be mindful of that if you want new heads.\n",
      "\n",
      "Switch OK? Then buy new heads and keep on shavin'\n",
      "Rating: 5.0\n",
      "\n",
      "Title: Philips Norelco HQ5 Shaving Heads\n",
      "Review: I've had many Norelco razors in my 50 years of shaving with all being renewed\n",
      "with a fresh set of heads after a few years. Every Norelco I owned always failed\n",
      "the switch so be mindful of that if you want new heads.\n",
      "\n",
      "Switch OK? Then buy new heads and keep on shavin'\n",
      "Rating: 5.0\n"
     ]
    }
   ],
   "source": [
    "# print the title, reviewText, and rating of each example\n",
    "for idx, row in df.head(NUM_EXAMPLES).iterrows():\n",
    "    print(\"\")\n",
    "    print(f\"Title: {row['title']}\")\n",
    "    print(f\"Review: {row['reviewText']}\")\n",
    "    print(f\"Rating: {row['rating']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build cache to save embeddings (OpenAI API)\n",
    "\n",
    "+ Save our embeddings so we can re-use them later.\n",
    "+ The cache is a dictionary that maps tuples of `(text, model)` to an embedding, which is a list of floats. The cache is saved as a Python pickle file.\n",
    "+ The embedded vectors are a numerical representation of the input text's meaning, capturing both its inherent semantics and its context within the provided input. \n",
    "+ OpenAI embeddings are normalized to length 1, which means that:\n",
    "    + Cosine similarity can be computed slightly faster using just a dot product\n",
    "    + Cosine similarity and Euclidean distance will result in the identical rankings\n",
    "+ Aggregation process of embedding is not documented\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# establish a cache of embeddings to avoid recomputing\n",
    "# cache is a dict of tuples (text, model) -> embedding, saved as a pickle file\n",
    "\n",
    "# set path to embedding cache\n",
    "# Construct the path to data file\n",
    "embedding_cache_path = os.path.join(current_dir, 'amazon_embeddings_cache.pkl')\n",
    "\n",
    "# load the cache if it exists, and save a copy to disk\n",
    "try:\n",
    "    embedding_cache = pd.read_pickle(embedding_cache_path)\n",
    "except FileNotFoundError:\n",
    "    embedding_cache = {}\n",
    "with open(embedding_cache_path, \"wb\") as embedding_cache_file:\n",
    "    pickle.dump(embedding_cache, embedding_cache_file)\n",
    "\n",
    "# define a function to retrieve embeddings from the cache if present, and otherwise request via the API\n",
    "def embedding_from_string(\n",
    "    string: str,\n",
    "    model: str = EMBEDDING_MODEL,\n",
    "    embedding_cache=embedding_cache\n",
    ") -> list:\n",
    "    \"\"\"Return embedding of given string, using a cache to avoid recomputing.\"\"\"\n",
    "    if (string, model) not in embedding_cache.keys():\n",
    "        embedding_cache[(string, model)] = get_embedding(string, model)\n",
    "        with open(embedding_cache_path, \"wb\") as embedding_cache_file:\n",
    "            pickle.dump(embedding_cache, embedding_cache_file)\n",
    "    return embedding_cache[(string, model)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example string: Jenna Jameson Heartbreaker Perfume for women 3.4 oz Eau De Parfum Spray\n",
      "\n",
      "Example embedding: [-0.018199129030108452, 0.007970279082655907, -0.027546744793653488, -0.020601309835910797, 0.006847520358860493, 0.015914447605609894, -0.008583879098296165, -0.018721342086791992, -0.011932571418583393, -0.014726411551237106]...\n"
     ]
    }
   ],
   "source": [
    "# as an example, take the first title from the dataset\n",
    "example_string = df[\"title\"].values[0]\n",
    "print(f\"\\nExample string: {example_string}\")\n",
    "\n",
    "# print the first 10 dimensions of the embedding\n",
    "example_embedding = embedding_from_string(example_string)\n",
    "print(f\"\\nExample embedding: {example_embedding[:10]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommend similar products based on embeddings\n",
    "\n",
    "+ Get the similarity embeddings of all the product title\n",
    "+ Calculate the distance between a source title and all other products\n",
    "+ Print out the other products closest to the source title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source string: Jenna Jameson Heartbreaker Perfume for women 3.4 oz Eau De Parfum Spray\n",
      "\n",
      "        --- Recommendation #1 (nearest neighbor 1 of 5) ---\n",
      "        String: Sex In The City Kiss by Instyle Parfums Eau De Parfum Spray 3.4 oz\n",
      "        Distance: 0.126\n",
      "\n",
      "        --- Recommendation #2 (nearest neighbor 2 of 5) ---\n",
      "        String: Sex In The City Kiss by Instyle Parfums Eau De Parfum Spray 3.4 oz\n",
      "        Distance: 0.126\n",
      "\n",
      "        --- Recommendation #3 (nearest neighbor 3 of 5) ---\n",
      "        String: Love Potion ~ Scented Sexology 1/3 Fl. Oz. Pheromone Enhanced Perfume Oil for Women\n",
      "        Distance: 0.138\n",
      "\n",
      "        --- Recommendation #4 (nearest neighbor 4 of 5) ---\n",
      "        String: Love Potion Rocket Fuel ~ 1/3 Fl. Oz. Pheromone Enhanced Perfume Oil for Women\n",
      "        Distance: 0.140\n",
      "\n",
      "        --- Recommendation #5 (nearest neighbor 5 of 5) ---\n",
      "        String: Fideau ~ 1/3 Fl. Oz. Pheromone Enhanced Perfume Oil for Women\n",
      "        Distance: 0.144\n"
     ]
    }
   ],
   "source": [
    "def print_recommendations_from_strings(\n",
    "    strings: list[str],\n",
    "    index_of_source_string: int,\n",
    "    k_nearest_neighbors: int = 1,\n",
    "    model=EMBEDDING_MODEL,\n",
    ") -> list[int]:\n",
    "    \"\"\"Print out the k nearest neighbors of a given string.\"\"\"\n",
    "    # get embeddings for all strings\n",
    "    embeddings = [embedding_from_string(string, model=model) for string in strings]\n",
    "    # get the embedding of the source string\n",
    "    query_embedding = embeddings[index_of_source_string]\n",
    "    # get distances between the source embedding and other embeddings (function from embeddings_utils.py)\n",
    "    distances = distances_from_embeddings(query_embedding, embeddings, distance_metric=\"cosine\")\n",
    "    # get indices of nearest neighbors (function from embeddings_utils.py)\n",
    "    indices_of_nearest_neighbors = indices_of_nearest_neighbors_from_distances(distances)\n",
    "\n",
    "    # print out source string\n",
    "    query_string = strings[index_of_source_string]\n",
    "    print(f\"Source string: {query_string}\")\n",
    "    # print out its k nearest neighbors\n",
    "    k_counter = 0\n",
    "    for i in indices_of_nearest_neighbors:\n",
    "        # skip any strings that are identical matches to the starting string\n",
    "        if query_string == strings[i]:\n",
    "            continue\n",
    "        # stop after printing out k products\n",
    "        if k_counter >= k_nearest_neighbors:\n",
    "            break\n",
    "        k_counter += 1\n",
    "\n",
    "        # print out the similar strings and their distances\n",
    "        print(\n",
    "            f\"\"\"\n",
    "        --- Recommendation #{k_counter} (nearest neighbor {k_counter} of {k_nearest_neighbors}) ---\n",
    "        String: {strings[i]}\n",
    "        Distance: {distances[i]:0.3f}\"\"\"\n",
    "        )\n",
    "\n",
    "    return indices_of_nearest_neighbors\n",
    "\n",
    "product_titles = df[\"title\"].tolist()\n",
    "\n",
    "tony_blair_products = print_recommendations_from_strings(\n",
    "    strings=product_titles,  # let's base similarity off of the product title\n",
    "    index_of_source_string=0,  # let's look at products similar to the first one about\n",
    "    k_nearest_neighbors=5,  # let's look at the 5 most similar products\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression using embedding\n",
    "\n",
    "+ Obtain embeddings for each unique user ID.\n",
    "+ For each data point, concatenate the title embedding with the user embedding to form a combined feature vector.\n",
    "+ Split the dataset into training and test sets.\n",
    "+ Train the model on the combined embeddings and predict the test set.\n",
    "+ Evaluate using RMSE and MAE metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "RetryError",
     "evalue": "RetryError[<Future at 0x199938490 state=finished raised InvalidRequestError>]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/test/lib/python3.11/site-packages/tenacity/__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 382\u001b[0m     result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    383\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m:  \u001b[39m# noqa: B902\u001b[39;00m\n",
      "File \u001b[0;32m~/VSCode/recommender-system/recommender-system-openAI/rec-sys/notebook/large_amazon_data/../../embeddings.py:12\u001b[0m, in \u001b[0;36mget_embeddings\u001b[0;34m(texts, model)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39m@retry\u001b[39m(wait\u001b[39m=\u001b[39mwait_random_exponential(\u001b[39mmin\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, \u001b[39mmax\u001b[39m\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m), stop\u001b[39m=\u001b[39mstop_after_attempt(\u001b[39m6\u001b[39m))\n\u001b[1;32m     11\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_embeddings\u001b[39m(texts: \u001b[39mlist\u001b[39m[\u001b[39mstr\u001b[39m], model\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtext-embedding-ada-002\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mlist\u001b[39m[\u001b[39mlist\u001b[39m[\u001b[39mfloat\u001b[39m]]:\n\u001b[0;32m---> 12\u001b[0m     \u001b[39mreturn\u001b[39;00m [item[\u001b[39m\"\u001b[39m\u001b[39membedding\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m openai\u001b[39m.\u001b[39;49mEmbedding\u001b[39m.\u001b[39;49mcreate(\u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49mtexts, model\u001b[39m=\u001b[39;49mmodel)[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m]]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/test/lib/python3.11/site-packages/openai/api_resources/embedding.py:33\u001b[0m, in \u001b[0;36mEmbedding.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 33\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     35\u001b[0m     \u001b[39m# If a user specifies base64, we'll just return the encoded string.\u001b[39;00m\n\u001b[1;32m     36\u001b[0m     \u001b[39m# This is only for the default case.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/test/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    138\u001b[0m (\n\u001b[1;32m    139\u001b[0m     deployment_id,\n\u001b[1;32m    140\u001b[0m     engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m     api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m )\n\u001b[0;32m--> 153\u001b[0m response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    154\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    155\u001b[0m     url,\n\u001b[1;32m    156\u001b[0m     params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    157\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    158\u001b[0m     stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    159\u001b[0m     request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    160\u001b[0m     request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    161\u001b[0m )\n\u001b[1;32m    163\u001b[0m \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m     \u001b[39m# must be an iterator\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/test/lib/python3.11/site-packages/openai/api_requestor.py:226\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    216\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[1;32m    217\u001b[0m     method\u001b[39m.\u001b[39mlower(),\n\u001b[1;32m    218\u001b[0m     url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    224\u001b[0m     request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    225\u001b[0m )\n\u001b[0;32m--> 226\u001b[0m resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[1;32m    227\u001b[0m \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/test/lib/python3.11/site-packages/openai/api_requestor.py:620\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    619\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 620\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[1;32m    621\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    622\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[1;32m    623\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    624\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    625\u001b[0m         ),\n\u001b[1;32m    626\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    627\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/test/lib/python3.11/site-packages/openai/api_requestor.py:683\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[0;32m--> 683\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[1;32m    684\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[1;32m    685\u001b[0m     )\n\u001b[1;32m    686\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mInvalidRequestError\u001b[0m: We could not parse the JSON body of your request. (HINT: This likely means you aren't using your HTTP library correctly. The OpenAI API expects a JSON payload, but what was sent was not valid JSON. If you have trouble figuring out how to fix this, please contact us through our help center at help.openai.com.)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRetryError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m<timed eval>:1\u001b[0m\n",
      "File \u001b[0;32m~/VSCode/recommender-system/recommender-system-openAI/rec-sys/notebook/large_amazon_data/../../embeddings.py:23\u001b[0m, in \u001b[0;36mtrain_and_evaluate_embeddings_model\u001b[0;34m(df, columns_for_unique_pairs, batch_size, RANDOM_STATE, TEST_SIZE, N_ESTIMATORS)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(df[column]), batch_size):\n\u001b[1;32m     22\u001b[0m         batch_texts \u001b[39m=\u001b[39m df[column]\u001b[39m.\u001b[39miloc[i:i\u001b[39m+\u001b[39mbatch_size]\u001b[39m.\u001b[39mtolist()\n\u001b[0;32m---> 23\u001b[0m         column_embeddings\u001b[39m.\u001b[39mextend(get_embeddings(batch_texts))\n\u001b[1;32m     24\u001b[0m     embeddings[column] \u001b[39m=\u001b[39m column_embeddings\n\u001b[1;32m     26\u001b[0m \u001b[39m# Get embeddings for unique users\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/test/lib/python3.11/site-packages/tenacity/__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[1;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_f\u001b[39m(\u001b[39m*\u001b[39margs: t\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mAny:\n\u001b[0;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(f, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/test/lib/python3.11/site-packages/tenacity/__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m retry_state \u001b[39m=\u001b[39m RetryCallState(retry_object\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, fn\u001b[39m=\u001b[39mfn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[1;32m    378\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 379\u001b[0m     do \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter(retry_state\u001b[39m=\u001b[39;49mretry_state)\n\u001b[1;32m    380\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/test/lib/python3.11/site-packages/tenacity/__init__.py:326\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreraise:\n\u001b[1;32m    325\u001b[0m         \u001b[39mraise\u001b[39;00m retry_exc\u001b[39m.\u001b[39mreraise()\n\u001b[0;32m--> 326\u001b[0m     \u001b[39mraise\u001b[39;00m retry_exc \u001b[39mfrom\u001b[39;00m \u001b[39mfut\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexception\u001b[39;00m()\n\u001b[1;32m    328\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwait:\n\u001b[1;32m    329\u001b[0m     sleep \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwait(retry_state)\n",
      "\u001b[0;31mRetryError\u001b[0m: RetryError[<Future at 0x199938490 state=finished raised InvalidRequestError>]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_and_evaluate_embeddings_model(df, columns_for_unique_pairs=['title', 'reviewText'], batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "+ https://cookbook.openai.com/examples/recommendation_using_embeddings\n",
    "+ https://github.com/openai/openai-python/blob/main/openai/embeddings_utils.py\n",
    "+ https://help.openai.com/en/products/6824809-embeddings-frequently-asked-questions\n",
    "+ https://platform.openai.com/docs/guides/embeddings/use-cases"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
