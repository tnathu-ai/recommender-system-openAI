{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current directory: /Users/tnathu-ai/VSCode/recommender-system/recommender-system-openAI/rec-sys/data/amazon-beauty\n",
      "embedding model current directory: /Users/tnathu-ai/VSCode/recommender-system/recommender-system-openAI/rec-sys/models/embedding\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import openai\n",
    "import numpy as np\n",
    "from openai.embeddings_utils import (\n",
    "    get_embedding,\n",
    "    distances_from_embeddings,\n",
    "    tsne_components_from_embeddings,\n",
    "    chart_from_components,\n",
    "    indices_of_nearest_neighbors_from_distances,\n",
    ")\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Add the path to the constants file to the system path\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "from constants import *\n",
    "from evaluation_utils import *\n",
    "from embeddings import *\n",
    "\n",
    "# OpenAI API Key\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "# Get the current directory of the notebook\n",
    "current_dir = os.path.dirname(os.path.abspath(\"../../data/amazon-beauty/parse_and_clean_meta_data.ipynb\"))\n",
    "# # Get the current directory of the notebook\n",
    "embedding_model_current_dir = os.path.dirname(os.path.abspath(\"../../models/embedding/parse_and_clean_meta_data.ipynb\"))\n",
    "print(f\"current directory: {current_dir}\")\n",
    "print(f\"embedding model current directory: {embedding_model_current_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data path: /Users/tnathu-ai/VSCode/recommender-system/recommender-system-openAI/rec-sys/data/amazon-beauty/merged_data.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>ANV9L0JU6BNL</td>\n",
       "      <td>B000052YAN</td>\n",
       "      <td>best floss i've used. does not break as easily...</td>\n",
       "      <td>best floss i've used</td>\n",
       "      <td>Reach Dentotape Waxed Dental Floss with Extra ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>ANV9L0JU6BNL</td>\n",
       "      <td>B000052YAN</td>\n",
       "      <td>best floss i've used. does not break as easily...</td>\n",
       "      <td>best floss i've used</td>\n",
       "      <td>Reach Dentotape Waxed Dental Floss with Extra ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>A2TU781PWGS09X</td>\n",
       "      <td>B00006L9LC</td>\n",
       "      <td>Doesnt smell</td>\n",
       "      <td>Two Stars</td>\n",
       "      <td>Citre Shine Moisture Burst Shampoo - 16 fl oz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>A2TU781PWGS09X</td>\n",
       "      <td>B00006L9LC</td>\n",
       "      <td>Doesnt smell</td>\n",
       "      <td>Two Stars</td>\n",
       "      <td>Citre Shine Moisture Burst Shampoo - 16 fl oz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>A3A8F2URN7MEPR</td>\n",
       "      <td>B00006L9LC</td>\n",
       "      <td>My favorite powder!</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>Citre Shine Moisture Burst Shampoo - 16 fl oz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating      reviewerID        asin  \\\n",
       "0     5.0    ANV9L0JU6BNL  B000052YAN   \n",
       "1     5.0    ANV9L0JU6BNL  B000052YAN   \n",
       "2     2.0  A2TU781PWGS09X  B00006L9LC   \n",
       "3     2.0  A2TU781PWGS09X  B00006L9LC   \n",
       "4     5.0  A3A8F2URN7MEPR  B00006L9LC   \n",
       "\n",
       "                                          reviewText               summary  \\\n",
       "0  best floss i've used. does not break as easily...  best floss i've used   \n",
       "1  best floss i've used. does not break as easily...  best floss i've used   \n",
       "2                                       Doesnt smell             Two Stars   \n",
       "3                                       Doesnt smell             Two Stars   \n",
       "4                                My favorite powder!            Five Stars   \n",
       "\n",
       "                                               title  \n",
       "0  Reach Dentotape Waxed Dental Floss with Extra ...  \n",
       "1  Reach Dentotape Waxed Dental Floss with Extra ...  \n",
       "2      Citre Shine Moisture Burst Shampoo - 16 fl oz  \n",
       "3      Citre Shine Moisture Burst Shampoo - 16 fl oz  \n",
       "4      Citre Shine Moisture Burst Shampoo - 16 fl oz  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct the path to data file\n",
    "data_path = os.path.join(current_dir, 'merged_data.csv')\n",
    "print(f'data path: {data_path}')\n",
    "# load data (full dataset available at http://groups.di.unipi.it/~gulli/AG_corpus_of_news_products.html)\n",
    "dataset_path = data_path\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "df.head(NUM_EXAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Title: Reach Dentotape Waxed Dental Floss with Extra Wide Cleaning Surface for Large Spaces between Teeth, Unflavored, 100 Yards\n",
      "Review: best floss i've used. does not break as easily as others, and i have tight teeth.\n",
      "Rating: 5.0\n",
      "\n",
      "Title: Reach Dentotape Waxed Dental Floss with Extra Wide Cleaning Surface for Large Spaces between Teeth, Unflavored, 100 Yards\n",
      "Review: best floss i've used. does not break as easily as others, and i have tight teeth.\n",
      "Rating: 5.0\n",
      "\n",
      "Title: Citre Shine Moisture Burst Shampoo - 16 fl oz\n",
      "Review: Doesnt smell\n",
      "Rating: 2.0\n",
      "\n",
      "Title: Citre Shine Moisture Burst Shampoo - 16 fl oz\n",
      "Review: Doesnt smell\n",
      "Rating: 2.0\n",
      "\n",
      "Title: Citre Shine Moisture Burst Shampoo - 16 fl oz\n",
      "Review: My favorite powder!\n",
      "Rating: 5.0\n"
     ]
    }
   ],
   "source": [
    "# print the title, reviewText, and rating of each example\n",
    "for idx, row in df.head(NUM_EXAMPLES).iterrows():\n",
    "    print(\"\")\n",
    "    print(f\"Title: {row['title']}\")\n",
    "    print(f\"Review: {row['reviewText']}\")\n",
    "    print(f\"Rating: {row['rating']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build cache to save embeddings (OpenAI API)\n",
    "\n",
    "+ Save our embeddings so we can re-use them later.\n",
    "+ The cache is a dictionary that maps tuples of `(text, model)` to an embedding, which is a list of floats. The cache is saved as a Python pickle file.\n",
    "+ The embedded vectors are a numerical representation of the input text's meaning, capturing both its inherent semantics and its context within the provided input. \n",
    "+ OpenAI embeddings are normalized to length 1, which means that:\n",
    "    + Cosine similarity can be computed slightly faster using just a dot product\n",
    "    + Cosine similarity and Euclidean distance will result in the identical rankings\n",
    "+ Aggregation process of embedding is not documented\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# establish a cache of embeddings to avoid recomputing\n",
    "# cache is a dict of tuples (text, model) -> embedding, saved as a pickle file\n",
    "\n",
    "# set path to embedding cache\n",
    "# Construct the path to data file\n",
    "embedding_cache_path = os.path.join(current_dir, 'amazon_embeddings_cache.pkl')\n",
    "\n",
    "# load the cache if it exists, and save a copy to disk\n",
    "try:\n",
    "    embedding_cache = pd.read_pickle(embedding_cache_path)\n",
    "except FileNotFoundError:\n",
    "    embedding_cache = {}\n",
    "with open(embedding_cache_path, \"wb\") as embedding_cache_file:\n",
    "    pickle.dump(embedding_cache, embedding_cache_file)\n",
    "\n",
    "# define a function to retrieve embeddings from the cache if present, and otherwise request via the API\n",
    "def embedding_from_string(\n",
    "    string: str,\n",
    "    model: str = EMBEDDING_MODEL,\n",
    "    embedding_cache=embedding_cache\n",
    ") -> list:\n",
    "    \"\"\"Return embedding of given string, using a cache to avoid recomputing.\"\"\"\n",
    "    if (string, model) not in embedding_cache.keys():\n",
    "        embedding_cache[(string, model)] = get_embedding(string, model)\n",
    "        with open(embedding_cache_path, \"wb\") as embedding_cache_file:\n",
    "            pickle.dump(embedding_cache, embedding_cache_file)\n",
    "    return embedding_cache[(string, model)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example string: Reach Dentotape Waxed Dental Floss with Extra Wide Cleaning Surface for Large Spaces between Teeth, Unflavored, 100 Yards\n",
      "\n",
      "Example embedding: [0.008420577272772789, 0.004031274002045393, 0.006344694644212723, -0.005752569064497948, 0.0015130186220631003, 0.003907340578734875, 0.001457076519727707, -0.006193220615386963, -0.007332718465477228, 0.0009880235884338617]...\n"
     ]
    }
   ],
   "source": [
    "# as an example, take the first title from the dataset\n",
    "example_string = df[\"title\"].values[0]\n",
    "print(f\"\\nExample string: {example_string}\")\n",
    "\n",
    "# print the first 10 dimensions of the embedding\n",
    "example_embedding = embedding_from_string(example_string)\n",
    "print(f\"\\nExample embedding: {example_embedding[:10]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommend similar products based on embeddings\n",
    "\n",
    "+ Get the similarity embeddings of all the product title\n",
    "+ Calculate the distance between a source title and all other products\n",
    "+ Print out the other products closest to the source title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source string: Reach Dentotape Waxed Dental Floss with Extra Wide Cleaning Surface for Large Spaces between Teeth, Unflavored, 100 Yards\n",
      "\n",
      "        --- Recommendation #1 (nearest neighbor 1 of 5) ---\n",
      "        String: Astra Platinum Double Edge Safety Razor Blades ,100 Blades (20 x 5)\n",
      "        Distance: 0.204\n",
      "\n",
      "        --- Recommendation #2 (nearest neighbor 2 of 5) ---\n",
      "        String: Zapzyt Maximum Strength 10% Benzoyl Peroxide Acne Treatment Gel, 1 Ounce\n",
      "        Distance: 0.215\n",
      "\n",
      "        --- Recommendation #3 (nearest neighbor 3 of 5) ---\n",
      "        String: Zapzyt Maximum Strength 10% Benzoyl Peroxide Acne Treatment Gel, 1 Ounce\n",
      "        Distance: 0.215\n",
      "\n",
      "        --- Recommendation #4 (nearest neighbor 4 of 5) ---\n",
      "        String: Avalon Grapefruit and Geranium Smoothing Shampoo, 11 Ounce\n",
      "        Distance: 0.233\n",
      "\n",
      "        --- Recommendation #5 (nearest neighbor 5 of 5) ---\n",
      "        String: Avalon Grapefruit and Geranium Smoothing Shampoo, 11 Ounce\n",
      "        Distance: 0.233\n"
     ]
    }
   ],
   "source": [
    "def print_recommendations_from_strings(\n",
    "    strings: list[str],\n",
    "    index_of_source_string: int,\n",
    "    k_nearest_neighbors: int = 1,\n",
    "    model=EMBEDDING_MODEL,\n",
    ") -> list[int]:\n",
    "    \"\"\"Print out the k nearest neighbors of a given string.\"\"\"\n",
    "    # get embeddings for all strings\n",
    "    embeddings = [embedding_from_string(string, model=model) for string in strings]\n",
    "    # get the embedding of the source string\n",
    "    query_embedding = embeddings[index_of_source_string]\n",
    "    # get distances between the source embedding and other embeddings (function from embeddings_utils.py)\n",
    "    distances = distances_from_embeddings(query_embedding, embeddings, distance_metric=\"cosine\")\n",
    "    # get indices of nearest neighbors (function from embeddings_utils.py)\n",
    "    indices_of_nearest_neighbors = indices_of_nearest_neighbors_from_distances(distances)\n",
    "\n",
    "    # print out source string\n",
    "    query_string = strings[index_of_source_string]\n",
    "    print(f\"Source string: {query_string}\")\n",
    "    # print out its k nearest neighbors\n",
    "    k_counter = 0\n",
    "    for i in indices_of_nearest_neighbors:\n",
    "        # skip any strings that are identical matches to the starting string\n",
    "        if query_string == strings[i]:\n",
    "            continue\n",
    "        # stop after printing out k products\n",
    "        if k_counter >= k_nearest_neighbors:\n",
    "            break\n",
    "        k_counter += 1\n",
    "\n",
    "        # print out the similar strings and their distances\n",
    "        print(\n",
    "            f\"\"\"\n",
    "        --- Recommendation #{k_counter} (nearest neighbor {k_counter} of {k_nearest_neighbors}) ---\n",
    "        String: {strings[i]}\n",
    "        Distance: {distances[i]:0.3f}\"\"\"\n",
    "        )\n",
    "\n",
    "    return indices_of_nearest_neighbors\n",
    "\n",
    "product_titles = df[\"title\"].tolist()\n",
    "\n",
    "tony_blair_products = print_recommendations_from_strings(\n",
    "    strings=product_titles,  # let's base similarity off of the product title\n",
    "    index_of_source_string=0,  # let's look at products similar to the first one about\n",
    "    k_nearest_neighbors=5,  # let's look at the 5 most similar products\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression using embedding\n",
    "\n",
    "+ Obtain embeddings for each unique user ID.\n",
    "+ For each data point, concatenate the title embedding with the user embedding to form a combined feature vector.\n",
    "+ Split the dataset into training and test sets.\n",
    "+ Train the model on the combined embeddings and predict the test set.\n",
    "+ Evaluate using RMSE and MAE metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RetryError",
     "evalue": "RetryError[<Future at 0x13543f350 state=finished raised APIError>]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAPIError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/test/lib/python3.11/site-packages/tenacity/__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 382\u001b[0m     result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    383\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m:  \u001b[39m# noqa: B902\u001b[39;00m\n",
      "File \u001b[0;32m~/VSCode/recommender-system/recommender-system-openAI/rec-sys/notebook/large_amazon_data/../../embeddings.py:12\u001b[0m, in \u001b[0;36mget_embeddings\u001b[0;34m(texts, model)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39m@retry\u001b[39m(wait\u001b[39m=\u001b[39mwait_random_exponential(\u001b[39mmin\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, \u001b[39mmax\u001b[39m\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m), stop\u001b[39m=\u001b[39mstop_after_attempt(\u001b[39m6\u001b[39m))\n\u001b[1;32m     11\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_embeddings\u001b[39m(texts: \u001b[39mlist\u001b[39m[\u001b[39mstr\u001b[39m], model\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtext-embedding-ada-002\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mlist\u001b[39m[\u001b[39mlist\u001b[39m[\u001b[39mfloat\u001b[39m]]:\n\u001b[0;32m---> 12\u001b[0m     \u001b[39mreturn\u001b[39;00m [item[\u001b[39m\"\u001b[39m\u001b[39membedding\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m openai\u001b[39m.\u001b[39;49mEmbedding\u001b[39m.\u001b[39;49mcreate(\u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49mtexts, model\u001b[39m=\u001b[39;49mmodel)[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m]]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/test/lib/python3.11/site-packages/openai/api_resources/embedding.py:33\u001b[0m, in \u001b[0;36mEmbedding.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 33\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     35\u001b[0m     \u001b[39m# If a user specifies base64, we'll just return the encoded string.\u001b[39;00m\n\u001b[1;32m     36\u001b[0m     \u001b[39m# This is only for the default case.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/test/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    138\u001b[0m (\n\u001b[1;32m    139\u001b[0m     deployment_id,\n\u001b[1;32m    140\u001b[0m     engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m     api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m )\n\u001b[0;32m--> 153\u001b[0m response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    154\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    155\u001b[0m     url,\n\u001b[1;32m    156\u001b[0m     params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    157\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    158\u001b[0m     stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    159\u001b[0m     request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    160\u001b[0m     request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    161\u001b[0m )\n\u001b[1;32m    163\u001b[0m \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m     \u001b[39m# must be an iterator\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/test/lib/python3.11/site-packages/openai/api_requestor.py:226\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    216\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[1;32m    217\u001b[0m     method\u001b[39m.\u001b[39mlower(),\n\u001b[1;32m    218\u001b[0m     url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    224\u001b[0m     request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    225\u001b[0m )\n\u001b[0;32m--> 226\u001b[0m resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[1;32m    227\u001b[0m \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/test/lib/python3.11/site-packages/openai/api_requestor.py:620\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    619\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 620\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[1;32m    621\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    622\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[1;32m    623\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    624\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    625\u001b[0m         ),\n\u001b[1;32m    626\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    627\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/test/lib/python3.11/site-packages/openai/api_requestor.py:683\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[0;32m--> 683\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[1;32m    684\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[1;32m    685\u001b[0m     )\n\u001b[1;32m    686\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mAPIError\u001b[0m: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Fri, 20 Oct 2023 02:00:41 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '818dab27f9735a73-MEL', 'alt-svc': 'h3=\":443\"; ma=86400'}",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRetryError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m<timed eval>:1\u001b[0m\n",
      "File \u001b[0;32m~/VSCode/recommender-system/recommender-system-openAI/rec-sys/notebook/large_amazon_data/../../embeddings.py:23\u001b[0m, in \u001b[0;36mtrain_and_evaluate_embeddings_model\u001b[0;34m(df, columns_for_unique_pairs, batch_size, RANDOM_STATE, TEST_SIZE, N_ESTIMATORS)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(df[column]), batch_size):\n\u001b[1;32m     22\u001b[0m         batch_texts \u001b[39m=\u001b[39m df[column]\u001b[39m.\u001b[39miloc[i:i\u001b[39m+\u001b[39mbatch_size]\u001b[39m.\u001b[39mtolist()\n\u001b[0;32m---> 23\u001b[0m         column_embeddings\u001b[39m.\u001b[39mextend(get_embeddings(batch_texts))\n\u001b[1;32m     24\u001b[0m     embeddings[column] \u001b[39m=\u001b[39m column_embeddings\n\u001b[1;32m     26\u001b[0m \u001b[39m# Get embeddings for unique users\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/test/lib/python3.11/site-packages/tenacity/__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[1;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_f\u001b[39m(\u001b[39m*\u001b[39margs: t\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mAny:\n\u001b[0;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(f, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/test/lib/python3.11/site-packages/tenacity/__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m retry_state \u001b[39m=\u001b[39m RetryCallState(retry_object\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, fn\u001b[39m=\u001b[39mfn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[1;32m    378\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 379\u001b[0m     do \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter(retry_state\u001b[39m=\u001b[39;49mretry_state)\n\u001b[1;32m    380\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/test/lib/python3.11/site-packages/tenacity/__init__.py:326\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreraise:\n\u001b[1;32m    325\u001b[0m         \u001b[39mraise\u001b[39;00m retry_exc\u001b[39m.\u001b[39mreraise()\n\u001b[0;32m--> 326\u001b[0m     \u001b[39mraise\u001b[39;00m retry_exc \u001b[39mfrom\u001b[39;00m \u001b[39mfut\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexception\u001b[39;00m()\n\u001b[1;32m    328\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwait:\n\u001b[1;32m    329\u001b[0m     sleep \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwait(retry_state)\n",
      "\u001b[0;31mRetryError\u001b[0m: RetryError[<Future at 0x13543f350 state=finished raised APIError>]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_and_evaluate_embeddings_model(df, columns_for_unique_pairs=['title', 'reviewText'], batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "+ https://cookbook.openai.com/examples/recommendation_using_embeddings\n",
    "+ https://github.com/openai/openai-python/blob/main/openai/embeddings_utils.py\n",
    "+ https://help.openai.com/en/products/6824809-embeddings-frequently-asked-questions\n",
    "+ https://platform.openai.com/docs/guides/embeddings/use-cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
