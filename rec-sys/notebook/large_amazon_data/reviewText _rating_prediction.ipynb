{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "current directory: /Users/tnathu-ai/VSCode/recommender-system/recommender-system-openAI/rec-sys/data/amazon-beauty\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import openai\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import sys\n",
    "import re\n",
    "import time\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "\n",
    "# Add the path to the constants file to the system path\n",
    "sys.path.append('../../')\n",
    "from constants import *\n",
    "from evaluation_utils import *\n",
    "from ChatCompletion_OpenAI_API import *\n",
    "\n",
    "# OpenAI API Key\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "# Get the current directory of the notebook\n",
    "current_dir = os.path.dirname(os.path.abspath(\"../../data/amazon-beauty/rating_prediction.ipynb\"))\n",
    "print(f\"current directory: {current_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RMSE & MAE evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  1.0\n",
      "MAE:  1.0\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "actual_ratings = [4, 4]  # Ground truth ratings\n",
    "predicted_ratings = [3, 5]  # Predicted ratings\n",
    "rmse, mae = calculate_rmse_and_mae(actual_ratings, predicted_ratings)\n",
    "print(\"RMSE: \", rmse)\n",
    "print(\"MAE: \", mae)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data path: /Users/tnathu-ai/VSCode/recommender-system/recommender-system-openAI/rec-sys/data/amazon-beauty/large_merged_data.csv\n"
     ]
    }
   ],
   "source": [
    "# Construct the path to data file\n",
    "data_path = os.path.join(current_dir, 'large_merged_data.csv')\n",
    "print(f'data path: {data_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9767 entries, 0 to 9766\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   rating      9767 non-null   float64\n",
      " 1   reviewerID  9767 non-null   object \n",
      " 2   asin        9767 non-null   object \n",
      " 3   reviewText  9759 non-null   object \n",
      " 4   summary     9759 non-null   object \n",
      " 5   category    9767 non-null   object \n",
      " 6   title       9767 non-null   object \n",
      "dtypes: float64(1), object(6)\n",
      "memory usage: 534.3+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>rating</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewerID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jenna Jameson Heartbreaker Perfume for women 3...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I use a lot of perfume, I go through a new bot...</td>\n",
       "      <td>A2RYSCZOPEXOCQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Norelco 6885XL Deluxe Quadra Action Cord/Cordl...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>First, a little background.  I've switched bet...</td>\n",
       "      <td>A141OPVE376YFI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Norelco 6885XL Deluxe Quadra Action Cord/Cordl...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>First, a little background.  I've switched bet...</td>\n",
       "      <td>A141OPVE376YFI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  rating  \\\n",
       "0  Jenna Jameson Heartbreaker Perfume for women 3...     1.0   \n",
       "1  Norelco 6885XL Deluxe Quadra Action Cord/Cordl...     5.0   \n",
       "2  Norelco 6885XL Deluxe Quadra Action Cord/Cordl...     5.0   \n",
       "\n",
       "                                          reviewText      reviewerID  \n",
       "0  I use a lot of perfume, I go through a new bot...  A2RYSCZOPEXOCQ  \n",
       "1  First, a little background.  I've switched bet...  A141OPVE376YFI  \n",
       "2  First, a little background.  I've switched bet...  A141OPVE376YFI  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data\n",
    "data = pd.read_csv(data_path)\n",
    "# get sample data of NUM_SAMPLES rows\n",
    "data.info()\n",
    "# get neccessary columns\n",
    "data = data[['title', 'rating', 'reviewText', 'reviewerID']]\n",
    "data.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero-shot (OpenAI API)\n",
    "\n",
    "+ We used the ``.drop_duplicates()`` method to get unique pairs of \"title\" and \"reviewText\". The predictions are then based on both the title and the corresponding review text for each unique pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RetryError",
     "evalue": "RetryError[<Future at 0x131fe2450 state=finished raised APIError>]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAPIError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/test/lib/python3.11/site-packages/tenacity/__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 382\u001b[0m     result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    383\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m:  \u001b[39m# noqa: B902\u001b[39;00m\n",
      "File \u001b[0;32m~/VSCode/recommender-system/recommender-system-openAI/rec-sys/notebook/large_amazon_data/../../ChatCompletion_OpenAI_API.py:20\u001b[0m, in \u001b[0;36mpredict_rating_zero_shot_ChatCompletion\u001b[0;34m(title, model, temperature)\u001b[0m\n\u001b[1;32m     18\u001b[0m prompt \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mHow will users rate this product title: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mtitle\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m? (1 being lowest and 5 being highest) Attention! Just give me back the exact whole number as a result, and you don\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt need a lot of text.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 20\u001b[0m response \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mChatCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m     21\u001b[0m     model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m     22\u001b[0m     temperature\u001b[39m=\u001b[39;49mtemperature,\n\u001b[1;32m     23\u001b[0m     messages\u001b[39m=\u001b[39;49m[\n\u001b[1;32m     24\u001b[0m         {\n\u001b[1;32m     25\u001b[0m             \u001b[39m\"\u001b[39;49m\u001b[39mrole\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39msystem\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     26\u001b[0m             \u001b[39m\"\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39mYou are an Amazon Beauty products critic.\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m     27\u001b[0m         },\n\u001b[1;32m     28\u001b[0m         {\n\u001b[1;32m     29\u001b[0m             \u001b[39m\"\u001b[39;49m\u001b[39mrole\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39muser\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     30\u001b[0m             \u001b[39m\"\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m\"\u001b[39;49m: prompt\n\u001b[1;32m     31\u001b[0m         }\n\u001b[1;32m     32\u001b[0m     ]\n\u001b[1;32m     33\u001b[0m )\n\u001b[1;32m     35\u001b[0m rating_text \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mchoices[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mmessage[\u001b[39m'\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mstrip()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/test/lib/python3.11/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/test/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    138\u001b[0m (\n\u001b[1;32m    139\u001b[0m     deployment_id,\n\u001b[1;32m    140\u001b[0m     engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m     api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m )\n\u001b[0;32m--> 153\u001b[0m response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    154\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    155\u001b[0m     url,\n\u001b[1;32m    156\u001b[0m     params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    157\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    158\u001b[0m     stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    159\u001b[0m     request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    160\u001b[0m     request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    161\u001b[0m )\n\u001b[1;32m    163\u001b[0m \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m     \u001b[39m# must be an iterator\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/test/lib/python3.11/site-packages/openai/api_requestor.py:226\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    216\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[1;32m    217\u001b[0m     method\u001b[39m.\u001b[39mlower(),\n\u001b[1;32m    218\u001b[0m     url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    224\u001b[0m     request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    225\u001b[0m )\n\u001b[0;32m--> 226\u001b[0m resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[1;32m    227\u001b[0m \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/test/lib/python3.11/site-packages/openai/api_requestor.py:620\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    619\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 620\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[1;32m    621\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    622\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[1;32m    623\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    624\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    625\u001b[0m         ),\n\u001b[1;32m    626\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    627\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/test/lib/python3.11/site-packages/openai/api_requestor.py:683\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[0;32m--> 683\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[1;32m    684\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[1;32m    685\u001b[0m     )\n\u001b[1;32m    686\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mAPIError\u001b[0m: Internal server error {\n    \"error\": {\n        \"message\": \"Internal server error\",\n        \"type\": \"auth_subrequest_error\",\n        \"param\": null,\n        \"code\": \"internal_error\"\n    }\n}\n 500 {'error': {'message': 'Internal server error', 'type': 'auth_subrequest_error', 'param': None, 'code': 'internal_error'}} {'Date': 'Fri, 20 Oct 2023 02:01:32 GMT', 'Content-Type': 'application/json; charset=utf-8', 'Content-Length': '166', 'Connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': '371487f9324dcc7f8efd2191b7021ef8', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '818dac46597d2e6e-MEL', 'alt-svc': 'h3=\":443\"; ma=86400'}",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRetryError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:9\u001b[0m\n",
      "File \u001b[0;32m<timed exec>:3\u001b[0m, in \u001b[0;36mpredict_rating_zero_shot_with_review\u001b[0;34m(title, review)\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/test/lib/python3.11/site-packages/tenacity/__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[1;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_f\u001b[39m(\u001b[39m*\u001b[39margs: t\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mAny:\n\u001b[0;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(f, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/test/lib/python3.11/site-packages/tenacity/__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m retry_state \u001b[39m=\u001b[39m RetryCallState(retry_object\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, fn\u001b[39m=\u001b[39mfn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[1;32m    378\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 379\u001b[0m     do \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter(retry_state\u001b[39m=\u001b[39;49mretry_state)\n\u001b[1;32m    380\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/test/lib/python3.11/site-packages/tenacity/__init__.py:326\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreraise:\n\u001b[1;32m    325\u001b[0m         \u001b[39mraise\u001b[39;00m retry_exc\u001b[39m.\u001b[39mreraise()\n\u001b[0;32m--> 326\u001b[0m     \u001b[39mraise\u001b[39;00m retry_exc \u001b[39mfrom\u001b[39;00m \u001b[39mfut\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexception\u001b[39;00m()\n\u001b[1;32m    328\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwait:\n\u001b[1;32m    329\u001b[0m     sleep \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwait(retry_state)\n",
      "\u001b[0;31mRetryError\u001b[0m: RetryError[<Future at 0x131fe2450 state=finished raised APIError>]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Function to predict rating using both title and reviewText\n",
    "def predict_rating_zero_shot_with_review(title, review):\n",
    "    return predict_rating_zero_shot_ChatCompletion(f\"{title}. {review}\")\n",
    "\n",
    "# Iterate through the dataset and predict ratings\n",
    "predicted_ratings = []\n",
    "unique_pairs = data[['title', 'reviewText']].drop_duplicates().values\n",
    "for idx, (title, review) in enumerate(unique_pairs):\n",
    "    predicted_rating = predict_rating_zero_shot_with_review(title, review)\n",
    "    print(f\"Predicted rating for {title}: {predicted_rating}\")\n",
    "    predicted_ratings.append(predicted_rating)\n",
    "    \n",
    "    # Pause every PAUSE_EVERY_N_USERS rows\n",
    "    if (idx + 1) % PAUSE_EVERY_N_USERS == 0:\n",
    "        print(f\"Pausing for {SLEEP_TIME} seconds...\")\n",
    "        time.sleep(SLEEP_TIME)\n",
    "\n",
    "# Create a DataFrame with titles, reviewText and predicted ratings\n",
    "predicted_ratings_df = pd.DataFrame({\n",
    "    'title': unique_pairs[:, 0],\n",
    "    'reviewText': unique_pairs[:, 1],\n",
    "    'zero_shot_predicted_rating': predicted_ratings\n",
    "})\n",
    "\n",
    "# Merge the predicted ratings with the original data\n",
    "merged_data_with_predictions = pd.merge(data, predicted_ratings_df, on=['title', 'reviewText'])\n",
    "\n",
    "# Save the merged data with predictions to a new CSV file\n",
    "merged_data_with_predictions.to_csv('../../data/amazon-beauty/reviewText_large_predictions_zero_shot.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the rating prediction model\n",
    "\n",
    "product_titles = merged_data_with_predictions['title']\n",
    "actual_ratings = merged_data_with_predictions['rating']\n",
    "\n",
    "# Remove None predictions if any\n",
    "actual_ratings_filtered, predicted_ratings_filtered = zip(*[(actual, predicted) for actual, predicted in zip(actual_ratings, predicted_ratings) if predicted is not None])\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(actual_ratings_filtered, predicted_ratings_filtered))\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse}')\n",
    "\n",
    "# Calculate MAE\n",
    "mae = mean_absolute_error(actual_ratings_filtered, predicted_ratings_filtered)\n",
    "print(f'Mean Absolute Error (MAE): {mae}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Few-shot (OpenAI API)\n",
    "\n",
    "\n",
    "+ For each user, we'll use 4 of their ratings as training data to predict ratings for the rest of their products. Finally, we'll evaluate the predictions against the actual ratings to calculate the overall RMSE and MAE.\n",
    "\n",
    "+ The rating_history_str now includes both the title and the review text for each of the training data rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Function to predict rating using both title and reviewText with user's rating history\n",
    "def predict_rating_few_shot_with_review(title, review, rating_history_str):\n",
    "    return predict_rating_few_shot_ChatCompletion(f\"{title}. {review}\", rating_history_str)\n",
    "\n",
    "predicted_ratings = []\n",
    "actual_ratings = []\n",
    "\n",
    "# For each user in the dataset\n",
    "users = data['reviewerID'].unique()\n",
    "for idx, reviewerID in enumerate(users):\n",
    "    user_data = data[data['reviewerID'] == reviewerID]\n",
    "    \n",
    "    # Check if the user has at least 5 ratings\n",
    "    if len(user_data) >= 5:\n",
    "        train_data = user_data.sample(4, random_state=RANDOM_STATE)\n",
    "        test_data = user_data.drop(train_data.index)\n",
    "\n",
    "        # For each product in the testing set, use the training data to predict a rating\n",
    "        for _, test_row in test_data.iterrows():\n",
    "            rating_history_str = ', '.join([f\"{row['title']} ({row['rating']} stars): {row['reviewText']}\" for _, row in train_data.iterrows()])\n",
    "            predicted_rating = predict_rating_few_shot_with_review(test_row['title'], test_row['reviewText'], rating_history_str)\n",
    "            \n",
    "            predicted_ratings.append(predicted_rating)\n",
    "            actual_ratings.append(test_row['rating'])\n",
    "    \n",
    "    # Introduce a pause after processing every PAUSE_EVERY_N_USERS\n",
    "    if (idx + 1) % PAUSE_EVERY_N_USERS == 0:\n",
    "        print(f\"Processed {idx + 1} users. Pausing for {SLEEP_TIME} seconds...\")\n",
    "        time.sleep(SLEEP_TIME)\n",
    "\n",
    "# Save the predicted ratings to a new CSV file\n",
    "predicted_ratings_df = pd.DataFrame({\n",
    "    'few_shot_predicted_rating': predicted_ratings,\n",
    "    'actual_rating': actual_ratings\n",
    "})\n",
    "predicted_ratings_df.to_csv('../../data/amazon-beauty/reviewText_large_predictions_few_shot.csv', index=False)\n",
    "\n",
    "predicted_ratings_df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from ../../data/amazon-beauty/large_predictions_few_shot.csv file\n",
    "large_predictions_few_shot = pd.read_csv('../../data/amazon-beauty/reviewText_large_predictions_few_shot.csv')\n",
    "large_predictions_few_shot.head(NUM_EXAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert few_shot_predicted_rating column to list\n",
    "predicted_ratings = large_predictions_few_shot['few_shot_predicted_rating'].tolist()\n",
    "# convert actual_rating column to list\n",
    "actual_ratings = large_predictions_few_shot['actual_rating'].tolist()\n",
    "filtered_list = [(actual, predicted) for actual, predicted in zip(actual_ratings, predicted_ratings) if predicted is not None]\n",
    "\n",
    "if not filtered_list:\n",
    "    print(\"No valid predictions available for evaluation.\")\n",
    "else:\n",
    "    actual_ratings_filtered, predicted_ratings_filtered = zip(*filtered_list)\n",
    "    # Evaluate the model's performance\n",
    "    rmse = np.sqrt(mean_squared_error(actual_ratings_filtered, predicted_ratings_filtered))\n",
    "    print(f'Root Mean Squared Error (RMSE): {rmse}')\n",
    "\n",
    "    mae = mean_absolute_error(actual_ratings_filtered, predicted_ratings_filtered)\n",
    "    print(f'Mean Absolute Error (MAE): {mae}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 observation per reviewer - Few-shot OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Function to predict rating using both title and reviewText with user's rating history\n",
    "def predict_rating_few_shot_with_review(title, review, rating_history_str):\n",
    "    return predict_rating_few_shot_ChatCompletion(f\"{title}. {review}\", rating_history_str)\n",
    "\n",
    "\n",
    "predicted_ratings = []\n",
    "actual_ratings = []\n",
    "\n",
    "# For each user in the dataset\n",
    "users = data['reviewerID'].unique()\n",
    "for idx, reviewerID in enumerate(users):\n",
    "    user_data = data[data['reviewerID'] == reviewerID]\n",
    "    \n",
    "    # Check if the user has at least 5 ratings\n",
    "    if len(user_data) >= 5:\n",
    "        # Sample one observation for the test set\n",
    "        test_data = user_data.sample(1, random_state=RANDOM_STATE)\n",
    "        \n",
    "        # Use the remaining data for training\n",
    "        train_data = user_data.drop(test_data.index)\n",
    "\n",
    "        # For the single product in the testing set, use the training data to predict a rating\n",
    "        for _, test_row in test_data.iterrows():\n",
    "            rating_history_str = ', '.join([f\"{row['title']} ({row['rating']} stars): {row['reviewText']}\" for _, row in train_data.iterrows()])\n",
    "            predicted_rating = predict_rating_few_shot_with_review(test_row['title'], test_row['reviewText'], rating_history_str)\n",
    "            \n",
    "            predicted_ratings.append(predicted_rating)\n",
    "            actual_ratings.append(test_row['rating'])\n",
    "    \n",
    "    # Introduce a pause after processing every PAUSE_EVERY_N_USERS\n",
    "    if (idx + 1) % PAUSE_EVERY_N_USERS == 0:\n",
    "        print(f\"Processed {idx + 1} users. Pausing for {SLEEP_TIME} seconds...\")\n",
    "        time.sleep(SLEEP_TIME)\n",
    "\n",
    "# Save the predicted ratings to a new CSV file\n",
    "predicted_ratings_df = pd.DataFrame({\n",
    "    'few_shot_predicted_rating': predicted_ratings,\n",
    "    'actual_rating': actual_ratings\n",
    "})\n",
    "\n",
    "predicted_ratings_df.to_csv('../../data/amazon-beauty/reviewText_large_1_test_predictions_few_shot.csv', index=False)\n",
    "\n",
    "predicted_ratings_df.head(NUM_EXAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_predictions_few_shot = pd.read_csv('../../data/amazon-beauty/reviewText_large_1_test_predictions_few_shot.csv')\n",
    "large_predictions_few_shot.head(NUM_EXAMPLES)\n",
    "# convert few_shot_predicted_rating column to list\n",
    "predicted_ratings = large_predictions_few_shot['few_shot_predicted_rating'].tolist()\n",
    "# convert actual_rating column to list\n",
    "actual_ratings = large_predictions_few_shot['actual_rating'].tolist()\n",
    "filtered_list = [(actual, predicted) for actual, predicted in zip(actual_ratings, predicted_ratings) if predicted is not None]\n",
    "\n",
    "if not filtered_list:\n",
    "    print(\"No valid predictions available for evaluation.\")\n",
    "else:\n",
    "    actual_ratings_filtered, predicted_ratings_filtered = zip(*filtered_list)\n",
    "    # Evaluate the model's performance\n",
    "    rmse = np.sqrt(mean_squared_error(actual_ratings_filtered, predicted_ratings_filtered))\n",
    "    print(f'Root Mean Squared Error (RMSE): {rmse}')\n",
    "\n",
    "    mae = mean_absolute_error(actual_ratings_filtered, predicted_ratings_filtered)\n",
    "    print(f'Mean Absolute Error (MAE): {mae}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limitations:\n",
    "\n",
    "The model might not fully understand the nuanced relationships between products based on titles alone. Additional context or features might be needed for more accurate predictions.\n",
    "This approach might be computationally expensive and slower than traditional matrix factorization or deep learning-based recommendation models, especially for a large number of users.\n",
    "\n",
    "# References\n",
    "\n",
    "+ https://platform.openai.com/docs/api-reference/authentication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Advanced_Programming_for_Data_Science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
