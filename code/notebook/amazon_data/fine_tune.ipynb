{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "current directory: /Users/tnathu-ai/VSCode/recommender-system/recommender-system-openAI/code/data/amazon-beauty\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import openai\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import signal\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import sys\n",
    "# Add the path to the constants file to the system path\n",
    "sys.path.append('../../')\n",
    "from constants import RANDOM_STATE, OPENAI_API_KEY\n",
    "\n",
    "# OpenAI API Key\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "# OpenAI GPT Model parameters\n",
    "GPT_MODEL_NAME = \"gpt-3.5-turbo\"\n",
    "TEMPERATURE = 0\n",
    "\n",
    "# Get the current directory of the notebook\n",
    "current_dir = os.path.dirname(os.path.abspath(\"../../data/amazon-beauty/fine_tune.ipynb\"))\n",
    "print(f\"current directory: {current_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data path: /Users/tnathu-ai/VSCode/recommender-system/recommender-system-openAI/code/data/amazon-beauty/merged_data.csv\n"
     ]
    }
   ],
   "source": [
    "# Construct the path to data file\n",
    "data_path = os.path.join(current_dir, 'merged_data.csv')\n",
    "print(f'data path: {data_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert the pandas DataFrame to JSONL format:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset\n",
    "movie_data = pd.read_csv(data_path)\n",
    "\n",
    "# Split the dataset into training and validation sets (80-20% split)\n",
    "train_data = movie_data.sample(frac=0.8, random_state=RANDOM_STATE)\n",
    "validation_data = movie_data.drop(train_data.index)\n",
    "\n",
    "# Convert the DataFrame to a list of dictionaries for training data\n",
    "training_data = []\n",
    "for index, row in train_data.iterrows():\n",
    "    prompt = f\"Title: {row['title']}\"\n",
    "    completion = str(row['rating'])\n",
    "    training_data.append({\"prompt\": prompt, \"completion\": completion})\n",
    "\n",
    "# Repeat for validation data\n",
    "validation_data_list = []\n",
    "for index, row in validation_data.iterrows():\n",
    "    prompt = f\"Title: {row['title']}\"\n",
    "    completion = str(row['rating'])\n",
    "    validation_data_list.append({\"prompt\": prompt, \"completion\": completion})\n",
    "\n",
    "# Define the current directory\n",
    "current_dir = os.path.dirname(os.path.abspath(\"../../data/amazon-beauty/fine_tune.ipynb\"))\n",
    "\n",
    "# Save the data in JSONL format\n",
    "training_file_name = os.path.join(current_dir, \"training_data.jsonl\")\n",
    "validation_file_name = os.path.join(current_dir, \"validation_data.jsonl\")\n",
    "\n",
    "def prepare_data(dictionary_data, final_file_name):\n",
    "    with open(final_file_name, 'w') as outfile:\n",
    "        for entry in dictionary_data:\n",
    "            json.dump(entry, outfile)\n",
    "            outfile.write('\\n')\n",
    "\n",
    "prepare_data(training_data, training_file_name)\n",
    "prepare_data(validation_data_list, validation_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning model with jobID: ft-ifP1a6eOV8nLQqRdqiVWrPPh.\n",
      "Training Response: {\n",
      "  \"created_at\": 1695959342,\n",
      "  \"events\": [\n",
      "    {\n",
      "      \"created_at\": 1695959342,\n",
      "      \"level\": \"info\",\n",
      "      \"message\": \"Created fine-tune: ft-ifP1a6eOV8nLQqRdqiVWrPPh\",\n",
      "      \"object\": \"fine-tune-event\"\n",
      "    }\n",
      "  ],\n",
      "  \"fine_tuned_model\": null,\n",
      "  \"hyperparams\": {\n",
      "    \"batch_size\": 2,\n",
      "    \"learning_rate_multiplier\": 0.5,\n",
      "    \"n_epochs\": 10,\n",
      "    \"prompt_loss_weight\": 0.01\n",
      "  },\n",
      "  \"id\": \"ft-ifP1a6eOV8nLQqRdqiVWrPPh\",\n",
      "  \"model\": \"davinci\",\n",
      "  \"object\": \"fine-tune\",\n",
      "  \"organization_id\": \"org-ppCCXZWpTaByE4cI4jMbZjBx\",\n",
      "  \"result_files\": [],\n",
      "  \"status\": \"pending\",\n",
      "  \"training_files\": [\n",
      "    {\n",
      "      \"bytes\": 3260,\n",
      "      \"created_at\": 1695959341,\n",
      "      \"filename\": \"file\",\n",
      "      \"id\": \"file-BINZ0Wf02A1T9y3v5P3UQGbE\",\n",
      "      \"object\": \"file\",\n",
      "      \"purpose\": \"fine-tune\",\n",
      "      \"status\": \"uploaded\",\n",
      "      \"status_details\": null\n",
      "    }\n",
      "  ],\n",
      "  \"updated_at\": 1695959342,\n",
      "  \"validation_files\": [\n",
      "    {\n",
      "      \"bytes\": 824,\n",
      "      \"created_at\": 1695959342,\n",
      "      \"filename\": \"file\",\n",
      "      \"id\": \"file-ssac5GriMbeq8jH24bXboxWM\",\n",
      "      \"object\": \"file\",\n",
      "      \"purpose\": \"fine-tune\",\n",
      "      \"status\": \"uploaded\",\n",
      "      \"status_details\": null\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Training Status: pending\n",
      "Waiting for fine-tuning to complete. Current status: pending\n",
      "Waiting for fine-tuning to complete. Current status: pending\n",
      "Waiting for fine-tuning to complete. Current status: pending\n",
      "Waiting for fine-tuning to complete. Current status: pending\n",
      "Waiting for fine-tuning to complete. Current status: pending\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Upload the datasets to OpenAI\n",
    "def upload_data_to_OpenAI(file_name):\n",
    "    with open(file_name, \"rb\") as f:\n",
    "        response = openai.File.create(file=f, purpose='fine-tune')\n",
    "        return response.id\n",
    "\n",
    "training_file_id = upload_data_to_OpenAI(training_file_name)\n",
    "validation_file_id = upload_data_to_OpenAI(validation_file_name)\n",
    "\n",
    "# Adjusted fine-tuning parameters\n",
    "create_args = {\n",
    "    \"training_file\": training_file_id,\n",
    "    \"validation_file\": validation_file_id,\n",
    "    \"model\": \"davinci\",\n",
    "    \"n_epochs\": 10,               # Reduced number of epochs\n",
    "    \"batch_size\": 2,              # Reduced batch size\n",
    "    \"learning_rate_multiplier\": 0.5  # Slightly increased learning rate\n",
    "}\n",
    "\n",
    "response = openai.FineTune.create(**create_args)\n",
    "job_id = response[\"id\"]\n",
    "status = response[\"status\"]\n",
    "\n",
    "print(f'Fine-tuning model with jobID: {job_id}.')\n",
    "print(f\"Training Response: {response}\")\n",
    "print(f\"Training Status: {status}\")\n",
    "\n",
    "\n",
    "# Wait for the fine-tuning to complete\n",
    "while status != \"succeeded\":\n",
    "    print(f\"Waiting for fine-tuning to complete. Current status: {status}\")\n",
    "    time.sleep(60)  # Wait for 60 seconds before checking again\n",
    "    response = openai.FineTune.retrieve(job_id)\n",
    "    status = response[\"status\"]\n",
    "\n",
    "# Once the fine-tuning is complete, proceed with the rest of the code\n",
    "fine_tuned_model = response[\"id\"]\n",
    "\n",
    "# Generate predictions using the fine-tuned model\n",
    "def get_model_predictions(model, prompts):\n",
    "    predictions = []\n",
    "    for prompt in prompts:\n",
    "        response = openai.Completion.create(model=model, prompt=prompt)\n",
    "        predictions.append(float(response['choices'][0]['text'].strip()))\n",
    "    return predictions\n",
    "\n",
    "# Prepare prompts from validation_data for rating predictions\n",
    "prompts = validation_data['title'].tolist()  # Assuming 'title' is the feature you want to use for prediction\n",
    "\n",
    "# Get predictions\n",
    "predicted_ratings = get_model_predictions(fine_tuned_model, prompts)\n",
    "\n",
    "# True ratings from the validation set\n",
    "true_ratings = validation_data['rating'].tolist()\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "mae = mean_absolute_error(true_ratings, predicted_ratings)\n",
    "mse = mean_squared_error(true_ratings, predicted_ratings)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Stream events to monitor fine-tuning progress\n",
    "def signal_handler(sig, frame):\n",
    "    status = openai.FineTune.retrieve(job_id).status\n",
    "    print(f\"Stream interrupted. Job is still {status}.\")\n",
    "    return\n",
    "\n",
    "print(f'Streaming events for the fine-tuning job: {job_id}')\n",
    "signal.signal(signal.SIGINT, signal_handler)\n",
    "\n",
    "events = openai.FineTune.stream_events(job_id)\n",
    "try:\n",
    "    for event in events:\n",
    "        print(f'{datetime.datetime.fromtimestamp(event[\"created_at\"])} {event[\"message\"]}')\n",
    "except Exception:\n",
    "    print(\"Stream interrupted (client disconnected).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Checking other finetune jobs in the subscription.')\n",
    "result = openai.FineTune.list()\n",
    "print(f'Found {len(result.data)} finetune jobs.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the finetuned model\n",
    "fine_tuned_model = result\n",
    "print(fine_tuned_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Retrieve fine-tuned model ID\n",
    "fine_tuned_model_id = response[\"id\"]\n",
    "print(f\"Fine-tuned model ID: {fine_tuned_model_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Completion of Fine-tuning: \n",
    "\n",
    "Ensure that the fine-tuning process for the model has been completed successfully. It's possible that the model is still being fine-tuned or there was an issue during the fine-tuning process.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "+ https://platform.openai.com/docs/guides/fine-tuning/use-a-fine-tuned-model\n",
    "+ https://platform.openai.com/docs/guides/fine-tuning/estimate-costs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
