{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Rec-sys directory: /Users/tnathu-ai/VSCode/recommender-system/recommender-system-openAI/code/notebook\n",
      "Data directory: /Users/tnathu-ai/VSCode/recommender-system/recommender-system-openAI/code/notebook/../data\n",
      "Data path: /Users/tnathu-ai/VSCode/recommender-system/recommender-system-openAI/code/notebook/../data/ml-1m/merged_data.dat\n",
      "Data path: /Users/tnathu-ai/VSCode/recommender-system/recommender-system-openAI/code/notebook/../data/ml-1m/output/CF_fewshot_output_path_ratings_per_user.dat\n",
      "Data path: /Users/tnathu-ai/VSCode/recommender-system/recommender-system-openAI/code/notebook/../data/ml-1m/output/rerun_CF_fewshot_output_path_ratings_per_user.dat\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import openai\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.sparse import csr_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import openai\n",
    "# Add the path to the constants file to the system path\n",
    "sys.path.append('../../../')\n",
    "from constants import *\n",
    "from evaluation_utils import *\n",
    "from path_utils import *\n",
    "from ChatCompletion_OpenAI_API import *\n",
    "from CF_utils import *\n",
    "\n",
    "# OpenAI API Key\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "# source code folder path\n",
    "rec_sys_dir = get_rec_sys_directory()\n",
    "print(f\"Rec-sys directory: {rec_sys_dir}\")\n",
    "\n",
    "# data folder path\n",
    "DATA_DIR = os.path.join(rec_sys_dir, '../data')\n",
    "print(f\"Data directory: {DATA_DIR}\")\n",
    "\n",
    "# data path\n",
    "data_path = os.path.join(DATA_DIR, 'ml-1m/merged_data.dat')\n",
    "print(f'Data path: {data_path}')\n",
    "\n",
    "# output\n",
    "\n",
    "CF_OUTPUT_PATH = os.path.join(DATA_DIR, 'ml-1m/output/CF_fewshot_output_path_ratings_per_user.dat')\n",
    "print(f'Data path: {CF_OUTPUT_PATH}')\n",
    "\n",
    "CF_RERUN_PATH = os.path.join(DATA_DIR, 'ml-1m/output/rerun_CF_fewshot_output_path_ratings_per_user.dat')\n",
    "print(f'Data path: {CF_RERUN_PATH}')\n",
    "\n",
    "\n",
    "# Constants for column names\n",
    "USER_COLUMN_NAME = 'UserID'\n",
    "TITLE_COLUMN_NAME = 'Title'\n",
    "ITEM_ID_COLUMN = 'MovieID'\n",
    "RATING_COLUMN_NAME = 'Rating'\n",
    "\n",
    "SYSTEM_CONTENT = MOVIELENS_CONTENT_SYSTEM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Zip-code</th>\n",
       "      <th>Title</th>\n",
       "      <th>Genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978298413</td>\n",
       "      <td>M</td>\n",
       "      <td>56</td>\n",
       "      <td>16</td>\n",
       "      <td>70072</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>1193</td>\n",
       "      <td>4</td>\n",
       "      <td>978220179</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>32793</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID  MovieID  Rating  Timestamp Gender  Age  Occupation Zip-code  \\\n",
       "0       1     1193       5  978300760      F    1          10    48067   \n",
       "1       2     1193       5  978298413      M   56          16    70072   \n",
       "2      12     1193       4  978220179      M   25          12    32793   \n",
       "\n",
       "                                    Title Genres  \n",
       "0  One Flew Over the Cuckoo's Nest (1975)  Drama  \n",
       "1  One Flew Over the Cuckoo's Nest (1975)  Drama  \n",
       "2  One Flew Over the Cuckoo's Nest (1975)  Drama  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(data_path)\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>MovieID</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>3943</th>\n",
       "      <th>3944</th>\n",
       "      <th>3945</th>\n",
       "      <th>3946</th>\n",
       "      <th>3947</th>\n",
       "      <th>3948</th>\n",
       "      <th>3949</th>\n",
       "      <th>3950</th>\n",
       "      <th>3951</th>\n",
       "      <th>3952</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UserID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6036</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6037</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6038</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6039</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6040</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6040 rows × 3706 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "MovieID  1     2     3     4     5     6     7     8     9     10    ...  \\\n",
       "UserID                                                               ...   \n",
       "1         5.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "2         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "3         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "4         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "5         0.0   0.0   0.0   0.0   0.0   2.0   0.0   0.0   0.0   0.0  ...   \n",
       "...       ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n",
       "6036      0.0   0.0   0.0   2.0   0.0   3.0   0.0   0.0   0.0   0.0  ...   \n",
       "6037      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "6038      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "6039      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "6040      3.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "\n",
       "MovieID  3943  3944  3945  3946  3947  3948  3949  3950  3951  3952  \n",
       "UserID                                                               \n",
       "1         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "5         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "...       ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "6036      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "6037      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "6038      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "6039      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "6040      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[6040 rows x 3706 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create User-Item Interaction Matrix\n",
    "interaction_matrix = pd.pivot_table(data, index=USER_COLUMN_NAME, columns=ITEM_ID_COLUMN, values=RATING_COLUMN_NAME).fillna(0)\n",
    "csr_interaction_matrix = csr_matrix(interaction_matrix.values)\n",
    "\n",
    "interaction_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6040x3706 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1000209 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csr_interaction_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "EPSILON_CONSTANT = 1e-9\n",
    "\n",
    "def pearson_correlation(interaction_matrix, epsilon_constant=EPSILON_CONSTANT):\n",
    "    \"\"\"\n",
    "    Compute the Pearson Correlation Coefficient matrix for the user-item interaction matrix.\n",
    "\n",
    "    Args:\n",
    "        interaction_matrix (numpy.ndarray): A 2D array where rows represent users and columns represent items.\n",
    "                                             The values in the array are the ratings given by users to items.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: A 2D array representing the Pearson Correlation Coefficients between each pair of users.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the number of users\n",
    "    n_users = interaction_matrix.shape[0]\n",
    "    \n",
    "    # Initialize the Pearson Correlation matrix\n",
    "    np_user_pearson_corr = np.zeros((n_users, n_users))\n",
    "    \n",
    "    print(\"Starting user-user Pearson Correlation computation...\")\n",
    "\n",
    "    # Iterate over each pair of users\n",
    "    for i, user_i_vec in enumerate(interaction_matrix):\n",
    "        for j, user_j_vec in enumerate(interaction_matrix):\n",
    "\n",
    "            # if i % 50 == 0 and j % 50 == 0:  # Reduce the frequency of print statements\n",
    "            #     print(f\"Processing correlation between users {i} and {j}\")\n",
    "\n",
    "            # Ratings corated by the current pair of users\n",
    "            mask_i = user_i_vec > 0\n",
    "            mask_j = user_j_vec > 0\n",
    "            \n",
    "            corrated_index = np.intersect1d(np.where(mask_i), np.where(mask_j))\n",
    "\n",
    "            if len(corrated_index) == 0:\n",
    "                continue\n",
    "            \n",
    "            # Average value of user_i_vec and user_j_vec\n",
    "            mean_user_i = np.sum(user_i_vec) / (np.sum(np.clip(user_i_vec, 0, 1)) + epsilon_constant)\n",
    "            mean_user_j = np.sum(user_j_vec) / (np.sum(np.clip(user_j_vec, 0, 1)) + epsilon_constant)\n",
    "            \n",
    "            # Compute Pearson correlation\n",
    "            user_i_sub_mean = user_i_vec[corrated_index] - mean_user_i\n",
    "            user_j_sub_mean = user_j_vec[corrated_index] - mean_user_j\n",
    "            \n",
    "            r_ui_sub_r_i_sq = np.square(user_i_sub_mean)\n",
    "            r_uj_sub_r_j_sq = np.square(user_j_sub_mean)\n",
    "            \n",
    "            r_ui_sum_sqrt = np.sqrt(np.sum(r_ui_sub_r_i_sq))\n",
    "            r_uj_sum_sqrt = np.sqrt(np.sum(r_uj_sub_r_j_sq))\n",
    "            \n",
    "            sim = np.sum(user_i_sub_mean * user_j_sub_mean) / (r_ui_sum_sqrt * r_uj_sum_sqrt + epsilon_constant)\n",
    "            \n",
    "            np_user_pearson_corr[i][j] = sim\n",
    "\n",
    "    print(\"User-user Pearson Correlation computation completed.\")\n",
    "    return np_user_pearson_corr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "DELTA = 25\n",
    "EPSILON = 1e-9\n",
    "\n",
    "def item_pearson_correlation(interaction_matrix):\n",
    "    \"\"\"\n",
    "    Compute the Pearson Correlation Coefficient matrix for the item-item interaction matrix with significance weighting.\n",
    "\n",
    "    Args:\n",
    "        interaction_matrix (2D numpy array): A matrix where rows represent users and columns represent items.\n",
    "                                              The values in the matrix are the ratings given by users to items.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: A 2D array representing the Pearson Correlation Coefficients between each pair of items.\n",
    "    \"\"\"\n",
    "\n",
    "    n_items = interaction_matrix.shape[1]  # Number of items\n",
    "    np_item_pearson_corr = np.zeros((n_items, n_items))  # Initialize the Pearson Correlation matrix\n",
    "\n",
    "    print(\"Starting item-item Pearson Correlation computation...\")\n",
    "\n",
    "    for i, item_i_vec in enumerate(interaction_matrix.T):\n",
    "        for j, item_j_vec in enumerate(interaction_matrix.T):\n",
    "\n",
    "            # if i % 50 == 0 and j % 50 == 0:  # Reduce the frequency of print statements\n",
    "            #     print(f\"Processing correlation between items {i} and {j}\")\n",
    "\n",
    "            # Ratings co-rated by the current pair of items\n",
    "            mask_i = item_i_vec > 0\n",
    "            mask_j = item_j_vec > 0\n",
    "\n",
    "            corrated_index = np.intersect1d(np.where(mask_i), np.where(mask_j))\n",
    "            if len(corrated_index) == 0:\n",
    "                # print(f\"No corrated ratings for items {i} and {j}. Skipping...\")\n",
    "                continue\n",
    "\n",
    "            mean_item_i = np.sum(item_i_vec) / (np.sum(np.clip(item_i_vec, 0, 1)) + EPSILON)\n",
    "            mean_item_j = np.sum(item_j_vec) / (np.sum(np.clip(item_j_vec, 0, 1)) + EPSILON)\n",
    "\n",
    "            # print(f\"Mean rating for item {i}: {mean_item_i}, item {j}: {mean_item_j}\")\n",
    "\n",
    "            item_i_sub_mean = item_i_vec[corrated_index] - mean_item_i\n",
    "            item_j_sub_mean = item_j_vec[corrated_index] - mean_item_j\n",
    "\n",
    "            r_ui_sub_ri_sq = np.square(item_i_sub_mean)\n",
    "            r_uj_sub_rj_sq = np.square(item_j_sub_mean)\n",
    "\n",
    "            r_ui_sub_ri_sq_sum_sqrt = np.sqrt(np.sum(r_ui_sub_ri_sq))\n",
    "            r_uj_sub_rj_sq_sum_sqrt = np.sqrt(np.sum(r_uj_sub_rj_sq))\n",
    "\n",
    "            sim = np.sum(item_i_sub_mean * item_j_sub_mean) / (r_ui_sub_ri_sq_sum_sqrt * r_uj_sub_rj_sq_sum_sqrt + EPSILON)\n",
    "\n",
    "            weighted_sim = (min(len(corrated_index), DELTA) / DELTA) * sim\n",
    "\n",
    "            # print(f\"Correlation between item {i} and item {j}: {weighted_sim}\")\n",
    "\n",
    "            np_item_pearson_corr[i][j] = weighted_sim\n",
    "\n",
    "    print(\"Item-item Pearson Correlation computation completed.\")\n",
    "    return np_item_pearson_corr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting user-user Pearson Correlation computation...\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Compute the user-user Pearson Correlation Coefficient Matrix\n",
    "dense_interaction_matrix = csr_interaction_matrix.toarray()\n",
    "user_pcc_matrix = pearson_correlation(dense_interaction_matrix)\n",
    "print(f'User PCC Matrix:\\n{user_pcc_matrix}\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the item-item Pearson Correlation Coefficient Matrix\n",
    "# Assuming the function 'item_pearson_correlation' takes a dense matrix as input.\n",
    "# If it still takes a csr_matrix, then convert it inside the function.\n",
    "item_pcc_matrix = item_pearson_correlation(dense_interaction_matrix.T)\n",
    "print(f'Item PCC Matrix:\\n{item_pcc_matrix}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ratings_with_CF_item_PCC_and_save(data, user_pcc_matrix, item_pcc_matrix,\n",
    "                                              user_column_name='reviewerID', \n",
    "                                              movie_column_name='title', \n",
    "                                              movie_id_column='asin',\n",
    "                                              rating_column_name='rating', \n",
    "                                              num_ratings_per_user=NUM_RATINGS_PER_USER, \n",
    "                                              num_similar_users=NUM_SIMILAR_USERS,\n",
    "                                              num_main_user_ratings=NUM_MAIN_USER_RATINGS,\n",
    "                                              similarity_threshold=0,  # Lowered threshold\n",
    "                                              save_path='cf_predictions.csv', \n",
    "                                              seed=RANDOM_STATE,\n",
    "                                              system_content=AMAZON_CONTENT_SYSTEM):\n",
    "    results = []\n",
    "\n",
    "    unique_users = data[user_column_name].unique()\n",
    "    unique_items = data[movie_id_column].unique()\n",
    "\n",
    "    user_id_to_index = {user_id: idx for idx, user_id in enumerate(unique_users)}\n",
    "    item_id_to_index = {item_id: idx for idx, item_id in enumerate(unique_items)}\n",
    "\n",
    "    random.seed(seed)\n",
    "\n",
    "    for user_id in unique_users:\n",
    "        user_idx = user_id_to_index[user_id]\n",
    "        print(f\"Processing user {user_id} (Index: {user_idx})\")\n",
    "\n",
    "        main_user_data = data[data[user_column_name] == user_id]\n",
    "        test_set, remaining_data = select_test_set_for_user(main_user_data, num_tests=TEST_OBSERVATION_PER_USER, seed=seed)\n",
    "        if test_set.empty:\n",
    "            print(f\"No test data available for user {user_id}.\")\n",
    "            continue\n",
    "\n",
    "        for random_movie_row in test_set.itertuples():\n",
    "            random_movie_title = getattr(random_movie_row, movie_column_name)\n",
    "            random_movie_id = getattr(random_movie_row, movie_id_column)\n",
    "            random_movie_index = item_id_to_index.get(random_movie_id)\n",
    "            actual_rating = getattr(random_movie_row, rating_column_name)\n",
    "\n",
    "            if random_movie_index is None or random_movie_index >= item_pcc_matrix.shape[0]:\n",
    "                print(f\"Item '{random_movie_id}' not found or out of bounds in item_pcc_matrix.\")\n",
    "                continue\n",
    "\n",
    "            if len(remaining_data) < num_main_user_ratings:\n",
    "                main_user_ratings = remaining_data\n",
    "            else:\n",
    "                main_user_ratings = remaining_data.sample(n=num_main_user_ratings, random_state=seed)\n",
    "            main_user_ratings_str = '\\n'.join([\n",
    "                f\"* Title: {row[movie_column_name]}, Rating: {row[rating_column_name]} stars\"\n",
    "                for _, row in main_user_ratings.iterrows()\n",
    "            ])\n",
    "\n",
    "            similar_users_idx = np.argsort(-user_pcc_matrix[user_idx])[:num_similar_users + 1]\n",
    "            similar_users_idx = similar_users_idx[similar_users_idx != user_idx][:num_similar_users]\n",
    "\n",
    "            similar_users_ratings = \"\"\n",
    "            for idx in similar_users_idx:\n",
    "                similar_user_id = unique_users[idx]\n",
    "                similar_user_data = data[data[user_column_name] == similar_user_id]\n",
    "\n",
    "                # Find top-rated items by this similar user, sorted by item PCC\n",
    "                similar_items_indices = np.argsort(-item_pcc_matrix[random_movie_index, :])\n",
    "                top_rated_items = similar_user_data[similar_user_data[movie_id_column].isin(unique_items[similar_items_indices])]\n",
    "\n",
    "                # Extract top ratings from this user\n",
    "                top_ratings = top_rated_items.nlargest(num_ratings_per_user, rating_column_name)\n",
    "                for top_rating_row in top_ratings.itertuples():\n",
    "                    item_id = getattr(top_rating_row, movie_id_column)\n",
    "                    rating = getattr(top_rating_row, rating_column_name)\n",
    "                    item_title = data.loc[data[movie_id_column] == item_id, movie_column_name].iloc[0]  # Get the title of the item\n",
    "                    similar_users_ratings += f\"* Title: {item_title}, Rating: {rating} stars\\n\"\n",
    "\n",
    "            combined_text = f\"Title: {random_movie_title}\"\n",
    "            prompt = f\"Main User Ratings:\\n{main_user_ratings_str}\\n\\nSimilar Users' Ratings:\\n{similar_users_ratings}\\n\\nPredict rating for '{combined_text}':\"\n",
    "\n",
    "            predicted_rating = predict_rating_combined_ChatCompletion(\n",
    "                combined_text, \n",
    "                approach=\"CF\", \n",
    "                similar_users_ratings=similar_users_ratings,\n",
    "                rating_history=main_user_ratings_str,\n",
    "                system_content=system_content\n",
    "            )\n",
    "\n",
    "            results.append([user_id, random_movie_id, random_movie_title, actual_rating, predicted_rating])\n",
    "            print(f\"User {user_id}: Predicted rating for '{random_movie_title}' is {predicted_rating}.\")\n",
    "\n",
    "    results_df = pd.DataFrame(results, columns=['user_id', 'item_id', 'title', 'actual_rating', 'predicted_rating'])\n",
    "    results_df.to_csv(save_path, index=False)\n",
    "    print(f\"Predictions saved to {save_path}\")\n",
    "\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "results_df = predict_ratings_with_CF_item_PCC_and_save(\n",
    "    data=data, \n",
    "    user_pcc_matrix=user_pcc_matrix, \n",
    "    item_pcc_matrix=item_pcc_matrix,\n",
    "    user_column_name=USER_COLUMN_NAME, \n",
    "    movie_column_name=TITLE_COLUMN_NAME, \n",
    "    movie_id_column=ITEM_ID_COLUMN,\n",
    "    rating_column_name=RATING_COLUMN_NAME, \n",
    "    num_ratings_per_user=NUM_RATINGS_PER_USER, \n",
    "    num_similar_users=NUM_SIMILAR_USERS,\n",
    "    num_main_user_ratings=NUM_MAIN_USER_RATINGS,\n",
    "    save_path=CF_OUTPUT_PATH, \n",
    "    seed=RANDOM_STATE\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate updated CF model predictions\n",
    "evaluate_model_predictions_rmse_mae(\n",
    "    data_path=CF_OUTPUT_PATH,\n",
    "    num_examples=NUM_EXAMPLES,\n",
    "    actual_ratings_column='actual_rating',\n",
    "    predicted_ratings_column='predicted_rating'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry_decorator\n",
    "def predict_rating_combined_ChatCompletion(combined_text, \n",
    "                                           model=GPT_MODEL_NAME, \n",
    "                                           temperature=TEMPERATURE, \n",
    "                                           approach=\"zero-shot\", \n",
    "                                           rating_history=None, \n",
    "                                           similar_users_ratings=None, \n",
    "                                           seed=RANDOM_STATE, \n",
    "                                           system_content=AMAZON_CONTENT_SYSTEM):\n",
    "    # Validation\n",
    "    if approach == \"few-shot\" and rating_history is None:\n",
    "        raise ValueError(\"Rating history is required for the few-shot approach.\")\n",
    "    if approach == \"CF\" and similar_users_ratings is None:\n",
    "        raise ValueError(\"Similar users' ratings are required for the collaborative filtering approach.\")\n",
    "    if not system_content:\n",
    "        raise ValueError(\"System content is required.\")\n",
    "    \n",
    "    # Initialize prompt variable\n",
    "    prompt = \"\"\n",
    "\n",
    "    # Check and reduce length of combined_text\n",
    "    combined_text = check_and_reduce_length(combined_text, MAX_TOKENS_CHAT_GPT // 3, TOKENIZER)\n",
    "\n",
    "    # Construct the prompt based on the approach\n",
    "    if approach == \"few-shot\":\n",
    "        rating_history = check_and_reduce_length(rating_history, MAX_TOKENS_CHAT_GPT // 3, TOKENIZER)\n",
    "        prompt += f\"\\n\\nHere is user rating history:\\n{rating_history}\"\n",
    "        prompt += f\"\\n\\nBased on above rating history, please predict user's rating for the product {combined_text}, (1 being lowest and 5 being highest,The output should be like: (x stars, xx%), do not explain the reason.)\"\n",
    "\n",
    "    elif approach == \"CF\":\n",
    "        rating_history = check_and_reduce_length(rating_history, MAX_TOKENS_CHAT_GPT // 3, TOKENIZER)\n",
    "        prompt += f\"\\n\\nHere is user rating history:\\n{rating_history}\"\n",
    "        similar_users_ratings = check_and_reduce_length(similar_users_ratings, MAX_TOKENS_CHAT_GPT // 3, TOKENIZER)\n",
    "        prompt += f\"\\n\\nHere is the rating history from users who are similar to this user:\\n{similar_users_ratings}\"\n",
    "        prompt += f\"\\n\\nBased on above rating history and similar users' rating history, please predict user's rating for the product {combined_text}, (1 being lowest and 5 being highest,The output should be like: (x stars, xx%), do not explain the reason.)\"\n",
    "        \n",
    "    else:\n",
    "        prompt = f\"How will user rate this product {combined_text}? (1 being lowest and 5 being highest) Attention! Just give me back the exact number as a result, and you don't need a lot of text.\"\n",
    "        \n",
    "\n",
    "    print(f\"Constructed Prompt for {approach} approach:\\n\")\n",
    "    print(f'The prompt:\\n**********\\n{prompt}\\n**********\\n')\n",
    "\n",
    "    try:\n",
    "        # Create the API call\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=model,\n",
    "            temperature=temperature,\n",
    "            max_tokens=MAX_TOKENS_CHAT_GPT,\n",
    "            seed=seed,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_content},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        # Extract the system fingerprint and print it\n",
    "        system_fingerprint = response.get('system_fingerprint')\n",
    "        print(f\"\\nSystem Fingerprint: {system_fingerprint}\")\n",
    "        # Extract and return the rating\n",
    "        rating_text = response.choices[0].message['content'].strip()\n",
    "        print(f'\\nAPI call response: \"{rating_text}\"')\n",
    "        extracted_rating = extract_numeric_rating(rating_text)\n",
    "        print(f'Extracted rating: {extracted_rating}\\n\\n\\n')\n",
    "        print(\"----------------------------------------------------------------------------------\")\n",
    "        return extracted_rating  # A float\n",
    "    \n",
    "    except APIError as api_err:\n",
    "        print(f\"API Error occurred: {api_err}\")\n",
    "        return None, str(api_err)\n",
    "    except RateLimitError as rate_err:\n",
    "        print(f\"Rate Limit Error occurred: {rate_err}\")\n",
    "        return None, str(rate_err)\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected Error: {e}\")\n",
    "        return None, str(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from scipy.spatial.distance import cosine\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Load SimCSE model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"princeton-nlp/sup-simcse-bert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"princeton-nlp/sup-simcse-bert-base-uncased\")\n",
    "\n",
    "def compute_semantic_similarity(text1, text2):\n",
    "    inputs = tokenizer([text1, text2], padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        embeddings = model(**inputs, output_hidden_states=True, return_dict=True).pooler_output\n",
    "    return 1 - cosine(embeddings[0], embeddings[1])\n",
    "\n",
    "def predict_ratings_semantic_similarity_CFfewshot_and_save(data, pcc_matrix, user_column_name='reviewerID', \n",
    "                                                           movie_column_name='title', movie_id_column='asin', \n",
    "                                                           rating_column_name='rating', num_ratings_per_user=NUM_RATINGS_PER_USER, \n",
    "                                                           num_similar_users=NUM_SIMILAR_USERS, num_main_user_ratings=NUM_MAIN_USER_RATINGS, \n",
    "                                                           save_path='cf_predictions.csv', seed=RANDOM_STATE,\n",
    "                                                           system_content=AMAZON_CONTENT_SYSTEM):\n",
    "    results = []\n",
    "    unique_users = data[user_column_name].unique()\n",
    "    user_id_to_index = {user_id: idx for idx, user_id in enumerate(unique_users)}\n",
    "\n",
    "    random.seed(seed)\n",
    "\n",
    "    for user_id in unique_users:\n",
    "        user_idx = user_id_to_index[user_id]\n",
    "        main_user_data = data[data[user_column_name] == user_id]\n",
    "        main_user_ratings = main_user_data.sample(n=num_main_user_ratings, random_state=seed)\n",
    "\n",
    "        similar_users_idx = np.argsort(-pcc_matrix[user_idx])[:num_similar_users + 1]\n",
    "        similar_users_idx = similar_users_idx[similar_users_idx != user_idx][:num_similar_users]\n",
    "\n",
    "        # Collect ratings from similar users\n",
    "        similar_users_ratings = \"\"\n",
    "        for similar_user_idx in similar_users_idx:\n",
    "            similar_user_id = unique_users[similar_user_idx]\n",
    "            similar_user_data = data[data[user_column_name] == similar_user_id]\n",
    "            similar_user_ratings = similar_user_data.sample(n=num_ratings_per_user, random_state=seed)\n",
    "            for _, rating_row in similar_user_ratings.iterrows():\n",
    "                similar_users_ratings += f\"* Title: {rating_row[movie_column_name]}, Rating: {rating_row[rating_column_name]} stars\\n\"\n",
    "\n",
    "        print(f\"Similar users' ratings for user {user_id}:\\n{similar_users_ratings}\")\n",
    "\n",
    "        potential_movies_for_prediction = main_user_data[~main_user_data[movie_id_column].isin(main_user_ratings[movie_id_column])]\n",
    "        if potential_movies_for_prediction.empty:\n",
    "            continue\n",
    "\n",
    "        random_movie_row = potential_movies_for_prediction.sample(n=1, random_state=seed).iloc[0]\n",
    "        random_movie_title = random_movie_row[movie_column_name]\n",
    "        actual_rating = random_movie_row[rating_column_name]\n",
    "\n",
    "        # Compute semantic similarities\n",
    "        similarities = []\n",
    "        for _, row in main_user_ratings.iterrows():\n",
    "            main_movie_title = row[movie_column_name]\n",
    "            similarity = compute_semantic_similarity(main_movie_title, random_movie_title)\n",
    "            similarities.append(similarity)\n",
    "        \n",
    "        average_similarity = np.mean(similarities)\n",
    "        print(f\"Average semantic similarity for '{random_movie_title}' with user's history: {average_similarity}\")\n",
    "\n",
    "        combined_text = f\"Title: {random_movie_title}\"\n",
    "\n",
    "        predicted_rating = predict_rating_combined_ChatCompletion(\n",
    "            combined_text, \n",
    "            approach=\"CF\", \n",
    "            similar_users_ratings=similar_users_ratings,\n",
    "            rating_history=main_user_ratings,\n",
    "            system_content=system_content\n",
    "        )\n",
    "\n",
    "        results.append([user_id, random_movie_row[movie_id_column], random_movie_title, actual_rating, predicted_rating])\n",
    "\n",
    "    results_df = pd.DataFrame(results, columns=['user_id', 'item_id', 'title', 'actual_rating', 'predicted_rating'])\n",
    "    results_df.to_csv(save_path, index=False)\n",
    "    print(f\"Predictions saved to {save_path}\")\n",
    "\n",
    "    return results_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Call the prediction function\n",
    "results_df = predict_ratings_with_CF_item_PCC_and_save(\n",
    "    data=data, \n",
    "    user_pcc_matrix=user_pcc_matrix, \n",
    "    item_pcc_matrix=item_pcc_matrix,\n",
    "    user_column_name=USER_COLUMN_NAME, \n",
    "    movie_column_name=TITLE_COLUMN_NAME, \n",
    "    movie_id_column=ITEM_ID_COLUMN,\n",
    "    rating_column_name=RATING_COLUMN_NAME, \n",
    "    num_ratings_per_user=NUM_RATINGS_PER_USER, \n",
    "    num_similar_users=NUM_SIMILAR_USERS,\n",
    "    num_main_user_ratings=NUM_MAIN_USER_RATINGS,\n",
    "    save_path=CF_OUTPUT_PATH, \n",
    "    seed=RANDOM_STATE\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate updated CF model predictions\n",
    "evaluate_model_predictions_rmse_mae(\n",
    "    data_path=CF_OUTPUT_PATH,\n",
    "    num_examples=NUM_EXAMPLES,\n",
    "    actual_ratings_column='actual_rating',\n",
    "    predicted_ratings_column='predicted_rating'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FAll back to random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from scipy.spatial.distance import cosine\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"princeton-nlp/sup-simcse-bert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"princeton-nlp/sup-simcse-bert-base-uncased\")\n",
    "\n",
    "\n",
    "@retry_decorator\n",
    "def predict_rating_combined_ChatCompletion(combined_text, \n",
    "                                           model=GPT_MODEL_NAME, \n",
    "                                           temperature=TEMPERATURE, \n",
    "                                           approach=\"zero-shot\", \n",
    "                                           rating_history=None, \n",
    "                                           similar_users_ratings=None, \n",
    "                                           seed=RANDOM_STATE, \n",
    "                                           system_content=AMAZON_CONTENT_SYSTEM):\n",
    "    # Validation\n",
    "    if approach == \"few-shot\" and rating_history is None:\n",
    "        raise ValueError(\"Rating history is required for the few-shot approach.\")\n",
    "    if approach == \"CF\" and similar_users_ratings is None:\n",
    "        raise ValueError(\"Similar users' ratings are required for the collaborative filtering approach.\")\n",
    "    if not system_content:\n",
    "        raise ValueError(\"System content is required.\")\n",
    "    \n",
    "    # Initialize prompt variable\n",
    "    prompt = \"\"\n",
    "\n",
    "    # Check and reduce length of combined_text\n",
    "    combined_text = check_and_reduce_length(combined_text, MAX_TOKENS_CHAT_GPT // 3, TOKENIZER)\n",
    "\n",
    "    # Construct the prompt based on the approach\n",
    "    if approach == \"few-shot\":\n",
    "        rating_history = check_and_reduce_length(rating_history, MAX_TOKENS_CHAT_GPT // 3, TOKENIZER)\n",
    "        prompt += f\"\\n\\nHere is user rating history:\\n{rating_history}\"\n",
    "        prompt += f\"\\n\\nBased on above rating history, please predict user's rating for the product {combined_text}, (1 being lowest and 5 being highest,The output should be like: (x stars, xx%), do not explain the reason.)\"\n",
    "\n",
    "    elif approach == \"CF\":\n",
    "        rating_history = check_and_reduce_length(rating_history, MAX_TOKENS_CHAT_GPT // 3, TOKENIZER)\n",
    "        prompt += f\"\\n\\nHere is user rating history:\\n{rating_history}\"\n",
    "        similar_users_ratings = check_and_reduce_length(similar_users_ratings, MAX_TOKENS_CHAT_GPT // 3, TOKENIZER)\n",
    "        prompt += f\"\\n\\nHere is the rating history from users who are similar to this user:\\n{similar_users_ratings}\"\n",
    "        prompt += f\"\\n\\nBased on above rating history and similar users' rating history, please predict user's rating for the product {combined_text}, (1 being lowest and 5 being highest,The output should be like: (x stars, xx%), do not explain the reason.)\"\n",
    "        \n",
    "    else:\n",
    "        prompt = f\"How will user rate this product {combined_text}? (1 being lowest and 5 being highest) Attention! Just give me back the exact number as a result, and you don't need a lot of text.\"\n",
    "        \n",
    "\n",
    "    print(f\"Constructed Prompt for {approach} approach:\\n\")\n",
    "    print(f'The prompt:\\n**********\\n{prompt}\\n**********\\n')\n",
    "\n",
    "    try:\n",
    "        # Create the API call\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=model,\n",
    "            temperature=temperature,\n",
    "            max_tokens=MAX_TOKENS_CHAT_GPT,\n",
    "            seed=seed,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_content},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        # Extract the system fingerprint and print it\n",
    "        system_fingerprint = response.get('system_fingerprint')\n",
    "        print(f\"\\nSystem Fingerprint: {system_fingerprint}\")\n",
    "        # Extract and return the rating\n",
    "        rating_text = response.choices[0].message['content'].strip()\n",
    "        print(f'\\nAPI call response: \"{rating_text}\"')\n",
    "        extracted_rating = extract_numeric_rating(rating_text)\n",
    "        print(f'Extracted rating: {extracted_rating}\\n\\n\\n')\n",
    "        print(\"----------------------------------------------------------------------------------\")\n",
    "        return extracted_rating  # A float\n",
    "    \n",
    "    except APIError as api_err:\n",
    "        print(f\"API Error occurred: {api_err}\")\n",
    "        return None, str(api_err)\n",
    "    except RateLimitError as rate_err:\n",
    "        print(f\"Rate Limit Error occurred: {rate_err}\")\n",
    "        return None, str(rate_err)\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected Error: {e}\")\n",
    "        return None, str(e)\n",
    "\n",
    "def predict_ratings_with_collaborative_filtering_and_save(data, pcc_matrix, \n",
    "                                                          user_column_name='reviewerID', \n",
    "                                                          movie_column_name='title', \n",
    "                                                          movie_id_column='asin',\n",
    "                                                          rating_column_name='rating', \n",
    "                                                          num_ratings_per_user=NUM_RATINGS_PER_USER, \n",
    "                                                          num_similar_users=NUM_SIMILAR_USERS,\n",
    "                                                          num_main_user_ratings=NUM_MAIN_USER_RATINGS,\n",
    "                                                          save_path='cf_predictions.csv', \n",
    "                                                          seed=RANDOM_STATE,\n",
    "                                                          system_content=AMAZON_CONTENT_SYSTEM):\n",
    "    results = []\n",
    "    unique_users = data[user_column_name].unique()\n",
    "    user_id_to_index = {user_id: idx for idx, user_id in enumerate(unique_users)}\n",
    "    \n",
    "    random.seed(seed)\n",
    "\n",
    "    for user_id in unique_users:\n",
    "        user_idx = user_id_to_index[user_id]\n",
    "\n",
    "        print(f\"Processing user {user_id} (Index: {user_idx})\")\n",
    "\n",
    "        # Retrieve the main user's historical ratings randomly\n",
    "        main_user_data = data[data[user_column_name] == user_id]\n",
    "        main_user_ratings = main_user_data.sample(n=num_main_user_ratings, random_state=seed)\n",
    "\n",
    "        main_user_ratings_str = '\\n'.join([\n",
    "            f\"* Title: {row[movie_column_name]}, Rating: {row[rating_column_name]} stars\"\n",
    "            for _, row in main_user_ratings.iterrows()\n",
    "        ])\n",
    "        print(f\"Main user's historical ratings:\\n{main_user_ratings_str}\")\n",
    "\n",
    "        # Find the top similar users based on Pearson Correlation Coefficient\n",
    "        similar_users_idx = np.argsort(-pcc_matrix[user_idx])[:num_similar_users + 1]\n",
    "        similar_users_idx = similar_users_idx[similar_users_idx != user_idx][:num_similar_users]\n",
    "\n",
    "        print(f\"Top similar users for {user_id}: {[unique_users[idx] for idx in similar_users_idx]}\")\n",
    "\n",
    "        # Collect historical ratings from similar users randomly\n",
    "        similar_users_ratings = \"\"\n",
    "        for idx in similar_users_idx:\n",
    "            similar_user_id = unique_users[idx]\n",
    "            similar_user_data = data[data[user_column_name] == similar_user_id]\n",
    "            historical_ratings = similar_user_data.sample(n=num_ratings_per_user, random_state=seed)\n",
    "            for _, row in historical_ratings.iterrows():\n",
    "                rating_info = f\"* Title: {row[movie_column_name]}, Rating: {row[rating_column_name]} stars\"\n",
    "                similar_users_ratings += rating_info + \"\\n\"\n",
    "        print(f\"Similar users' historical ratings:\\n{similar_users_ratings}\")\n",
    "                \n",
    "        # List of movie IDs already rated by the user\n",
    "        rated_movie_ids = main_user_ratings[movie_id_column].tolist()\n",
    "\n",
    "        # Exclude already rated movies and select a random movie for prediction\n",
    "        potential_movies_for_prediction = main_user_data[~main_user_data[movie_id_column].isin(rated_movie_ids)]\n",
    "        if potential_movies_for_prediction.empty:\n",
    "            print(f\"No unrated movies available for user {user_id} for prediction.\")\n",
    "            continue\n",
    "\n",
    "        random_movie_row = potential_movies_for_prediction.sample(n=1, random_state=seed).iloc[0]\n",
    "        random_movie_title = random_movie_row[movie_column_name]\n",
    "        random_movie_id = random_movie_row[movie_id_column]\n",
    "        actual_rating = random_movie_row[rating_column_name]\n",
    "        print(f\"Selected random movie '{random_movie_title}' for prediction.\")\n",
    "\n",
    "        # Construct prompt for API call\n",
    "        combined_text = f\"Title: {random_movie_title}\"\n",
    "        prompt = f\"Main User Ratings:\\n{main_user_ratings_str}\\n\\nSimilar Users' Ratings:\\n{similar_users_ratings}\\n\\nPredict rating for '{combined_text}':\"\n",
    "\n",
    "        print(f\"Generated prompt for user {user_id}:\\n{prompt}\")\n",
    "\n",
    "        predicted_rating = predict_rating_combined_ChatCompletion(\n",
    "            combined_text, \n",
    "            approach=\"CF\", \n",
    "            similar_users_ratings=similar_users_ratings,\n",
    "            rating_history=main_user_ratings_str,\n",
    "            system_content=system_content\n",
    "        )\n",
    "\n",
    "        # Store prediction results\n",
    "        results.append([user_id, random_movie_id, random_movie_title, actual_rating, predicted_rating])\n",
    "\n",
    "        print(f\"User {user_id}: Predicted rating for '{random_movie_title}' is {predicted_rating}.\")\n",
    "\n",
    "    results_df = pd.DataFrame(results, columns=['user_id', 'item_id', 'title', 'actual_rating', 'predicted_rating'])\n",
    "    results_df.to_csv(save_path, index=False)\n",
    "    print(f\"Predictions saved to {save_path}\")\n",
    "\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Call the prediction function\n",
    "results_df = predict_ratings_with_CF_item_PCC_and_save(\n",
    "    data=data, \n",
    "    user_pcc_matrix=user_pcc_matrix, \n",
    "    item_pcc_matrix=item_pcc_matrix,\n",
    "    user_column_name=USER_COLUMN_NAME, \n",
    "    movie_column_name=TITLE_COLUMN_NAME, \n",
    "    movie_id_column=ITEM_ID_COLUMN,\n",
    "    rating_column_name=RATING_COLUMN_NAME, \n",
    "    num_ratings_per_user=NUM_RATINGS_PER_USER, \n",
    "    num_similar_users=NUM_SIMILAR_USERS,\n",
    "    num_main_user_ratings=NUM_MAIN_USER_RATINGS,\n",
    "    save_path=CF_OUTPUT_PATH, \n",
    "    seed=RANDOM_STATE\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate updated CF model predictions\n",
    "evaluate_model_predictions_rmse_mae(\n",
    "    data_path=CF_OUTPUT_PATH,\n",
    "    num_examples=NUM_EXAMPLES,\n",
    "    actual_ratings_column='actual_rating',\n",
    "    predicted_ratings_column='predicted_rating'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "cf_predictions = predict_ratings_with_CF_item_PCC_and_save(data, \n",
    "                                                                       pcc_matrix, \n",
    "                                                                       save_path=CF_OUTPUT_PATH,\n",
    "                                                                       user_column_name=USER_COLUMN_NAME,\n",
    "                                                                       movie_column_name=TITLE_COLUMN_NAME,\n",
    "                                                                       movie_id_column=ITEM_ID_COLUMN,\n",
    "                                                                       rating_column_name=RATING_COLUMN_NAME, \n",
    "                                                                       num_ratings_per_user=NUM_RATINGS_PER_USER,\n",
    "                                                                       num_main_user_ratings=NUM_MAIN_USER_RATINGS,\n",
    "                                                                       num_similar_users=NUM_SIMILAR_USERS,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "saved_data = pd.read_csv(CF_OUTPUT_PATH)\n",
    "\n",
    "# Display the original data types\n",
    "print(\"Original Data Types:\")\n",
    "print(saved_data.dtypes)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Attempt to convert ratings to float and add a flag for conversion failure\n",
    "saved_data['is_rating_float'] = pd.to_numeric(saved_data['predicted_rating'], errors='coerce').notna()\n",
    "\n",
    "# Filter rows where ratings are not float\n",
    "non_float_ratings = saved_data[saved_data['is_rating_float'] == False]\n",
    "\n",
    "# total number of rows with non-float ratings\n",
    "print(f\"Total number of rows with non-float ratings: {len(non_float_ratings)}\")\n",
    "\n",
    "# rerun indices for non-float ratings\n",
    "rerun_indices = non_float_ratings.index.tolist()\n",
    "print(f\"Rerun indices: {rerun_indices}\")\n",
    "\n",
    "# Display rows with non-float ratings\n",
    "print(\"Rows with non-float ratings:\")\n",
    "non_float_ratings.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "rerun_failed_CF_fewshot_predictions(data, \n",
    "                                    pcc_matrix, \n",
    "                                    save_path=CF_OUTPUT_PATH,\n",
    "                                    user_column_name=USER_COLUMN_NAME,\n",
    "                                    movie_column_name=TITLE_COLUMN_NAME,\n",
    "                                    movie_id_column=ITEM_ID_COLUMN,\n",
    "                                    rating_column_name=RATING_COLUMN_NAME, \n",
    "                                    num_ratings_per_user=NUM_RATINGS_PER_USER,\n",
    "                                    num_main_user_ratings=NUM_MAIN_USER_RATINGS,\n",
    "                                    num_similar_users=NUM_SIMILAR_USERS, \n",
    "                                    new_path=CF_RERUN_PATH,\n",
    "                                    rerun_indices=rerun_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rerun_data = pd.read_csv(CF_RERUN_PATH)\n",
    "rerun_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CF_RERUN_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate updated CF model predictions\n",
    "evaluate_model_predictions_rmse_mae(\n",
    "    data_path=CF_RERUN_PATH,\n",
    "    num_examples=NUM_EXAMPLES,\n",
    "    actual_ratings_column='actual_rating',\n",
    "    predicted_ratings_column='predicted_rating'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# output\n",
    "CF_OUTPUT_PATH = os.path.join(DATA_DIR, 'ml-1m/output/CF_fewshot_output_path_ratings_per_user_2nd.dat')\n",
    "print(f'Data path: {data_path}')\n",
    "\n",
    "CF_RERUN_PATH = os.path.join(DATA_DIR, 'ml-1m/output/rerun_CF_fewshot_output_path_ratings_per_user_2nd.dat')\n",
    "print(f'Data path: {data_path}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cf_predictions = predict_ratings_with_CF_item_PCC_and_save(data, \n",
    "                                                                       pcc_matrix, \n",
    "                                                                       save_path=CF_OUTPUT_PATH,\n",
    "                                                                       user_column_name=USER_COLUMN_NAME,\n",
    "                                                                       movie_column_name=TITLE_COLUMN_NAME,\n",
    "                                                                       movie_id_column=ITEM_ID_COLUMN,\n",
    "                                                                       rating_column_name=RATING_COLUMN_NAME, \n",
    "                                                                       num_ratings_per_user=NUM_RATINGS_PER_USER,\n",
    "                                                                       num_main_user_ratings=NUM_MAIN_USER_RATINGS,\n",
    "                                                                       num_similar_users=NUM_SIMILAR_USERS, )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "saved_data = pd.read_csv(CF_OUTPUT_PATH)\n",
    "\n",
    "# Display the original data types\n",
    "print(\"Original Data Types:\")\n",
    "print(saved_data.dtypes)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Attempt to convert ratings to float and add a flag for conversion failure\n",
    "saved_data['is_rating_float'] = pd.to_numeric(saved_data['predicted_rating'], errors='coerce').notna()\n",
    "\n",
    "# Filter rows where ratings are not float\n",
    "non_float_ratings = saved_data[saved_data['is_rating_float'] == False]\n",
    "\n",
    "# total number of rows with non-float ratings\n",
    "print(f\"Total number of rows with non-float ratings: {len(non_float_ratings)}\")\n",
    "\n",
    "# rerun indices for non-float ratings\n",
    "rerun_indices = non_float_ratings.index.tolist()\n",
    "print(f\"Rerun indices: {rerun_indices}\")\n",
    "\n",
    "# Display rows with non-float ratings\n",
    "print(\"Rows with non-float ratings:\")\n",
    "non_float_ratings.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "rerun_failed_CF_fewshot_predictions(data, \n",
    "                                    pcc_matrix, \n",
    "                                    save_path=CF_OUTPUT_PATH,\n",
    "                                    user_column_name=USER_COLUMN_NAME,\n",
    "                                    movie_column_name=TITLE_COLUMN_NAME,\n",
    "                                    movie_id_column=ITEM_ID_COLUMN,\n",
    "                                    rating_column_name=RATING_COLUMN_NAME, \n",
    "                                    num_ratings_per_user=NUM_RATINGS_PER_USER,\n",
    "                                    num_main_user_ratings=NUM_MAIN_USER_RATINGS,\n",
    "                                    num_similar_users=NUM_SIMILAR_USERS, , \n",
    "                                    new_path=CF_RERUN_PATH,\n",
    "                                    rerun_indices=rerun_indices)\n",
    "\n",
    "\n",
    "# Evaluate updated CF model predictions\n",
    "evaluate_model_predictions_rmse_mae(\n",
    "    data_path=CF_RERUN_PATH,\n",
    "    num_examples=NUM_EXAMPLES,\n",
    "    actual_ratings_column='actual_rating',\n",
    "    predicted_ratings_column='predicted_rating'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Third iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# output\n",
    "CF_OUTPUT_PATH = os.path.join(DATA_DIR, 'ml-1m/output/CF_fewshot_output_path_ratings_per_user_3rd.dat')\n",
    "print(f'Data path: {data_path}')\n",
    "\n",
    "CF_RERUN_PATH = os.path.join(DATA_DIR, 'ml-1m/output/rerun_CF_fewshot_output_path_ratings_per_user_3rd.dat')\n",
    "print(f'Data path: {data_path}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cf_predictions = predict_ratings_with_CF_item_PCC_and_save(data, \n",
    "                                                                       pcc_matrix, \n",
    "                                                                       save_path=CF_OUTPUT_PATH,\n",
    "                                                                       user_column_name=USER_COLUMN_NAME,\n",
    "                                                                       movie_column_name=TITLE_COLUMN_NAME,\n",
    "                                                                       movie_id_column=ITEM_ID_COLUMN,\n",
    "                                                                       rating_column_name=RATING_COLUMN_NAME, \n",
    "                                                                       num_ratings_per_user=NUM_RATINGS_PER_USER,\n",
    "                                                                       num_main_user_ratings=NUM_MAIN_USER_RATINGS,\n",
    "                                                                       num_similar_users=NUM_SIMILAR_USERS, )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "saved_data = pd.read_csv(CF_OUTPUT_PATH)\n",
    "\n",
    "# Display the original data types\n",
    "print(\"Original Data Types:\")\n",
    "print(saved_data.dtypes)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Attempt to convert ratings to float and add a flag for conversion failure\n",
    "saved_data['is_rating_float'] = pd.to_numeric(saved_data['predicted_rating'], errors='coerce').notna()\n",
    "\n",
    "# Filter rows where ratings are not float\n",
    "non_float_ratings = saved_data[saved_data['is_rating_float'] == False]\n",
    "\n",
    "# total number of rows with non-float ratings\n",
    "print(f\"Total number of rows with non-float ratings: {len(non_float_ratings)}\")\n",
    "\n",
    "# rerun indices for non-float ratings\n",
    "rerun_indices = non_float_ratings.index.tolist()\n",
    "print(f\"Rerun indices: {rerun_indices}\")\n",
    "\n",
    "# Display rows with non-float ratings\n",
    "print(\"Rows with non-float ratings:\")\n",
    "non_float_ratings.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "rerun_failed_CF_fewshot_predictions(data, \n",
    "                                    pcc_matrix, \n",
    "                                    save_path=CF_OUTPUT_PATH,\n",
    "                                    user_column_name=USER_COLUMN_NAME,\n",
    "                                    movie_column_name=TITLE_COLUMN_NAME,\n",
    "                                    movie_id_column=ITEM_ID_COLUMN,\n",
    "                                    rating_column_name=RATING_COLUMN_NAME, \n",
    "                                    num_ratings_per_user=NUM_RATINGS_PER_USER,\n",
    "                                    num_main_user_ratings=NUM_MAIN_USER_RATINGS,\n",
    "                                    num_similar_users=NUM_SIMILAR_USERS, , \n",
    "                                    new_path=CF_RERUN_PATH,\n",
    "                                    rerun_indices=rerun_indices)\n",
    "\n",
    "\n",
    "# Evaluate updated CF model predictions\n",
    "evaluate_model_predictions_rmse_mae(\n",
    "    data_path=CF_RERUN_PATH,\n",
    "    num_examples=NUM_EXAMPLES,\n",
    "    actual_ratings_column='actual_rating',\n",
    "    predicted_ratings_column='predicted_rating'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fourth iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# output\n",
    "CF_OUTPUT_PATH = os.path.join(DATA_DIR, 'ml-1m/output/CF_fewshot_output_path_ratings_per_user_4th.dat')\n",
    "print(f'Data path: {data_path}')\n",
    "\n",
    "CF_RERUN_PATH = os.path.join(DATA_DIR, 'ml-1m/output/rerun_CF_fewshot_output_path_ratings_per_user_4th.dat')\n",
    "print(f'Data path: {data_path}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cf_predictions = predict_ratings_with_CF_item_PCC_and_save(data, \n",
    "                                                                       pcc_matrix, \n",
    "                                                                       save_path=CF_OUTPUT_PATH,\n",
    "                                                                       user_column_name=USER_COLUMN_NAME,\n",
    "                                                                       movie_column_name=TITLE_COLUMN_NAME,\n",
    "                                                                       movie_id_column=ITEM_ID_COLUMN,\n",
    "                                                                       rating_column_name=RATING_COLUMN_NAME, \n",
    "                                                                       num_ratings_per_user=NUM_RATINGS_PER_USER,\n",
    "                                                                       num_main_user_ratings=NUM_MAIN_USER_RATINGS,\n",
    "                                                                       num_similar_users=NUM_SIMILAR_USERS, )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "saved_data = pd.read_csv(CF_OUTPUT_PATH)\n",
    "\n",
    "# Display the original data types\n",
    "print(\"Original Data Types:\")\n",
    "print(saved_data.dtypes)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Attempt to convert ratings to float and add a flag for conversion failure\n",
    "saved_data['is_rating_float'] = pd.to_numeric(saved_data['predicted_rating'], errors='coerce').notna()\n",
    "\n",
    "# Filter rows where ratings are not float\n",
    "non_float_ratings = saved_data[saved_data['is_rating_float'] == False]\n",
    "\n",
    "# total number of rows with non-float ratings\n",
    "print(f\"Total number of rows with non-float ratings: {len(non_float_ratings)}\")\n",
    "\n",
    "# rerun indices for non-float ratings\n",
    "rerun_indices = non_float_ratings.index.tolist()\n",
    "print(f\"Rerun indices: {rerun_indices}\")\n",
    "\n",
    "# Display rows with non-float ratings\n",
    "print(\"Rows with non-float ratings:\")\n",
    "non_float_ratings.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "rerun_failed_CF_fewshot_predictions(data, \n",
    "                                    pcc_matrix, \n",
    "                                    save_path=CF_OUTPUT_PATH,\n",
    "                                    user_column_name=USER_COLUMN_NAME,\n",
    "                                    movie_column_name=TITLE_COLUMN_NAME,\n",
    "                                    movie_id_column=ITEM_ID_COLUMN,\n",
    "                                    rating_column_name=RATING_COLUMN_NAME, \n",
    "                                    num_ratings_per_user=NUM_RATINGS_PER_USER,\n",
    "                                    num_main_user_ratings=NUM_MAIN_USER_RATINGS,\n",
    "                                    num_similar_users=NUM_SIMILAR_USERS,\n",
    "                                    new_path=CF_RERUN_PATH,\n",
    "                                    rerun_indices=rerun_indices)\n",
    "\n",
    "\n",
    "# Evaluate updated CF model predictions\n",
    "evaluate_model_predictions_rmse_mae(\n",
    "    data_path=CF_RERUN_PATH,\n",
    "    num_examples=NUM_EXAMPLES,\n",
    "    actual_ratings_column='actual_rating',\n",
    "    predicted_ratings_column='predicted_rating'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fifth Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# output\n",
    "CF_OUTPUT_PATH = os.path.join(DATA_DIR, 'ml-1m/output/CF_fewshot_output_path_ratings_per_user_5th.dat')\n",
    "print(f'Data path: {data_path}')\n",
    "\n",
    "CF_RERUN_PATH = os.path.join(DATA_DIR, 'ml-1m/output/rerun_CF_fewshot_output_path_ratings_per_user_5th.dat')\n",
    "print(f'Data path: {data_path}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cf_predictions = predict_ratings_with_CF_item_PCC_and_save(data, \n",
    "                                                                       pcc_matrix, \n",
    "                                                                       save_path=CF_OUTPUT_PATH,\n",
    "                                                                       user_column_name=USER_COLUMN_NAME,\n",
    "                                                                       movie_column_name=TITLE_COLUMN_NAME,\n",
    "                                                                       movie_id_column=ITEM_ID_COLUMN,\n",
    "                                                                       rating_column_name=RATING_COLUMN_NAME, \n",
    "                                                                       num_ratings_per_user=NUM_RATINGS_PER_USER,\n",
    "                                                                       num_main_user_ratings=NUM_MAIN_USER_RATINGS,\n",
    "                                                                       num_similar_users=NUM_SIMILAR_USERS, )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "saved_data = pd.read_csv(CF_OUTPUT_PATH)\n",
    "\n",
    "# Display the original data types\n",
    "print(\"Original Data Types:\")\n",
    "print(saved_data.dtypes)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Attempt to convert ratings to float and add a flag for conversion failure\n",
    "saved_data['is_rating_float'] = pd.to_numeric(saved_data['predicted_rating'], errors='coerce').notna()\n",
    "\n",
    "# Filter rows where ratings are not float\n",
    "non_float_ratings = saved_data[saved_data['is_rating_float'] == False]\n",
    "\n",
    "# total number of rows with non-float ratings\n",
    "print(f\"Total number of rows with non-float ratings: {len(non_float_ratings)}\")\n",
    "\n",
    "# rerun indices for non-float ratings\n",
    "rerun_indices = non_float_ratings.index.tolist()\n",
    "print(f\"Rerun indices: {rerun_indices}\")\n",
    "\n",
    "# Display rows with non-float ratings\n",
    "print(\"Rows with non-float ratings:\")\n",
    "non_float_ratings.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "rerun_failed_CF_fewshot_predictions(data, \n",
    "                                    pcc_matrix, \n",
    "                                    save_path=CF_OUTPUT_PATH,\n",
    "                                    user_column_name=USER_COLUMN_NAME,\n",
    "                                    movie_column_name=TITLE_COLUMN_NAME,\n",
    "                                    movie_id_column=ITEM_ID_COLUMN,\n",
    "                                    rating_column_name=RATING_COLUMN_NAME, \n",
    "                                    num_ratings_per_user=NUM_RATINGS_PER_USER,\n",
    "                                    num_main_user_ratings=NUM_MAIN_USER_RATINGS,\n",
    "                                    num_similar_users=NUM_SIMILAR_USERS,\n",
    "                                    new_path=CF_RERUN_PATH,\n",
    "                                    rerun_indices=rerun_indices)\n",
    "\n",
    "\n",
    "# Evaluate updated CF model predictions\n",
    "evaluate_model_predictions_rmse_mae(\n",
    "    data_path=CF_RERUN_PATH,\n",
    "    num_examples=NUM_EXAMPLES,\n",
    "    actual_ratings_column='actual_rating',\n",
    "    predicted_ratings_column='predicted_rating'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sixth Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# output\n",
    "CF_OUTPUT_PATH = os.path.join(DATA_DIR, 'ml-1m/output/CF_fewshot_output_path_ratings_per_user_6th.dat')\n",
    "print(f'Data path: {data_path}')\n",
    "\n",
    "CF_RERUN_PATH = os.path.join(DATA_DIR, 'ml-1m/output/rerun_CF_fewshot_output_path_ratings_per_user_6th.dat')\n",
    "print(f'Data path: {data_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# output\n",
    "CF_OUTPUT_PATH = os.path.join(DATA_DIR, 'ml-1m/output/CF_fewshot_output_path_ratings_per_user_6th.dat')\n",
    "print(f'Data path: {data_path}')\n",
    "\n",
    "CF_RERUN_PATH = os.path.join(DATA_DIR, 'ml-1m/output/rerun_CF_fewshot_output_path_ratings_per_user_6th.dat')\n",
    "print(f'Data path: {data_path}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cf_predictions = predict_ratings_with_CF_item_PCC_and_save(data, \n",
    "                                                                       pcc_matrix, \n",
    "                                                                       save_path=CF_OUTPUT_PATH,\n",
    "                                                                       user_column_name=USER_COLUMN_NAME,\n",
    "                                                                       movie_column_name=TITLE_COLUMN_NAME,\n",
    "                                                                       movie_id_column=ITEM_ID_COLUMN,\n",
    "                                                                       rating_column_name=RATING_COLUMN_NAME, \n",
    "                                                                       num_ratings_per_user=NUM_RATINGS_PER_USER,\n",
    "                                                                       num_main_user_ratings=NUM_MAIN_USER_RATINGS,\n",
    "                                                                       num_similar_users=NUM_SIMILAR_USERS, )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "saved_data = pd.read_csv(CF_OUTPUT_PATH)\n",
    "\n",
    "# Display the original data types\n",
    "print(\"Original Data Types:\")\n",
    "print(saved_data.dtypes)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Attempt to convert ratings to float and add a flag for conversion failure\n",
    "saved_data['is_rating_float'] = pd.to_numeric(saved_data['predicted_rating'], errors='coerce').notna()\n",
    "\n",
    "# Filter rows where ratings are not float\n",
    "non_float_ratings = saved_data[saved_data['is_rating_float'] == False]\n",
    "\n",
    "# total number of rows with non-float ratings\n",
    "print(f\"Total number of rows with non-float ratings: {len(non_float_ratings)}\")\n",
    "\n",
    "# rerun indices for non-float ratings\n",
    "rerun_indices = non_float_ratings.index.tolist()\n",
    "print(f\"Rerun indices: {rerun_indices}\")\n",
    "\n",
    "# Display rows with non-float ratings\n",
    "print(\"Rows with non-float ratings:\")\n",
    "non_float_ratings.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "rerun_failed_CF_fewshot_predictions(data, \n",
    "                                    pcc_matrix, \n",
    "                                    save_path=CF_OUTPUT_PATH,\n",
    "                                    user_column_name=USER_COLUMN_NAME,\n",
    "                                    movie_column_name=TITLE_COLUMN_NAME,\n",
    "                                    movie_id_column=ITEM_ID_COLUMN,\n",
    "                                    rating_column_name=RATING_COLUMN_NAME, \n",
    "                                    num_ratings_per_user=NUM_RATINGS_PER_USER,\n",
    "                                    num_main_user_ratings=NUM_MAIN_USER_RATINGS,\n",
    "                                    num_similar_users=NUM_SIMILAR_USERS,\n",
    "                                    new_path=CF_RERUN_PATH,\n",
    "                                    rerun_indices=rerun_indices)\n",
    "\n",
    "\n",
    "# Evaluate updated CF model predictions\n",
    "evaluate_model_predictions_rmse_mae(\n",
    "    data_path=CF_RERUN_PATH,\n",
    "    num_examples=NUM_EXAMPLES,\n",
    "    actual_ratings_column='actual_rating',\n",
    "    predicted_ratings_column='predicted_rating'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
