{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rec-sys directory: /Users/tnathu-ai/VSCode/recommender-system/recommender-system-openAI/code\n",
      "Data directory: /Users/tnathu-ai/VSCode/recommender-system/recommender-system-openAI/code/data\n",
      "Data path: /Users/tnathu-ai/VSCode/recommender-system/recommender-system-openAI/code/data/amazon-beauty/large_merged_data.csv\n",
      "Data path: /Users/tnathu-ai/VSCode/recommender-system/recommender-system-openAI/code/data/amazon-beauty/output/large_CF_fewshot_output_path_ratings_per_user.csv\n",
      "Data path: /Users/tnathu-ai/VSCode/recommender-system/recommender-system-openAI/code/data/amazon-beauty/output/rerun_large_CF_fewshot_output_path_ratings_per_user.csv\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import openai\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.sparse import csr_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import openai\n",
    "# Add the path to the constants file to the system path\n",
    "sys.path.append('../../')\n",
    "from constants import *\n",
    "from evaluation_utils import *\n",
    "from path_utils import *\n",
    "from ChatCompletion_OpenAI_API import *\n",
    "from CF_utils import *\n",
    "\n",
    "# OpenAI API Key\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "# source code folder path\n",
    "rec_sys_dir = get_rec_sys_directory()\n",
    "print(f\"Rec-sys directory: {rec_sys_dir}\")\n",
    "\n",
    "# data folder path\n",
    "DATA_DIR = os.path.join(rec_sys_dir, 'data')\n",
    "print(f\"Data directory: {DATA_DIR}\")\n",
    "\n",
    "# data path\n",
    "data_path = os.path.join(DATA_DIR, 'amazon-beauty/large_merged_data.csv')\n",
    "print(f'Data path: {data_path}')\n",
    "\n",
    "# output\n",
    "\n",
    "CF_OUTPUT_PATH = os.path.join(DATA_DIR, 'amazon-beauty/output/large_CF_fewshot_output_path_ratings_per_user.csv')\n",
    "print(f'Data path: {CF_OUTPUT_PATH}')\n",
    "\n",
    "CF_RERUN_PATH = os.path.join(DATA_DIR, 'amazon-beauty/output/rerun_large_CF_fewshot_output_path_ratings_per_user.csv')\n",
    "print(f'Data path: {CF_RERUN_PATH}')\n",
    "\n",
    "\n",
    "# Constants for column names\n",
    "USER_COLUMN_NAME = 'reviewerID'\n",
    "TITLE_COLUMN_NAME = 'title'\n",
    "ITEM_ID_COLUMN = 'asin'\n",
    "RATING_COLUMN_NAME = 'rating'\n",
    "\n",
    "# num_ratings_per_user\n",
    "NUM_RATINGS_PER_USER = 1\n",
    "# num_main_user_ratings\n",
    "NUM_MAIN_USER_RATINGS = 4\n",
    "# num_similar_users\n",
    "NUM_SIMILAR_USERS = 4\n",
    "\n",
    "SYSTEM_CONTENT = AMAZON_CONTENT_SYSTEM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>vote</th>\n",
       "      <th>...</th>\n",
       "      <th>tech2</th>\n",
       "      <th>brand</th>\n",
       "      <th>feature</th>\n",
       "      <th>rank</th>\n",
       "      <th>also_view</th>\n",
       "      <th>details</th>\n",
       "      <th>main_cat</th>\n",
       "      <th>similar_item</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2015-08-25</td>\n",
       "      <td>A2RYSCZOPEXOCQ</td>\n",
       "      <td>9790787006</td>\n",
       "      <td>The Cat Next Door</td>\n",
       "      <td>I use a lot of perfume, I go through a new bot...</td>\n",
       "      <td>This is not going to be my favorite scent.</td>\n",
       "      <td>2015-08-25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jenna Jameson</td>\n",
       "      <td>[]</td>\n",
       "      <td>298.0</td>\n",
       "      <td>['B00357FTX8', 'B01NBID7FJ', 'B0017JT658']</td>\n",
       "      <td>{'Shipping Weight:': '12.8 ounces (', 'ASIN: '...</td>\n",
       "      <td>All Beauty</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2001-06-08</td>\n",
       "      <td>A141OPVE376YFI</td>\n",
       "      <td>B000050B65</td>\n",
       "      <td>Paul G.</td>\n",
       "      <td>First, a little background.  I've switched bet...</td>\n",
       "      <td>Finally, a razor that lives up to the ads</td>\n",
       "      <td>2001-06-08</td>\n",
       "      <td>81</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Norelco</td>\n",
       "      <td>[]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>['B01B1O9DOM', 'B00JITDVD2', 'B01KXV16DK', 'B0...</td>\n",
       "      <td>{}</td>\n",
       "      <td>All Beauty</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>2008-07-25</td>\n",
       "      <td>A1TVTDKNMSQ7XU</td>\n",
       "      <td>B000050B6B</td>\n",
       "      <td>Grandpa Pipes</td>\n",
       "      <td>I've had many Norelco razors in my 50 years of...</td>\n",
       "      <td>Just like new.....</td>\n",
       "      <td>2008-07-25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Philips Norelco</td>\n",
       "      <td>[]</td>\n",
       "      <td>148.0</td>\n",
       "      <td>['B001IA0PCY', 'B00196W5S4', 'B004URZADG', 'B0...</td>\n",
       "      <td>{'\\n    Product Dimensions: \\n    ': '5.1 x 0....</td>\n",
       "      <td>All Beauty</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating  verified  reviewTime      reviewerID        asin  \\\n",
       "0     1.0     False  2015-08-25  A2RYSCZOPEXOCQ  9790787006   \n",
       "1     5.0     False  2001-06-08  A141OPVE376YFI  B000050B65   \n",
       "2     5.0      True  2008-07-25  A1TVTDKNMSQ7XU  B000050B6B   \n",
       "\n",
       "        reviewerName                                         reviewText  \\\n",
       "0  The Cat Next Door  I use a lot of perfume, I go through a new bot...   \n",
       "1            Paul G.  First, a little background.  I've switched bet...   \n",
       "2      Grandpa Pipes  I've had many Norelco razors in my 50 years of...   \n",
       "\n",
       "                                      summary unixReviewTime vote  ... tech2  \\\n",
       "0  This is not going to be my favorite scent.     2015-08-25  NaN  ...   NaN   \n",
       "1   Finally, a razor that lives up to the ads     2001-06-08   81  ...   NaN   \n",
       "2                          Just like new.....     2008-07-25  NaN  ...   NaN   \n",
       "\n",
       "             brand feature   rank  \\\n",
       "0    Jenna Jameson      []  298.0   \n",
       "1          Norelco      []    2.0   \n",
       "2  Philips Norelco      []  148.0   \n",
       "\n",
       "                                           also_view  \\\n",
       "0         ['B00357FTX8', 'B01NBID7FJ', 'B0017JT658']   \n",
       "1  ['B01B1O9DOM', 'B00JITDVD2', 'B01KXV16DK', 'B0...   \n",
       "2  ['B001IA0PCY', 'B00196W5S4', 'B004URZADG', 'B0...   \n",
       "\n",
       "                                             details    main_cat  \\\n",
       "0  {'Shipping Weight:': '12.8 ounces (', 'ASIN: '...  All Beauty   \n",
       "1                                                 {}  All Beauty   \n",
       "2  {'\\n    Product Dimensions: \\n    ': '5.1 x 0....  All Beauty   \n",
       "\n",
       "   similar_item date  price  \n",
       "0           NaN  NaN  13.85  \n",
       "1           NaN  NaN    NaN  \n",
       "2           NaN  NaN  64.50  \n",
       "\n",
       "[3 rows x 27 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(data_path)\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>asin</th>\n",
       "      <th>9790787006</th>\n",
       "      <th>B000050B63</th>\n",
       "      <th>B000050B65</th>\n",
       "      <th>B000050B6B</th>\n",
       "      <th>B000050B6H</th>\n",
       "      <th>B000050FDT</th>\n",
       "      <th>B000050FDY</th>\n",
       "      <th>B000052YAN</th>\n",
       "      <th>B000052YD8</th>\n",
       "      <th>B0000530HU</th>\n",
       "      <th>...</th>\n",
       "      <th>B01H4Y9MSU</th>\n",
       "      <th>B01H640HTG</th>\n",
       "      <th>B01H71ND58</th>\n",
       "      <th>B01H71ND76</th>\n",
       "      <th>B01HATTFWW</th>\n",
       "      <th>B01HB4BS1C</th>\n",
       "      <th>B01HBWYB5Y</th>\n",
       "      <th>B01HBYF0CK</th>\n",
       "      <th>B01HD23OJG</th>\n",
       "      <th>B01HIPOQ2M</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviewerID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A105A034ZG9EHO</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A10JB7YPWZGRF4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A10M2MLE2R0L6K</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A10OYW0QYN13GL</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A10P0NAKKRYKTZ</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZMAOC6QC0WEP</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZPI1JA9XKV8P</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZQZIAWSFBHLW</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZRD4IZU6TBFV</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZTZ7SIIRXLXE</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1608 rows × 1879 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "asin            9790787006  B000050B63  B000050B65  B000050B6B  B000050B6H  \\\n",
       "reviewerID                                                                   \n",
       "A105A034ZG9EHO         0.0         0.0         0.0         0.0         0.0   \n",
       "A10JB7YPWZGRF4         0.0         0.0         0.0         0.0         0.0   \n",
       "A10M2MLE2R0L6K         0.0         0.0         0.0         0.0         0.0   \n",
       "A10OYW0QYN13GL         0.0         0.0         0.0         0.0         0.0   \n",
       "A10P0NAKKRYKTZ         0.0         0.0         0.0         0.0         0.0   \n",
       "...                    ...         ...         ...         ...         ...   \n",
       "AZMAOC6QC0WEP          0.0         0.0         0.0         0.0         0.0   \n",
       "AZPI1JA9XKV8P          0.0         0.0         0.0         0.0         0.0   \n",
       "AZQZIAWSFBHLW          0.0         0.0         0.0         0.0         0.0   \n",
       "AZRD4IZU6TBFV          0.0         0.0         0.0         0.0         0.0   \n",
       "AZTZ7SIIRXLXE          0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "asin            B000050FDT  B000050FDY  B000052YAN  B000052YD8  B0000530HU  \\\n",
       "reviewerID                                                                   \n",
       "A105A034ZG9EHO         0.0         0.0         0.0         0.0         0.0   \n",
       "A10JB7YPWZGRF4         0.0         0.0         0.0         0.0         0.0   \n",
       "A10M2MLE2R0L6K         0.0         0.0         0.0         0.0         0.0   \n",
       "A10OYW0QYN13GL         0.0         0.0         0.0         0.0         0.0   \n",
       "A10P0NAKKRYKTZ         0.0         0.0         0.0         0.0         0.0   \n",
       "...                    ...         ...         ...         ...         ...   \n",
       "AZMAOC6QC0WEP          0.0         0.0         0.0         0.0         0.0   \n",
       "AZPI1JA9XKV8P          0.0         0.0         0.0         0.0         0.0   \n",
       "AZQZIAWSFBHLW          0.0         0.0         0.0         0.0         0.0   \n",
       "AZRD4IZU6TBFV          0.0         0.0         0.0         0.0         0.0   \n",
       "AZTZ7SIIRXLXE          0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "asin            ...  B01H4Y9MSU  B01H640HTG  B01H71ND58  B01H71ND76  \\\n",
       "reviewerID      ...                                                   \n",
       "A105A034ZG9EHO  ...         0.0         0.0         0.0         0.0   \n",
       "A10JB7YPWZGRF4  ...         0.0         0.0         0.0         0.0   \n",
       "A10M2MLE2R0L6K  ...         0.0         0.0         0.0         0.0   \n",
       "A10OYW0QYN13GL  ...         0.0         0.0         0.0         0.0   \n",
       "A10P0NAKKRYKTZ  ...         0.0         0.0         0.0         0.0   \n",
       "...             ...         ...         ...         ...         ...   \n",
       "AZMAOC6QC0WEP   ...         0.0         0.0         0.0         0.0   \n",
       "AZPI1JA9XKV8P   ...         0.0         0.0         0.0         0.0   \n",
       "AZQZIAWSFBHLW   ...         0.0         0.0         0.0         0.0   \n",
       "AZRD4IZU6TBFV   ...         0.0         0.0         0.0         0.0   \n",
       "AZTZ7SIIRXLXE   ...         0.0         0.0         0.0         0.0   \n",
       "\n",
       "asin            B01HATTFWW  B01HB4BS1C  B01HBWYB5Y  B01HBYF0CK  B01HD23OJG  \\\n",
       "reviewerID                                                                   \n",
       "A105A034ZG9EHO         0.0         0.0         0.0         0.0         0.0   \n",
       "A10JB7YPWZGRF4         0.0         0.0         0.0         0.0         0.0   \n",
       "A10M2MLE2R0L6K         0.0         0.0         0.0         0.0         0.0   \n",
       "A10OYW0QYN13GL         0.0         0.0         0.0         0.0         0.0   \n",
       "A10P0NAKKRYKTZ         0.0         0.0         0.0         0.0         0.0   \n",
       "...                    ...         ...         ...         ...         ...   \n",
       "AZMAOC6QC0WEP          0.0         0.0         0.0         0.0         0.0   \n",
       "AZPI1JA9XKV8P          0.0         0.0         0.0         0.0         0.0   \n",
       "AZQZIAWSFBHLW          0.0         0.0         0.0         0.0         0.0   \n",
       "AZRD4IZU6TBFV          0.0         0.0         0.0         0.0         0.0   \n",
       "AZTZ7SIIRXLXE          0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "asin            B01HIPOQ2M  \n",
       "reviewerID                  \n",
       "A105A034ZG9EHO         0.0  \n",
       "A10JB7YPWZGRF4         0.0  \n",
       "A10M2MLE2R0L6K         0.0  \n",
       "A10OYW0QYN13GL         0.0  \n",
       "A10P0NAKKRYKTZ         0.0  \n",
       "...                    ...  \n",
       "AZMAOC6QC0WEP          0.0  \n",
       "AZPI1JA9XKV8P          0.0  \n",
       "AZQZIAWSFBHLW          0.0  \n",
       "AZRD4IZU6TBFV          0.0  \n",
       "AZTZ7SIIRXLXE          0.0  \n",
       "\n",
       "[1608 rows x 1879 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create User-Item Interaction Matrix\n",
    "interaction_matrix = pd.pivot_table(data, index=USER_COLUMN_NAME, columns=ITEM_ID_COLUMN, values=RATING_COLUMN_NAME).fillna(0)\n",
    "csr_interaction_matrix = csr_matrix(interaction_matrix.values)\n",
    "\n",
    "interaction_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1608x1879 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 7469 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csr_interaction_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User PCC Matrix:\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n",
      "\n",
      "Item PCC Matrix:\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute the user-user Pearson Correlation Coefficient Matrix\n",
    "user_pcc_matrix = pearson_correlation(csr_interaction_matrix)\n",
    "print(f'User PCC Matrix:\\n{user_pcc_matrix}\\n')\n",
    "# Compute the item-item Pearson Correlation Coefficient Matrix\n",
    "item_pcc_matrix = item_pearson_correlation(csr_interaction_matrix)\n",
    "print(f'Item PCC Matrix:\\n{item_pcc_matrix}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_pcc_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_pcc_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentence_transformers\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "!pip3 install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_numeric_rating(rating_text):\n",
    "    \"\"\"\n",
    "    Extract numeric rating from response text.\n",
    "\n",
    "    Args:\n",
    "        rating_text (str): Text containing numeric rating.\n",
    "\n",
    "    Returns:\n",
    "        float: Extracted rating value. Returns 0 for unexpected responses.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        rating_text = str(rating_text).strip()\n",
    "\n",
    "        # Updated regex pattern to match numeric ratings followed by the word 'stars' or 'star'\n",
    "        rating_match = re.search(r'(\\d+(\\.\\d+)?)\\s*(stars|star)\\b', rating_text, re.IGNORECASE)\n",
    "\n",
    "        if rating_match:\n",
    "            rating = float(rating_match.group(1))\n",
    "            if 1 <= rating <= 5:\n",
    "                return rating\n",
    "            else:\n",
    "                print(f\"Rating out of expected range (1-5): {rating_text}\")\n",
    "                return 0\n",
    "        else:\n",
    "            print(f\"No valid rating found in the response: {rating_text}\")\n",
    "            return 0\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting rating: {e}. Full response: {rating_text}\")\n",
    "        return 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@retry_decorator\n",
    "def predict_rating_combined_ChatCompletion(combined_text, \n",
    "                                           model=GPT_MODEL_NAME, \n",
    "                                           temperature=TEMPERATURE, \n",
    "                                           approach=\"zero-shot\", \n",
    "                                           rating_history=None, \n",
    "                                           similar_users_ratings=None, \n",
    "                                           seed=RANDOM_STATE, \n",
    "                                           system_content=AMAZON_CONTENT_SYSTEM):\n",
    "    # Validation\n",
    "    if approach == \"few-shot\" and rating_history is None:\n",
    "        raise ValueError(\"Rating history is required for the few-shot approach.\")\n",
    "    if approach == \"CF\" and similar_users_ratings is None:\n",
    "        raise ValueError(\"Similar users' ratings are required for the collaborative filtering approach.\")\n",
    "    if not system_content:\n",
    "        raise ValueError(\"System content is required.\")\n",
    "    \n",
    "    # Initialize prompt variable\n",
    "    prompt = \"\"\n",
    "\n",
    "    # Check and reduce length of combined_text\n",
    "    combined_text = check_and_reduce_length(combined_text, MAX_TOKENS_CHAT_GPT // 3, TOKENIZER)\n",
    "\n",
    "    # Construct the prompt based on the approach\n",
    "    if approach == \"few-shot\":\n",
    "        rating_history = check_and_reduce_length(rating_history, MAX_TOKENS_CHAT_GPT // 3, TOKENIZER)\n",
    "        prompt += f\"\\n\\nHere is user rating history:\\n{rating_history}\"\n",
    "        prompt += f\"\\n\\nBased on above rating history, please predict user's rating for the product {combined_text}, (1 being lowest and 5 being highest,The output should be like: (x stars, xx%), do not explain the reason.)\"\n",
    "\n",
    "    elif approach == \"CF\":\n",
    "        rating_history = check_and_reduce_length(rating_history, MAX_TOKENS_CHAT_GPT // 3, TOKENIZER)\n",
    "        prompt += f\"\\n\\nHere is user rating history:\\n{rating_history}\"\n",
    "        similar_users_ratings = check_and_reduce_length(similar_users_ratings, MAX_TOKENS_CHAT_GPT // 3, TOKENIZER)\n",
    "        prompt += f\"\\n\\nHere is the rating history from users who are similar to this user:\\n{similar_users_ratings}\"\n",
    "        prompt += f\"\\n\\nBased on above rating history and similar users' rating history, please predict user's rating for the product {combined_text}, (1 being lowest and 5 being highest,The output should be like: (x stars, xx%), do not explain the reason.)\"\n",
    "        \n",
    "    else:\n",
    "        prompt = f\"How will user rate this product {combined_text}? (1 being lowest and 5 being highest) Attention! Just give me back the exact number as a result, and you don't need a lot of text.\"\n",
    "        \n",
    "\n",
    "    print(f\"Constructed Prompt for {approach} approach:\\n\")\n",
    "    print(f'The prompt:\\n**********\\n{prompt}\\n**********\\n')\n",
    "\n",
    "    try:\n",
    "        # Create the API call\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=model,\n",
    "            temperature=temperature,\n",
    "            max_tokens=MAX_TOKENS_CHAT_GPT,\n",
    "            seed=seed,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_content},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        # Extract the system fingerprint and print it\n",
    "        system_fingerprint = response.get('system_fingerprint')\n",
    "        print(f\"\\nSystem Fingerprint: {system_fingerprint}\")\n",
    "        # Extract and return the rating\n",
    "        rating_text = response.choices[0].message['content'].strip()\n",
    "        print(f'\\nAPI call response: \"{rating_text}\"')\n",
    "        extracted_rating = extract_numeric_rating(rating_text)\n",
    "        print(f'Extracted rating: {extracted_rating}\\n\\n\\n')\n",
    "        print(\"----------------------------------------------------------------------------------\")\n",
    "        return extracted_rating  # A float\n",
    "    \n",
    "    except APIError as api_err:\n",
    "        print(f\"API Error occurred: {api_err}\")\n",
    "        return None, str(api_err)\n",
    "    except RateLimitError as rate_err:\n",
    "        print(f\"Rate Limit Error occurred: {rate_err}\")\n",
    "        return None, str(rate_err)\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected Error: {e}\")\n",
    "        return None, str(e)\n",
    "    \n",
    "def item_pearson_correlation(interaction_matrix):\n",
    "    \"\"\"\n",
    "    Compute the Pearson Correlation Coefficient matrix for the item-item interaction matrix.\n",
    "\n",
    "    This function calculates the Pearson Correlation Coefficients between each pair of items based on user ratings,\n",
    "    forming a square matrix where each cell (i, j) represents the correlation between items i and j.\n",
    "\n",
    "    Args:\n",
    "        interaction_matrix (csr_matrix): A sparse matrix where rows represent users and columns represent items.\n",
    "                                         The values in the matrix are the ratings given by users to items.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: A 2D array representing the Pearson Correlation Coefficients between each pair of items.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert the sparse matrix to a dense format for easier processing\n",
    "    dense_matrix = interaction_matrix.toarray()\n",
    "    n_items = dense_matrix.shape[1]  # Number of items\n",
    "\n",
    "    # Initialize the Pearson Correlation matrix as a square matrix with dimensions equal to the number of items\n",
    "    pearson_corr_matrix = np.zeros((n_items, n_items))\n",
    "    EPSILON = 1e-9  # Small constant to avoid division by zero in correlation calculation\n",
    "\n",
    "    # Iterate over each pair of items to compute their correlation\n",
    "    for i in range(n_items):\n",
    "        for j in range(n_items):\n",
    "            # Extract rating vectors for the current pair of items\n",
    "            item_i_vec = dense_matrix[:, i]\n",
    "            item_j_vec = dense_matrix[:, j]\n",
    "\n",
    "            # Create masks for filtering rated items (items with ratings greater than 0)\n",
    "            mask_i = item_i_vec > 0\n",
    "            mask_j = item_j_vec > 0\n",
    "\n",
    "            # Identify indices where both items have been rated (corrated items)\n",
    "            corrated_index = np.intersect1d(np.where(mask_i)[0], np.where(mask_j)[0])\n",
    "\n",
    "            # Skip the calculation if no users have rated both items\n",
    "            if len(corrated_index) == 0:\n",
    "                continue\n",
    "\n",
    "            # Calculate mean ratings for each item over all users who rated both items\n",
    "            mean_item_i = np.mean(item_i_vec[corrated_index])\n",
    "            mean_item_j = np.mean(item_j_vec[corrated_index])\n",
    "\n",
    "            # Compute deviations from the mean for each item\n",
    "            item_i_sub_mean = item_i_vec[corrated_index] - mean_item_i\n",
    "            item_j_sub_mean = item_j_vec[corrated_index] - mean_item_j\n",
    "\n",
    "            # Compute the squares of deviations\n",
    "            r_ui_sub_r_i_sq = np.square(item_i_sub_mean)\n",
    "            r_uj_sub_r_j_sq = np.square(item_j_sub_mean)\n",
    "\n",
    "            # Calculate the square roots of the sum of squared deviations\n",
    "            r_ui_sum_sqrt = np.sqrt(np.sum(r_ui_sub_r_i_sq))\n",
    "            r_uj_sum_sqrt = np.sqrt(np.sum(r_uj_sub_r_j_sq))\n",
    "\n",
    "            # Calculate the Pearson correlation coefficient\n",
    "            sim = np.sum(item_i_sub_mean * item_j_sub_mean) / (r_ui_sum_sqrt * r_uj_sum_sqrt + EPSILON)\n",
    "\n",
    "            # Store the computed similarity in the matrix\n",
    "            pearson_corr_matrix[i, j] = sim\n",
    "            \n",
    "    print(f\"Pearson Correlation Matrix:\\n{pearson_corr_matrix}\")\n",
    "\n",
    "    return pearson_corr_matrix\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def predict_ratings_with_CF_item_PCC_and_save(data, user_pcc_matrix, item_pcc_matrix,\n",
    "                                              user_column_name='reviewerID', \n",
    "                                              movie_column_name='title', \n",
    "                                              movie_id_column='asin',\n",
    "                                              rating_column_name='rating', \n",
    "                                              num_ratings_per_user=NUM_RATINGS_PER_USER, \n",
    "                                              num_similar_users=NUM_SIMILAR_USERS,\n",
    "                                              num_main_user_ratings=NUM_MAIN_USER_RATINGS,\n",
    "                                              save_path='cf_predictions.csv', \n",
    "                                              seed=RANDOM_STATE,\n",
    "                                              system_content=AMAZON_CONTENT_SYSTEM):\n",
    "    results = []\n",
    "\n",
    "    unique_users = data[user_column_name].unique()\n",
    "    unique_items = data[movie_id_column].unique()\n",
    "\n",
    "    user_id_to_index = {user_id: idx for idx, user_id in enumerate(unique_users)}\n",
    "    item_id_to_index = {item_id: idx for idx, item_id in enumerate(unique_items)}\n",
    "\n",
    "    random.seed(seed)\n",
    "\n",
    "    for user_id in unique_users:\n",
    "        user_idx = user_id_to_index[user_id]\n",
    "\n",
    "        print(f\"Processing user {user_id} (Index: {user_idx})\")\n",
    "\n",
    "        main_user_data = data[data[user_column_name] == user_id]\n",
    "        test_set, remaining_data = select_test_set_for_user(main_user_data, num_tests=TEST_OBSERVATION_PER_USER, seed=seed)\n",
    "        if test_set.empty:\n",
    "            print(f\"No test data available for user {user_id}.\")\n",
    "            continue\n",
    "\n",
    "        random_movie_row = test_set.iloc[0]\n",
    "        main_user_ratings = remaining_data.sample(n=num_main_user_ratings, random_state=seed)\n",
    "        main_user_ratings_str = '\\n'.join([\n",
    "            f\"* Title: {row[movie_column_name]}, Rating: {row[rating_column_name]} stars\"\n",
    "            for _, row in main_user_ratings.iterrows()\n",
    "        ])\n",
    "\n",
    "        random_movie_title = random_movie_row[movie_column_name]\n",
    "        random_movie_id = random_movie_row[movie_id_column]\n",
    "        random_movie_index = item_id_to_index[random_movie_id]\n",
    "        actual_rating = random_movie_row[rating_column_name]\n",
    "\n",
    "        similar_users_idx = np.argsort(-user_pcc_matrix[user_idx])[:num_similar_users + 1]\n",
    "        similar_users_idx = similar_users_idx[similar_users_idx != user_idx][:num_similar_users]\n",
    "\n",
    "        # Increasing the number of similar items considered\n",
    "        num_ratings_per_user_extended = num_ratings_per_user * 2\n",
    "\n",
    "        similar_users_ratings = \"\"\n",
    "        for idx in similar_users_idx:\n",
    "            similar_user_id = unique_users[idx]\n",
    "            similar_user_data = data[data[user_column_name] == similar_user_id]\n",
    "\n",
    "            similar_items_indices = np.argsort(-item_pcc_matrix[random_movie_index, :])\n",
    "            found_ratings = False\n",
    "            for similar_item_index in similar_items_indices[:num_ratings_per_user_extended]:\n",
    "                if similar_item_index == random_movie_index:\n",
    "                    continue\n",
    "\n",
    "                most_similar_item_id = unique_items[similar_item_index]\n",
    "                most_similar_item_ratings = similar_user_data[similar_user_data[movie_id_column] == most_similar_item_id][rating_column_name]\n",
    "                \n",
    "\n",
    "                if not most_similar_item_ratings.empty:\n",
    "                    rating_info = f\"* Title: {most_similar_item_id}, Rating: {most_similar_item_ratings.iloc[0]} stars\"\n",
    "                    similar_users_ratings += rating_info + \"\\n\"\n",
    "                    found_ratings = True\n",
    "\n",
    "            if not found_ratings:\n",
    "                print(f\"No similar item ratings found for user {similar_user_id} for similar items to '{random_movie_title}'\")\n",
    "\n",
    "        combined_text = f\"Title: {random_movie_title}\"\n",
    "        prompt = f\"Main User Ratings:\\n{main_user_ratings_str}\\n\\nSimilar Users' Ratings:\\n{similar_users_ratings}\\n\\nPredict rating for '{combined_text}':\"\n",
    "\n",
    "        predicted_rating = predict_rating_combined_ChatCompletion(\n",
    "            combined_text, \n",
    "            approach=\"CF\", \n",
    "            similar_users_ratings=similar_users_ratings,\n",
    "            rating_history=main_user_ratings_str,\n",
    "            system_content=system_content\n",
    "        )\n",
    "\n",
    "        results.append([user_id, random_movie_id, random_movie_title, actual_rating, predicted_rating])\n",
    "        print(f\"User {user_id}: Predicted rating for '{random_movie_title}' is {predicted_rating}.\")\n",
    "\n",
    "    results_df = pd.DataFrame(results, columns=['user_id', 'item_id', 'title', 'actual_rating', 'predicted_rating'])\n",
    "    results_df.to_csv(save_path, index=False)\n",
    "    print(f\"Predictions saved to {save_path}\")\n",
    "\n",
    "    return results_df\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Call the prediction function\n",
    "results_df = predict_ratings_with_CF_item_PCC_and_save(\n",
    "    data=data, \n",
    "    user_pcc_matrix=user_pcc_matrix, \n",
    "    item_pcc_matrix=item_pcc_matrix,\n",
    "    user_column_name=USER_COLUMN_NAME, \n",
    "    movie_column_name=TITLE_COLUMN_NAME, \n",
    "    movie_id_column=ITEM_ID_COLUMN,\n",
    "    rating_column_name=RATING_COLUMN_NAME, \n",
    "    num_ratings_per_user=NUM_RATINGS_PER_USER, \n",
    "    num_similar_users=NUM_SIMILAR_USERS,\n",
    "    num_main_user_ratings=NUM_MAIN_USER_RATINGS,\n",
    "    save_path=CF_OUTPUT_PATH, \n",
    "    seed=RANDOM_STATE\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_ratings_with_CF_item_PCC_and_save(data, user_pcc_matrix, item_pcc_matrix,\n",
    "                                              user_column_name='reviewerID', \n",
    "                                              movie_column_name='title', \n",
    "                                              movie_id_column='asin',\n",
    "                                              rating_column_name='rating', \n",
    "                                              num_ratings_per_user=NUM_RATINGS_PER_USER, \n",
    "                                              num_similar_users=NUM_SIMILAR_USERS,\n",
    "                                              num_main_user_ratings=NUM_MAIN_USER_RATINGS,\n",
    "                                              save_path='cf_predictions.csv', \n",
    "                                              seed=RANDOM_STATE,\n",
    "                                              system_content=AMAZON_CONTENT_SYSTEM):\n",
    "    results = []\n",
    "\n",
    "    unique_users = data[user_column_name].unique()\n",
    "    unique_items = data[movie_id_column].unique()\n",
    "\n",
    "    user_id_to_index = {user_id: idx for idx, user_id in enumerate(unique_users)}\n",
    "    item_id_to_index = {item_id: idx for idx, item_id in enumerate(unique_items)}\n",
    "\n",
    "    random.seed(seed)\n",
    "\n",
    "    for user_id in unique_users:\n",
    "        user_idx = user_id_to_index[user_id]\n",
    "        print(f\"Processing user {user_id} (Index: {user_idx})\")\n",
    "\n",
    "        main_user_data = data[data[user_column_name] == user_id]\n",
    "        test_set, remaining_data = select_test_set_for_user(main_user_data, num_tests=TEST_OBSERVATION_PER_USER, seed=seed)\n",
    "        if test_set.empty:\n",
    "            print(f\"No test data available for user {user_id}.\")\n",
    "            continue\n",
    "\n",
    "        random_movie_row = test_set.iloc[0]\n",
    "        main_user_ratings = remaining_data.sample(n=num_main_user_ratings, random_state=seed)\n",
    "        main_user_ratings_str = '\\n'.join([\n",
    "            f\"* Title: {row[movie_column_name]}, Rating: {row[rating_column_name]} stars\"\n",
    "            for _, row in main_user_ratings.iterrows()\n",
    "        ])\n",
    "\n",
    "        random_movie_title = random_movie_row[movie_column_name]\n",
    "        random_movie_id = random_movie_row[movie_id_column]\n",
    "        random_movie_index = item_id_to_index[random_movie_id]\n",
    "        actual_rating = random_movie_row[rating_column_name]\n",
    "\n",
    "        similar_users_idx = np.argsort(-user_pcc_matrix[user_idx])[:num_similar_users + 1]\n",
    "        similar_users_idx = similar_users_idx[similar_users_idx != user_idx][:num_similar_users]\n",
    "\n",
    "        similar_users_ratings = \"\"\n",
    "        ratings_found_for_similar_items = False\n",
    "        for idx in similar_users_idx:\n",
    "            similar_user_id = unique_users[idx]\n",
    "            similar_user_data = data[data[user_column_name] == similar_user_id]\n",
    "\n",
    "            similar_items_indices = np.argsort(-item_pcc_matrix[random_movie_index, :])\n",
    "            for similar_item_index in similar_items_indices[:num_ratings_per_user]:\n",
    "                if similar_item_index == random_movie_index:\n",
    "                    continue\n",
    "\n",
    "                most_similar_item_id = unique_items[similar_item_index]\n",
    "                most_similar_item_ratings = similar_user_data[similar_user_data[movie_id_column] == most_similar_item_id][rating_column_name]\n",
    "                \n",
    "                # Pearson correlation coefficient for the item relative to the predicted item\n",
    "                pcc = item_pcc_matrix[random_movie_index, similar_item_index]\n",
    "                print(f\"Pearson correlation coefficient between '{random_movie_title}' and '{most_similar_item_id}': {pcc}\")\n",
    "\n",
    "                if not most_similar_item_ratings.empty:\n",
    "                    rating_info = f\"* Title: {most_similar_item_id}, Rating: {most_similar_item_ratings.iloc[0]} stars\"\n",
    "                    similar_users_ratings += rating_info + \"\\n\"\n",
    "                    ratings_found_for_similar_items = True\n",
    "\n",
    "            if not ratings_found_for_similar_items:\n",
    "                print(f\"No similar item ratings found for user {similar_user_id} for similar items to '{random_movie_title}'\")\n",
    "\n",
    "        if not ratings_found_for_similar_items:\n",
    "            print(f\"No similar item ratings found for any similar users to '{random_movie_title}'. Skipping prediction.\")\n",
    "            continue\n",
    "\n",
    "        combined_text = f\"Title: {random_movie_title}\"\n",
    "        prompt = f\"Main User Ratings:\\n{main_user_ratings_str}\\n\\nSimilar Users' Ratings:\\n{similar_users_ratings}\\n\\nPredict rating for '{combined_text}':\"\n",
    "\n",
    "        predicted_rating = predict_rating_combined_ChatCompletion(\n",
    "            combined_text, \n",
    "            approach=\"CF\", \n",
    "            similar_users_ratings=similar_users_ratings,\n",
    "            rating_history=main_user_ratings_str,\n",
    "            system_content=system_content\n",
    "        )\n",
    "\n",
    "        results.append([user_id, random_movie_id, random_movie_title, actual_rating, predicted_rating])\n",
    "        print(f\"User {user_id}: Predicted rating for '{random_movie_title}' is {predicted_rating}.\")\n",
    "\n",
    "    results_df = pd.DataFrame(results, columns=['user_id', 'item_id', 'title', 'actual_rating', 'predicted_rating'])\n",
    "    results_df.to_csv(save_path, index=False)\n",
    "    print(f\"Predictions saved to {save_path}\")\n",
    "\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Call the prediction function\n",
    "results_df = predict_ratings_with_CF_item_PCC_and_save(\n",
    "    data=data, \n",
    "    user_pcc_matrix=user_pcc_matrix, \n",
    "    item_pcc_matrix=item_pcc_matrix,\n",
    "    user_column_name=USER_COLUMN_NAME, \n",
    "    movie_column_name=TITLE_COLUMN_NAME, \n",
    "    movie_id_column=ITEM_ID_COLUMN,\n",
    "    rating_column_name=RATING_COLUMN_NAME, \n",
    "    num_ratings_per_user=NUM_RATINGS_PER_USER, \n",
    "    num_similar_users=NUM_SIMILAR_USERS,\n",
    "    num_main_user_ratings=NUM_MAIN_USER_RATINGS,\n",
    "    save_path=CF_OUTPUT_PATH, \n",
    "    seed=RANDOM_STATE\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate updated CF model predictions\n",
    "evaluate_model_predictions_rmse_mae(\n",
    "    data_path=CF_OUTPUT_PATH,\n",
    "    num_examples=NUM_EXAMPLES,\n",
    "    actual_ratings_column='actual_rating',\n",
    "    predicted_ratings_column='predicted_rating'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry_decorator\n",
    "def predict_rating_combined_ChatCompletion(combined_text, \n",
    "                                           model=GPT_MODEL_NAME, \n",
    "                                           temperature=TEMPERATURE, \n",
    "                                           approach=\"zero-shot\", \n",
    "                                           rating_history=None, \n",
    "                                           similar_users_ratings=None, \n",
    "                                           seed=RANDOM_STATE, \n",
    "                                           system_content=AMAZON_CONTENT_SYSTEM):\n",
    "    # Validation\n",
    "    if approach == \"few-shot\" and rating_history is None:\n",
    "        raise ValueError(\"Rating history is required for the few-shot approach.\")\n",
    "    if approach == \"CF\" and similar_users_ratings is None:\n",
    "        raise ValueError(\"Similar users' ratings are required for the collaborative filtering approach.\")\n",
    "    if not system_content:\n",
    "        raise ValueError(\"System content is required.\")\n",
    "    \n",
    "    # Initialize prompt variable\n",
    "    prompt = \"\"\n",
    "\n",
    "    # Check and reduce length of combined_text\n",
    "    combined_text = check_and_reduce_length(combined_text, MAX_TOKENS_CHAT_GPT // 3, TOKENIZER)\n",
    "\n",
    "    # Construct the prompt based on the approach\n",
    "    if approach == \"few-shot\":\n",
    "        rating_history = check_and_reduce_length(rating_history, MAX_TOKENS_CHAT_GPT // 3, TOKENIZER)\n",
    "        prompt += f\"\\n\\nHere is user rating history:\\n{rating_history}\"\n",
    "        prompt += f\"\\n\\nBased on above rating history, please predict user's rating for the product {combined_text}, (1 being lowest and 5 being highest,The output should be like: (x stars, xx%), do not explain the reason.)\"\n",
    "\n",
    "    elif approach == \"CF\":\n",
    "        rating_history = check_and_reduce_length(rating_history, MAX_TOKENS_CHAT_GPT // 3, TOKENIZER)\n",
    "        prompt += f\"\\n\\nHere is user rating history:\\n{rating_history}\"\n",
    "        similar_users_ratings = check_and_reduce_length(similar_users_ratings, MAX_TOKENS_CHAT_GPT // 3, TOKENIZER)\n",
    "        prompt += f\"\\n\\nHere is the rating history from users who are similar to this user:\\n{similar_users_ratings}\"\n",
    "        prompt += f\"\\n\\nBased on above rating history and similar users' rating history, please predict user's rating for the product {combined_text}, (1 being lowest and 5 being highest,The output should be like: (x stars, xx%), do not explain the reason.)\"\n",
    "        \n",
    "    else:\n",
    "        prompt = f\"How will user rate this product {combined_text}? (1 being lowest and 5 being highest) Attention! Just give me back the exact number as a result, and you don't need a lot of text.\"\n",
    "        \n",
    "\n",
    "    print(f\"Constructed Prompt for {approach} approach:\\n\")\n",
    "    print(f'The prompt:\\n**********\\n{prompt}\\n**********\\n')\n",
    "\n",
    "    try:\n",
    "        # Create the API call\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=model,\n",
    "            temperature=temperature,\n",
    "            max_tokens=MAX_TOKENS_CHAT_GPT,\n",
    "            seed=seed,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_content},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        # Extract the system fingerprint and print it\n",
    "        system_fingerprint = response.get('system_fingerprint')\n",
    "        print(f\"\\nSystem Fingerprint: {system_fingerprint}\")\n",
    "        # Extract and return the rating\n",
    "        rating_text = response.choices[0].message['content'].strip()\n",
    "        print(f'\\nAPI call response: \"{rating_text}\"')\n",
    "        extracted_rating = extract_numeric_rating(rating_text)\n",
    "        print(f'Extracted rating: {extracted_rating}\\n\\n\\n')\n",
    "        print(\"----------------------------------------------------------------------------------\")\n",
    "        return extracted_rating  # A float\n",
    "    \n",
    "    except APIError as api_err:\n",
    "        print(f\"API Error occurred: {api_err}\")\n",
    "        return None, str(api_err)\n",
    "    except RateLimitError as rate_err:\n",
    "        print(f\"Rate Limit Error occurred: {rate_err}\")\n",
    "        return None, str(rate_err)\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected Error: {e}\")\n",
    "        return None, str(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from scipy.spatial.distance import cosine\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Load SimCSE model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"princeton-nlp/sup-simcse-bert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"princeton-nlp/sup-simcse-bert-base-uncased\")\n",
    "\n",
    "def compute_semantic_similarity(text1, text2):\n",
    "    inputs = tokenizer([text1, text2], padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        embeddings = model(**inputs, output_hidden_states=True, return_dict=True).pooler_output\n",
    "    return 1 - cosine(embeddings[0], embeddings[1])\n",
    "\n",
    "def predict_ratings_semantic_similarity_CFfewshot_and_save(data, pcc_matrix, user_column_name='reviewerID', \n",
    "                                                           movie_column_name='title', movie_id_column='asin', \n",
    "                                                           rating_column_name='rating', num_ratings_per_user=NUM_RATINGS_PER_USER, \n",
    "                                                           num_similar_users=NUM_SIMILAR_USERS, num_main_user_ratings=NUM_MAIN_USER_RATINGS, \n",
    "                                                           save_path='cf_predictions.csv', seed=RANDOM_STATE,\n",
    "                                                           system_content=AMAZON_CONTENT_SYSTEM):\n",
    "    results = []\n",
    "    unique_users = data[user_column_name].unique()\n",
    "    user_id_to_index = {user_id: idx for idx, user_id in enumerate(unique_users)}\n",
    "\n",
    "    random.seed(seed)\n",
    "\n",
    "    for user_id in unique_users:\n",
    "        user_idx = user_id_to_index[user_id]\n",
    "        main_user_data = data[data[user_column_name] == user_id]\n",
    "        main_user_ratings = main_user_data.sample(n=num_main_user_ratings, random_state=seed)\n",
    "\n",
    "        similar_users_idx = np.argsort(-pcc_matrix[user_idx])[:num_similar_users + 1]\n",
    "        similar_users_idx = similar_users_idx[similar_users_idx != user_idx][:num_similar_users]\n",
    "\n",
    "        # Collect ratings from similar users\n",
    "        similar_users_ratings = \"\"\n",
    "        for similar_user_idx in similar_users_idx:\n",
    "            similar_user_id = unique_users[similar_user_idx]\n",
    "            similar_user_data = data[data[user_column_name] == similar_user_id]\n",
    "            similar_user_ratings = similar_user_data.sample(n=num_ratings_per_user, random_state=seed)\n",
    "            for _, rating_row in similar_user_ratings.iterrows():\n",
    "                similar_users_ratings += f\"* Title: {rating_row[movie_column_name]}, Rating: {rating_row[rating_column_name]} stars\\n\"\n",
    "\n",
    "        print(f\"Similar users' ratings for user {user_id}:\\n{similar_users_ratings}\")\n",
    "\n",
    "        potential_movies_for_prediction = main_user_data[~main_user_data[movie_id_column].isin(main_user_ratings[movie_id_column])]\n",
    "        if potential_movies_for_prediction.empty:\n",
    "            continue\n",
    "\n",
    "        random_movie_row = potential_movies_for_prediction.sample(n=1, random_state=seed).iloc[0]\n",
    "        random_movie_title = random_movie_row[movie_column_name]\n",
    "        actual_rating = random_movie_row[rating_column_name]\n",
    "\n",
    "        # Compute semantic similarities\n",
    "        similarities = []\n",
    "        for _, row in main_user_ratings.iterrows():\n",
    "            main_movie_title = row[movie_column_name]\n",
    "            similarity = compute_semantic_similarity(main_movie_title, random_movie_title)\n",
    "            similarities.append(similarity)\n",
    "        \n",
    "        average_similarity = np.mean(similarities)\n",
    "        print(f\"Average semantic similarity for '{random_movie_title}' with user's history: {average_similarity}\")\n",
    "\n",
    "        combined_text = f\"Title: {random_movie_title}\"\n",
    "\n",
    "        predicted_rating = predict_rating_combined_ChatCompletion(\n",
    "            combined_text, \n",
    "            approach=\"CF\", \n",
    "            similar_users_ratings=similar_users_ratings,\n",
    "            rating_history=main_user_ratings,\n",
    "            system_content=system_content\n",
    "        )\n",
    "\n",
    "        results.append([user_id, random_movie_row[movie_id_column], random_movie_title, actual_rating, predicted_rating])\n",
    "\n",
    "    results_df = pd.DataFrame(results, columns=['user_id', 'item_id', 'title', 'actual_rating', 'predicted_rating'])\n",
    "    results_df.to_csv(save_path, index=False)\n",
    "    print(f\"Predictions saved to {save_path}\")\n",
    "\n",
    "    return results_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Call the prediction function\n",
    "results_df = predict_ratings_with_CF_item_PCC_and_save(\n",
    "    data=data, \n",
    "    user_pcc_matrix=user_pcc_matrix, \n",
    "    item_pcc_matrix=item_pcc_matrix,\n",
    "    user_column_name=USER_COLUMN_NAME, \n",
    "    movie_column_name=TITLE_COLUMN_NAME, \n",
    "    movie_id_column=ITEM_ID_COLUMN,\n",
    "    rating_column_name=RATING_COLUMN_NAME, \n",
    "    num_ratings_per_user=NUM_RATINGS_PER_USER, \n",
    "    num_similar_users=NUM_SIMILAR_USERS,\n",
    "    num_main_user_ratings=NUM_MAIN_USER_RATINGS,\n",
    "    save_path=CF_OUTPUT_PATH, \n",
    "    seed=RANDOM_STATE\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate updated CF model predictions\n",
    "evaluate_model_predictions_rmse_mae(\n",
    "    data_path=CF_OUTPUT_PATH,\n",
    "    num_examples=NUM_EXAMPLES,\n",
    "    actual_ratings_column='actual_rating',\n",
    "    predicted_ratings_column='predicted_rating'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FAll back to random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from scipy.spatial.distance import cosine\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"princeton-nlp/sup-simcse-bert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"princeton-nlp/sup-simcse-bert-base-uncased\")\n",
    "\n",
    "\n",
    "@retry_decorator\n",
    "def predict_rating_combined_ChatCompletion(combined_text, \n",
    "                                           model=GPT_MODEL_NAME, \n",
    "                                           temperature=TEMPERATURE, \n",
    "                                           approach=\"zero-shot\", \n",
    "                                           rating_history=None, \n",
    "                                           similar_users_ratings=None, \n",
    "                                           seed=RANDOM_STATE, \n",
    "                                           system_content=AMAZON_CONTENT_SYSTEM):\n",
    "    # Validation\n",
    "    if approach == \"few-shot\" and rating_history is None:\n",
    "        raise ValueError(\"Rating history is required for the few-shot approach.\")\n",
    "    if approach == \"CF\" and similar_users_ratings is None:\n",
    "        raise ValueError(\"Similar users' ratings are required for the collaborative filtering approach.\")\n",
    "    if not system_content:\n",
    "        raise ValueError(\"System content is required.\")\n",
    "    \n",
    "    # Initialize prompt variable\n",
    "    prompt = \"\"\n",
    "\n",
    "    # Check and reduce length of combined_text\n",
    "    combined_text = check_and_reduce_length(combined_text, MAX_TOKENS_CHAT_GPT // 3, TOKENIZER)\n",
    "\n",
    "    # Construct the prompt based on the approach\n",
    "    if approach == \"few-shot\":\n",
    "        rating_history = check_and_reduce_length(rating_history, MAX_TOKENS_CHAT_GPT // 3, TOKENIZER)\n",
    "        prompt += f\"\\n\\nHere is user rating history:\\n{rating_history}\"\n",
    "        prompt += f\"\\n\\nBased on above rating history, please predict user's rating for the product {combined_text}, (1 being lowest and 5 being highest,The output should be like: (x stars, xx%), do not explain the reason.)\"\n",
    "\n",
    "    elif approach == \"CF\":\n",
    "        rating_history = check_and_reduce_length(rating_history, MAX_TOKENS_CHAT_GPT // 3, TOKENIZER)\n",
    "        prompt += f\"\\n\\nHere is user rating history:\\n{rating_history}\"\n",
    "        similar_users_ratings = check_and_reduce_length(similar_users_ratings, MAX_TOKENS_CHAT_GPT // 3, TOKENIZER)\n",
    "        prompt += f\"\\n\\nHere is the rating history from users who are similar to this user:\\n{similar_users_ratings}\"\n",
    "        prompt += f\"\\n\\nBased on above rating history and similar users' rating history, please predict user's rating for the product {combined_text}, (1 being lowest and 5 being highest,The output should be like: (x stars, xx%), do not explain the reason.)\"\n",
    "        \n",
    "    else:\n",
    "        prompt = f\"How will user rate this product {combined_text}? (1 being lowest and 5 being highest) Attention! Just give me back the exact number as a result, and you don't need a lot of text.\"\n",
    "        \n",
    "\n",
    "    print(f\"Constructed Prompt for {approach} approach:\\n\")\n",
    "    print(f'The prompt:\\n**********\\n{prompt}\\n**********\\n')\n",
    "\n",
    "    try:\n",
    "        # Create the API call\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=model,\n",
    "            temperature=temperature,\n",
    "            max_tokens=MAX_TOKENS_CHAT_GPT,\n",
    "            seed=seed,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_content},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        # Extract the system fingerprint and print it\n",
    "        system_fingerprint = response.get('system_fingerprint')\n",
    "        print(f\"\\nSystem Fingerprint: {system_fingerprint}\")\n",
    "        # Extract and return the rating\n",
    "        rating_text = response.choices[0].message['content'].strip()\n",
    "        print(f'\\nAPI call response: \"{rating_text}\"')\n",
    "        extracted_rating = extract_numeric_rating(rating_text)\n",
    "        print(f'Extracted rating: {extracted_rating}\\n\\n\\n')\n",
    "        print(\"----------------------------------------------------------------------------------\")\n",
    "        return extracted_rating  # A float\n",
    "    \n",
    "    except APIError as api_err:\n",
    "        print(f\"API Error occurred: {api_err}\")\n",
    "        return None, str(api_err)\n",
    "    except RateLimitError as rate_err:\n",
    "        print(f\"Rate Limit Error occurred: {rate_err}\")\n",
    "        return None, str(rate_err)\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected Error: {e}\")\n",
    "        return None, str(e)\n",
    "\n",
    "def predict_ratings_with_collaborative_filtering_and_save(data, pcc_matrix, \n",
    "                                                          user_column_name='reviewerID', \n",
    "                                                          movie_column_name='title', \n",
    "                                                          movie_id_column='asin',\n",
    "                                                          rating_column_name='rating', \n",
    "                                                          num_ratings_per_user=NUM_RATINGS_PER_USER, \n",
    "                                                          num_similar_users=NUM_SIMILAR_USERS,\n",
    "                                                          num_main_user_ratings=NUM_MAIN_USER_RATINGS,\n",
    "                                                          save_path='cf_predictions.csv', \n",
    "                                                          seed=RANDOM_STATE,\n",
    "                                                          system_content=AMAZON_CONTENT_SYSTEM):\n",
    "    results = []\n",
    "    unique_users = data[user_column_name].unique()\n",
    "    user_id_to_index = {user_id: idx for idx, user_id in enumerate(unique_users)}\n",
    "    \n",
    "    random.seed(seed)\n",
    "\n",
    "    for user_id in unique_users:\n",
    "        user_idx = user_id_to_index[user_id]\n",
    "\n",
    "        print(f\"Processing user {user_id} (Index: {user_idx})\")\n",
    "\n",
    "        # Retrieve the main user's historical ratings randomly\n",
    "        main_user_data = data[data[user_column_name] == user_id]\n",
    "        main_user_ratings = main_user_data.sample(n=num_main_user_ratings, random_state=seed)\n",
    "\n",
    "        main_user_ratings_str = '\\n'.join([\n",
    "            f\"* Title: {row[movie_column_name]}, Rating: {row[rating_column_name]} stars\"\n",
    "            for _, row in main_user_ratings.iterrows()\n",
    "        ])\n",
    "        print(f\"Main user's historical ratings:\\n{main_user_ratings_str}\")\n",
    "\n",
    "        # Find the top similar users based on Pearson Correlation Coefficient\n",
    "        similar_users_idx = np.argsort(-pcc_matrix[user_idx])[:num_similar_users + 1]\n",
    "        similar_users_idx = similar_users_idx[similar_users_idx != user_idx][:num_similar_users]\n",
    "\n",
    "        print(f\"Top similar users for {user_id}: {[unique_users[idx] for idx in similar_users_idx]}\")\n",
    "\n",
    "        # Collect historical ratings from similar users randomly\n",
    "        similar_users_ratings = \"\"\n",
    "        for idx in similar_users_idx:\n",
    "            similar_user_id = unique_users[idx]\n",
    "            similar_user_data = data[data[user_column_name] == similar_user_id]\n",
    "            historical_ratings = similar_user_data.sample(n=num_ratings_per_user, random_state=seed)\n",
    "            for _, row in historical_ratings.iterrows():\n",
    "                rating_info = f\"* Title: {row[movie_column_name]}, Rating: {row[rating_column_name]} stars\"\n",
    "                similar_users_ratings += rating_info + \"\\n\"\n",
    "        print(f\"Similar users' historical ratings:\\n{similar_users_ratings}\")\n",
    "                \n",
    "        # List of movie IDs already rated by the user\n",
    "        rated_movie_ids = main_user_ratings[movie_id_column].tolist()\n",
    "\n",
    "        # Exclude already rated movies and select a random movie for prediction\n",
    "        potential_movies_for_prediction = main_user_data[~main_user_data[movie_id_column].isin(rated_movie_ids)]\n",
    "        if potential_movies_for_prediction.empty:\n",
    "            print(f\"No unrated movies available for user {user_id} for prediction.\")\n",
    "            continue\n",
    "\n",
    "        random_movie_row = potential_movies_for_prediction.sample(n=1, random_state=seed).iloc[0]\n",
    "        random_movie_title = random_movie_row[movie_column_name]\n",
    "        random_movie_id = random_movie_row[movie_id_column]\n",
    "        actual_rating = random_movie_row[rating_column_name]\n",
    "        print(f\"Selected random movie '{random_movie_title}' for prediction.\")\n",
    "\n",
    "        # Construct prompt for API call\n",
    "        combined_text = f\"Title: {random_movie_title}\"\n",
    "        prompt = f\"Main User Ratings:\\n{main_user_ratings_str}\\n\\nSimilar Users' Ratings:\\n{similar_users_ratings}\\n\\nPredict rating for '{combined_text}':\"\n",
    "\n",
    "        print(f\"Generated prompt for user {user_id}:\\n{prompt}\")\n",
    "\n",
    "        predicted_rating = predict_rating_combined_ChatCompletion(\n",
    "            combined_text, \n",
    "            approach=\"CF\", \n",
    "            similar_users_ratings=similar_users_ratings,\n",
    "            rating_history=main_user_ratings_str,\n",
    "            system_content=system_content\n",
    "        )\n",
    "\n",
    "        # Store prediction results\n",
    "        results.append([user_id, random_movie_id, random_movie_title, actual_rating, predicted_rating])\n",
    "\n",
    "        print(f\"User {user_id}: Predicted rating for '{random_movie_title}' is {predicted_rating}.\")\n",
    "\n",
    "    results_df = pd.DataFrame(results, columns=['user_id', 'item_id', 'title', 'actual_rating', 'predicted_rating'])\n",
    "    results_df.to_csv(save_path, index=False)\n",
    "    print(f\"Predictions saved to {save_path}\")\n",
    "\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Call the prediction function\n",
    "results_df = predict_ratings_with_CF_item_PCC_and_save(\n",
    "    data=data, \n",
    "    user_pcc_matrix=user_pcc_matrix, \n",
    "    item_pcc_matrix=item_pcc_matrix,\n",
    "    user_column_name=USER_COLUMN_NAME, \n",
    "    movie_column_name=TITLE_COLUMN_NAME, \n",
    "    movie_id_column=ITEM_ID_COLUMN,\n",
    "    rating_column_name=RATING_COLUMN_NAME, \n",
    "    num_ratings_per_user=NUM_RATINGS_PER_USER, \n",
    "    num_similar_users=NUM_SIMILAR_USERS,\n",
    "    num_main_user_ratings=NUM_MAIN_USER_RATINGS,\n",
    "    save_path=CF_OUTPUT_PATH, \n",
    "    seed=RANDOM_STATE\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate updated CF model predictions\n",
    "evaluate_model_predictions_rmse_mae(\n",
    "    data_path=CF_OUTPUT_PATH,\n",
    "    num_examples=NUM_EXAMPLES,\n",
    "    actual_ratings_column='actual_rating',\n",
    "    predicted_ratings_column='predicted_rating'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "cf_predictions = predict_ratings_with_CF_item_PCC_and_save(data, \n",
    "                                                                       pcc_matrix, \n",
    "                                                                       save_path=CF_OUTPUT_PATH,\n",
    "                                                                       user_column_name=USER_COLUMN_NAME,\n",
    "                                                                       movie_column_name=TITLE_COLUMN_NAME,\n",
    "                                                                       movie_id_column=ITEM_ID_COLUMN,\n",
    "                                                                       rating_column_name=RATING_COLUMN_NAME, \n",
    "                                                                       num_ratings_per_user=NUM_RATINGS_PER_USER,\n",
    "                                                                       num_main_user_ratings=NUM_MAIN_USER_RATINGS,\n",
    "                                                                       num_similar_users=NUM_SIMILAR_USERS,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "saved_data = pd.read_csv(CF_OUTPUT_PATH)\n",
    "\n",
    "# Display the original data types\n",
    "print(\"Original Data Types:\")\n",
    "print(saved_data.dtypes)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Attempt to convert ratings to float and add a flag for conversion failure\n",
    "saved_data['is_rating_float'] = pd.to_numeric(saved_data['predicted_rating'], errors='coerce').notna()\n",
    "\n",
    "# Filter rows where ratings are not float\n",
    "non_float_ratings = saved_data[saved_data['is_rating_float'] == False]\n",
    "\n",
    "# total number of rows with non-float ratings\n",
    "print(f\"Total number of rows with non-float ratings: {len(non_float_ratings)}\")\n",
    "\n",
    "# rerun indices for non-float ratings\n",
    "rerun_indices = non_float_ratings.index.tolist()\n",
    "print(f\"Rerun indices: {rerun_indices}\")\n",
    "\n",
    "# Display rows with non-float ratings\n",
    "print(\"Rows with non-float ratings:\")\n",
    "non_float_ratings.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "rerun_failed_CF_fewshot_predictions(data, \n",
    "                                    pcc_matrix, \n",
    "                                    save_path=CF_OUTPUT_PATH,\n",
    "                                    user_column_name=USER_COLUMN_NAME,\n",
    "                                    movie_column_name=TITLE_COLUMN_NAME,\n",
    "                                    movie_id_column=ITEM_ID_COLUMN,\n",
    "                                    rating_column_name=RATING_COLUMN_NAME, \n",
    "                                    num_ratings_per_user=NUM_RATINGS_PER_USER,\n",
    "                                    num_main_user_ratings=NUM_MAIN_USER_RATINGS,\n",
    "                                    num_similar_users=NUM_SIMILAR_USERS, \n",
    "                                    new_path=CF_RERUN_PATH,\n",
    "                                    rerun_indices=rerun_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rerun_data = pd.read_csv(CF_RERUN_PATH)\n",
    "rerun_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CF_RERUN_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate updated CF model predictions\n",
    "evaluate_model_predictions_rmse_mae(\n",
    "    data_path=CF_RERUN_PATH,\n",
    "    num_examples=NUM_EXAMPLES,\n",
    "    actual_ratings_column='actual_rating',\n",
    "    predicted_ratings_column='predicted_rating'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# output\n",
    "CF_OUTPUT_PATH = os.path.join(DATA_DIR, 'ml-1m/output/CF_fewshot_output_path_ratings_per_user_2nd.dat')\n",
    "print(f'Data path: {data_path}')\n",
    "\n",
    "CF_RERUN_PATH = os.path.join(DATA_DIR, 'ml-1m/output/rerun_CF_fewshot_output_path_ratings_per_user_2nd.dat')\n",
    "print(f'Data path: {data_path}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cf_predictions = predict_ratings_with_CF_item_PCC_and_save(data, \n",
    "                                                                       pcc_matrix, \n",
    "                                                                       save_path=CF_OUTPUT_PATH,\n",
    "                                                                       user_column_name=USER_COLUMN_NAME,\n",
    "                                                                       movie_column_name=TITLE_COLUMN_NAME,\n",
    "                                                                       movie_id_column=ITEM_ID_COLUMN,\n",
    "                                                                       rating_column_name=RATING_COLUMN_NAME, \n",
    "                                                                       num_ratings_per_user=NUM_RATINGS_PER_USER,\n",
    "                                                                       num_main_user_ratings=NUM_MAIN_USER_RATINGS,\n",
    "                                                                       num_similar_users=NUM_SIMILAR_USERS, )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "saved_data = pd.read_csv(CF_OUTPUT_PATH)\n",
    "\n",
    "# Display the original data types\n",
    "print(\"Original Data Types:\")\n",
    "print(saved_data.dtypes)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Attempt to convert ratings to float and add a flag for conversion failure\n",
    "saved_data['is_rating_float'] = pd.to_numeric(saved_data['predicted_rating'], errors='coerce').notna()\n",
    "\n",
    "# Filter rows where ratings are not float\n",
    "non_float_ratings = saved_data[saved_data['is_rating_float'] == False]\n",
    "\n",
    "# total number of rows with non-float ratings\n",
    "print(f\"Total number of rows with non-float ratings: {len(non_float_ratings)}\")\n",
    "\n",
    "# rerun indices for non-float ratings\n",
    "rerun_indices = non_float_ratings.index.tolist()\n",
    "print(f\"Rerun indices: {rerun_indices}\")\n",
    "\n",
    "# Display rows with non-float ratings\n",
    "print(\"Rows with non-float ratings:\")\n",
    "non_float_ratings.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "rerun_failed_CF_fewshot_predictions(data, \n",
    "                                    pcc_matrix, \n",
    "                                    save_path=CF_OUTPUT_PATH,\n",
    "                                    user_column_name=USER_COLUMN_NAME,\n",
    "                                    movie_column_name=TITLE_COLUMN_NAME,\n",
    "                                    movie_id_column=ITEM_ID_COLUMN,\n",
    "                                    rating_column_name=RATING_COLUMN_NAME, \n",
    "                                    num_ratings_per_user=NUM_RATINGS_PER_USER,\n",
    "                                    num_main_user_ratings=NUM_MAIN_USER_RATINGS,\n",
    "                                    num_similar_users=NUM_SIMILAR_USERS, , \n",
    "                                    new_path=CF_RERUN_PATH,\n",
    "                                    rerun_indices=rerun_indices)\n",
    "\n",
    "\n",
    "# Evaluate updated CF model predictions\n",
    "evaluate_model_predictions_rmse_mae(\n",
    "    data_path=CF_RERUN_PATH,\n",
    "    num_examples=NUM_EXAMPLES,\n",
    "    actual_ratings_column='actual_rating',\n",
    "    predicted_ratings_column='predicted_rating'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Third iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# output\n",
    "CF_OUTPUT_PATH = os.path.join(DATA_DIR, 'ml-1m/output/CF_fewshot_output_path_ratings_per_user_3rd.dat')\n",
    "print(f'Data path: {data_path}')\n",
    "\n",
    "CF_RERUN_PATH = os.path.join(DATA_DIR, 'ml-1m/output/rerun_CF_fewshot_output_path_ratings_per_user_3rd.dat')\n",
    "print(f'Data path: {data_path}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cf_predictions = predict_ratings_with_CF_item_PCC_and_save(data, \n",
    "                                                                       pcc_matrix, \n",
    "                                                                       save_path=CF_OUTPUT_PATH,\n",
    "                                                                       user_column_name=USER_COLUMN_NAME,\n",
    "                                                                       movie_column_name=TITLE_COLUMN_NAME,\n",
    "                                                                       movie_id_column=ITEM_ID_COLUMN,\n",
    "                                                                       rating_column_name=RATING_COLUMN_NAME, \n",
    "                                                                       num_ratings_per_user=NUM_RATINGS_PER_USER,\n",
    "                                                                       num_main_user_ratings=NUM_MAIN_USER_RATINGS,\n",
    "                                                                       num_similar_users=NUM_SIMILAR_USERS, )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "saved_data = pd.read_csv(CF_OUTPUT_PATH)\n",
    "\n",
    "# Display the original data types\n",
    "print(\"Original Data Types:\")\n",
    "print(saved_data.dtypes)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Attempt to convert ratings to float and add a flag for conversion failure\n",
    "saved_data['is_rating_float'] = pd.to_numeric(saved_data['predicted_rating'], errors='coerce').notna()\n",
    "\n",
    "# Filter rows where ratings are not float\n",
    "non_float_ratings = saved_data[saved_data['is_rating_float'] == False]\n",
    "\n",
    "# total number of rows with non-float ratings\n",
    "print(f\"Total number of rows with non-float ratings: {len(non_float_ratings)}\")\n",
    "\n",
    "# rerun indices for non-float ratings\n",
    "rerun_indices = non_float_ratings.index.tolist()\n",
    "print(f\"Rerun indices: {rerun_indices}\")\n",
    "\n",
    "# Display rows with non-float ratings\n",
    "print(\"Rows with non-float ratings:\")\n",
    "non_float_ratings.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "rerun_failed_CF_fewshot_predictions(data, \n",
    "                                    pcc_matrix, \n",
    "                                    save_path=CF_OUTPUT_PATH,\n",
    "                                    user_column_name=USER_COLUMN_NAME,\n",
    "                                    movie_column_name=TITLE_COLUMN_NAME,\n",
    "                                    movie_id_column=ITEM_ID_COLUMN,\n",
    "                                    rating_column_name=RATING_COLUMN_NAME, \n",
    "                                    num_ratings_per_user=NUM_RATINGS_PER_USER,\n",
    "                                    num_main_user_ratings=NUM_MAIN_USER_RATINGS,\n",
    "                                    num_similar_users=NUM_SIMILAR_USERS, , \n",
    "                                    new_path=CF_RERUN_PATH,\n",
    "                                    rerun_indices=rerun_indices)\n",
    "\n",
    "\n",
    "# Evaluate updated CF model predictions\n",
    "evaluate_model_predictions_rmse_mae(\n",
    "    data_path=CF_RERUN_PATH,\n",
    "    num_examples=NUM_EXAMPLES,\n",
    "    actual_ratings_column='actual_rating',\n",
    "    predicted_ratings_column='predicted_rating'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fourth iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# output\n",
    "CF_OUTPUT_PATH = os.path.join(DATA_DIR, 'ml-1m/output/CF_fewshot_output_path_ratings_per_user_4th.dat')\n",
    "print(f'Data path: {data_path}')\n",
    "\n",
    "CF_RERUN_PATH = os.path.join(DATA_DIR, 'ml-1m/output/rerun_CF_fewshot_output_path_ratings_per_user_4th.dat')\n",
    "print(f'Data path: {data_path}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cf_predictions = predict_ratings_with_CF_item_PCC_and_save(data, \n",
    "                                                                       pcc_matrix, \n",
    "                                                                       save_path=CF_OUTPUT_PATH,\n",
    "                                                                       user_column_name=USER_COLUMN_NAME,\n",
    "                                                                       movie_column_name=TITLE_COLUMN_NAME,\n",
    "                                                                       movie_id_column=ITEM_ID_COLUMN,\n",
    "                                                                       rating_column_name=RATING_COLUMN_NAME, \n",
    "                                                                       num_ratings_per_user=NUM_RATINGS_PER_USER,\n",
    "                                                                       num_main_user_ratings=NUM_MAIN_USER_RATINGS,\n",
    "                                                                       num_similar_users=NUM_SIMILAR_USERS, )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "saved_data = pd.read_csv(CF_OUTPUT_PATH)\n",
    "\n",
    "# Display the original data types\n",
    "print(\"Original Data Types:\")\n",
    "print(saved_data.dtypes)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Attempt to convert ratings to float and add a flag for conversion failure\n",
    "saved_data['is_rating_float'] = pd.to_numeric(saved_data['predicted_rating'], errors='coerce').notna()\n",
    "\n",
    "# Filter rows where ratings are not float\n",
    "non_float_ratings = saved_data[saved_data['is_rating_float'] == False]\n",
    "\n",
    "# total number of rows with non-float ratings\n",
    "print(f\"Total number of rows with non-float ratings: {len(non_float_ratings)}\")\n",
    "\n",
    "# rerun indices for non-float ratings\n",
    "rerun_indices = non_float_ratings.index.tolist()\n",
    "print(f\"Rerun indices: {rerun_indices}\")\n",
    "\n",
    "# Display rows with non-float ratings\n",
    "print(\"Rows with non-float ratings:\")\n",
    "non_float_ratings.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "rerun_failed_CF_fewshot_predictions(data, \n",
    "                                    pcc_matrix, \n",
    "                                    save_path=CF_OUTPUT_PATH,\n",
    "                                    user_column_name=USER_COLUMN_NAME,\n",
    "                                    movie_column_name=TITLE_COLUMN_NAME,\n",
    "                                    movie_id_column=ITEM_ID_COLUMN,\n",
    "                                    rating_column_name=RATING_COLUMN_NAME, \n",
    "                                    num_ratings_per_user=NUM_RATINGS_PER_USER,\n",
    "                                    num_main_user_ratings=NUM_MAIN_USER_RATINGS,\n",
    "                                    num_similar_users=NUM_SIMILAR_USERS,\n",
    "                                    new_path=CF_RERUN_PATH,\n",
    "                                    rerun_indices=rerun_indices)\n",
    "\n",
    "\n",
    "# Evaluate updated CF model predictions\n",
    "evaluate_model_predictions_rmse_mae(\n",
    "    data_path=CF_RERUN_PATH,\n",
    "    num_examples=NUM_EXAMPLES,\n",
    "    actual_ratings_column='actual_rating',\n",
    "    predicted_ratings_column='predicted_rating'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fifth Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# output\n",
    "CF_OUTPUT_PATH = os.path.join(DATA_DIR, 'ml-1m/output/CF_fewshot_output_path_ratings_per_user_5th.dat')\n",
    "print(f'Data path: {data_path}')\n",
    "\n",
    "CF_RERUN_PATH = os.path.join(DATA_DIR, 'ml-1m/output/rerun_CF_fewshot_output_path_ratings_per_user_5th.dat')\n",
    "print(f'Data path: {data_path}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cf_predictions = predict_ratings_with_CF_item_PCC_and_save(data, \n",
    "                                                                       pcc_matrix, \n",
    "                                                                       save_path=CF_OUTPUT_PATH,\n",
    "                                                                       user_column_name=USER_COLUMN_NAME,\n",
    "                                                                       movie_column_name=TITLE_COLUMN_NAME,\n",
    "                                                                       movie_id_column=ITEM_ID_COLUMN,\n",
    "                                                                       rating_column_name=RATING_COLUMN_NAME, \n",
    "                                                                       num_ratings_per_user=NUM_RATINGS_PER_USER,\n",
    "                                                                       num_main_user_ratings=NUM_MAIN_USER_RATINGS,\n",
    "                                                                       num_similar_users=NUM_SIMILAR_USERS, )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "saved_data = pd.read_csv(CF_OUTPUT_PATH)\n",
    "\n",
    "# Display the original data types\n",
    "print(\"Original Data Types:\")\n",
    "print(saved_data.dtypes)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Attempt to convert ratings to float and add a flag for conversion failure\n",
    "saved_data['is_rating_float'] = pd.to_numeric(saved_data['predicted_rating'], errors='coerce').notna()\n",
    "\n",
    "# Filter rows where ratings are not float\n",
    "non_float_ratings = saved_data[saved_data['is_rating_float'] == False]\n",
    "\n",
    "# total number of rows with non-float ratings\n",
    "print(f\"Total number of rows with non-float ratings: {len(non_float_ratings)}\")\n",
    "\n",
    "# rerun indices for non-float ratings\n",
    "rerun_indices = non_float_ratings.index.tolist()\n",
    "print(f\"Rerun indices: {rerun_indices}\")\n",
    "\n",
    "# Display rows with non-float ratings\n",
    "print(\"Rows with non-float ratings:\")\n",
    "non_float_ratings.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "rerun_failed_CF_fewshot_predictions(data, \n",
    "                                    pcc_matrix, \n",
    "                                    save_path=CF_OUTPUT_PATH,\n",
    "                                    user_column_name=USER_COLUMN_NAME,\n",
    "                                    movie_column_name=TITLE_COLUMN_NAME,\n",
    "                                    movie_id_column=ITEM_ID_COLUMN,\n",
    "                                    rating_column_name=RATING_COLUMN_NAME, \n",
    "                                    num_ratings_per_user=NUM_RATINGS_PER_USER,\n",
    "                                    num_main_user_ratings=NUM_MAIN_USER_RATINGS,\n",
    "                                    num_similar_users=NUM_SIMILAR_USERS,\n",
    "                                    new_path=CF_RERUN_PATH,\n",
    "                                    rerun_indices=rerun_indices)\n",
    "\n",
    "\n",
    "# Evaluate updated CF model predictions\n",
    "evaluate_model_predictions_rmse_mae(\n",
    "    data_path=CF_RERUN_PATH,\n",
    "    num_examples=NUM_EXAMPLES,\n",
    "    actual_ratings_column='actual_rating',\n",
    "    predicted_ratings_column='predicted_rating'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sixth Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# output\n",
    "CF_OUTPUT_PATH = os.path.join(DATA_DIR, 'ml-1m/output/CF_fewshot_output_path_ratings_per_user_6th.dat')\n",
    "print(f'Data path: {data_path}')\n",
    "\n",
    "CF_RERUN_PATH = os.path.join(DATA_DIR, 'ml-1m/output/rerun_CF_fewshot_output_path_ratings_per_user_6th.dat')\n",
    "print(f'Data path: {data_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# output\n",
    "CF_OUTPUT_PATH = os.path.join(DATA_DIR, 'ml-1m/output/CF_fewshot_output_path_ratings_per_user_6th.dat')\n",
    "print(f'Data path: {data_path}')\n",
    "\n",
    "CF_RERUN_PATH = os.path.join(DATA_DIR, 'ml-1m/output/rerun_CF_fewshot_output_path_ratings_per_user_6th.dat')\n",
    "print(f'Data path: {data_path}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cf_predictions = predict_ratings_with_CF_item_PCC_and_save(data, \n",
    "                                                                       pcc_matrix, \n",
    "                                                                       save_path=CF_OUTPUT_PATH,\n",
    "                                                                       user_column_name=USER_COLUMN_NAME,\n",
    "                                                                       movie_column_name=TITLE_COLUMN_NAME,\n",
    "                                                                       movie_id_column=ITEM_ID_COLUMN,\n",
    "                                                                       rating_column_name=RATING_COLUMN_NAME, \n",
    "                                                                       num_ratings_per_user=NUM_RATINGS_PER_USER,\n",
    "                                                                       num_main_user_ratings=NUM_MAIN_USER_RATINGS,\n",
    "                                                                       num_similar_users=NUM_SIMILAR_USERS, )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "saved_data = pd.read_csv(CF_OUTPUT_PATH)\n",
    "\n",
    "# Display the original data types\n",
    "print(\"Original Data Types:\")\n",
    "print(saved_data.dtypes)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Attempt to convert ratings to float and add a flag for conversion failure\n",
    "saved_data['is_rating_float'] = pd.to_numeric(saved_data['predicted_rating'], errors='coerce').notna()\n",
    "\n",
    "# Filter rows where ratings are not float\n",
    "non_float_ratings = saved_data[saved_data['is_rating_float'] == False]\n",
    "\n",
    "# total number of rows with non-float ratings\n",
    "print(f\"Total number of rows with non-float ratings: {len(non_float_ratings)}\")\n",
    "\n",
    "# rerun indices for non-float ratings\n",
    "rerun_indices = non_float_ratings.index.tolist()\n",
    "print(f\"Rerun indices: {rerun_indices}\")\n",
    "\n",
    "# Display rows with non-float ratings\n",
    "print(\"Rows with non-float ratings:\")\n",
    "non_float_ratings.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "rerun_failed_CF_fewshot_predictions(data, \n",
    "                                    pcc_matrix, \n",
    "                                    save_path=CF_OUTPUT_PATH,\n",
    "                                    user_column_name=USER_COLUMN_NAME,\n",
    "                                    movie_column_name=TITLE_COLUMN_NAME,\n",
    "                                    movie_id_column=ITEM_ID_COLUMN,\n",
    "                                    rating_column_name=RATING_COLUMN_NAME, \n",
    "                                    num_ratings_per_user=NUM_RATINGS_PER_USER,\n",
    "                                    num_main_user_ratings=NUM_MAIN_USER_RATINGS,\n",
    "                                    num_similar_users=NUM_SIMILAR_USERS,\n",
    "                                    new_path=CF_RERUN_PATH,\n",
    "                                    rerun_indices=rerun_indices)\n",
    "\n",
    "\n",
    "# Evaluate updated CF model predictions\n",
    "evaluate_model_predictions_rmse_mae(\n",
    "    data_path=CF_RERUN_PATH,\n",
    "    num_examples=NUM_EXAMPLES,\n",
    "    actual_ratings_column='actual_rating',\n",
    "    predicted_ratings_column='predicted_rating'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
