{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import openai\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "# Add the path to the constants file to the system path\n",
    "sys.path.append('../../')\n",
    "from constants import *\n",
    "from evaluation_utils import *\n",
    "from path_utils import *\n",
    "from ChatCompletion_OpenAI_API import *\n",
    "\n",
    "# OpenAI API Key\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "SYSTEM_CONTENT = AMAZON_CONTENT_SYSTEM\n",
    "\n",
    "# Constants for column names\n",
    "USER_COLUMN_NAME = 'reviewerID'\n",
    "TITLE_COLUMN_NAME = 'title'\n",
    "ITEM_ID_COLUMN = 'asin'\n",
    "RATING_COLUMN_NAME = 'rating'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source code folder path\n",
    "rec_sys_dir = get_rec_sys_directory()\n",
    "print(f\"Rec-sys directory: {rec_sys_dir}\")\n",
    "\n",
    "# data folder path\n",
    "DATA_DIR = os.path.join(rec_sys_dir, 'data')\n",
    "print(f\"Data directory: {DATA_DIR}\")\n",
    "\n",
    "# data path\n",
    "data_path = os.path.join(DATA_DIR, 'amazon-beauty/large_merged_data.csv')\n",
    "print(f'Data path: {data_path}')\n",
    "\n",
    "# zero shot save path\n",
    "ZERO_SHOT_SAVE_PATH = os.path.join(DATA_DIR, 'amazon-beauty/output/title_large_predictions_zero_shot.csv')\n",
    "print(f'Zero shot save path: {ZERO_SHOT_SAVE_PATH}')\n",
    "\n",
    "# few shot save path\n",
    "FEW_SHOT_1_OBS_SAVE_PATH = os.path.join(DATA_DIR, 'amazon-beauty/output/title_large_1_test_predictions_few_shot.csv')\n",
    "print(f'Few shot save path: {FEW_SHOT_1_OBS_SAVE_PATH}')\n",
    "\n",
    "\n",
    "\n",
    "# few shot save path\n",
    "FEW_SHOT_1_OBS_RERUN_PATH = os.path.join(DATA_DIR, 'amazon-beauty/output/rerun_title_large_1_test_predictions_few_shot.csv')\n",
    "print(f'Few shot rerun path: {FEW_SHOT_1_OBS_SAVE_PATH}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# get statistic and first few data of NUM_SAMPLES rows\n",
    "data.info()\n",
    "data.head(NUM_EXAMPLES)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero-shot (OpenAI API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "predict_ratings_zero_shot_and_save(data,\n",
    "                                       columns_for_prediction=[TITLE_COLUMN_NAME],\n",
    "                                       user_column_name=USER_COLUMN_NAME,\n",
    "                                       title_column_name=TITLE_COLUMN_NAME,\n",
    "                                       asin_column_name=ITEM_ID_COLUMN,\n",
    "                                       rating_column_name=RATING_COLUMN_NAME,\n",
    "                                       pause_every_n_users=PAUSE_EVERY_N_USERS,\n",
    "                                       sleep_time=SLEEP_TIME,\n",
    "                                       save_path=ZERO_SHOT_SAVE_PATH,\n",
    "                                       system_content=SYSTEM_CONTENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "zeroshot_saved_data = pd.read_csv(ZERO_SHOT_SAVE_PATH)\n",
    "\n",
    "# Display the original data types\n",
    "print(\"Original Data Types:\")\n",
    "print(zeroshot_saved_data.dtypes)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Attempt to convert ratings to float and add a flag for conversion failure\n",
    "zeroshot_saved_data['is_rating_float'] = pd.to_numeric(zeroshot_saved_data['predicted_rating'], errors='coerce').notna()\n",
    "\n",
    "# Filter rows where ratings are not float\n",
    "non_float_ratings = zeroshot_saved_data[zeroshot_saved_data['is_rating_float'] == False]\n",
    "\n",
    "# total number of rows with non-float ratings\n",
    "print(f\"Total number of rows with non-float ratings: {len(non_float_ratings)}\")\n",
    "\n",
    "# rerun indices for non-float ratings\n",
    "rerun_indices = non_float_ratings.index.tolist()\n",
    "print(f\"Rerun indices: {rerun_indices}\")\n",
    "\n",
    "# Display rows with non-float ratings\n",
    "print(\"Rows with non-float ratings:\")\n",
    "non_float_ratings.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "zero_shot_saved_data = pd.read_csv(ZERO_SHOT_SAVE_PATH)\n",
    "\n",
    "# Rerun predictions for failed cases and save the updated data\n",
    "rerun_save_path = os.path.join(DATA_DIR, 'movie-ml-latest-small/output/rerun_title_large_predictions_zero_shot.csv')\n",
    "columns_for_prediction = ['title']\n",
    "updated_data = rerun_failed_zero_shot_predictions(zero_shot_saved_data, ZERO_SHOT_SAVE_PATH, rerun_save_path, columns_for_prediction, PAUSE_EVERY_N_USERS, SLEEP_TIME)\n",
    "\n",
    "# Remove rows with non-float ratings and save the cleaned data\n",
    "cleaned_data = updated_data[pd.to_numeric(updated_data['predicted_rating'], errors='coerce').notna()]\n",
    "cleaned_data.to_csv(ZERO_SHOT_SAVE_PATH, index=False)\n",
    "\n",
    "# Evaluate the model predictions\n",
    "evaluate_model_predictions_rmse_mae(ZERO_SHOT_SAVE_PATH, NUM_EXAMPLES, 'actual_rating', 'predicted_rating')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Few-shot (OpenAI API)\n",
    "\n",
    "\n",
    "+ For each user, we'll use 4 of their ratings as training data to predict ratings for the rest of their products. Finally, we'll evaluate the predictions against the actual ratings to calculate the overall RMSE and MAE.\n",
    "\n",
    "+ The rating_history_str now includes both the title and the review text for each of the training data rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 observation per reviewer - Few-shot OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "predict_ratings_few_shot_and_save(data,\n",
    "                                      columns_for_training=[TITLE_COLUMN_NAME],\n",
    "                                       columns_for_prediction=[TITLE_COLUMN_NAME],\n",
    "                                       title_column_name=TITLE_COLUMN_NAME, \n",
    "                                       user_column_name=USER_COLUMN_NAME,\n",
    "                                       asin_column_name=ITEM_ID_COLUMN,\n",
    "                                       rating_column_name=RATING_COLUMN_NAME,\n",
    "                                       obs_per_user=TEST_OBSERVATION_PER_USER,\n",
    "                                       pause_every_n_users=PAUSE_EVERY_N_USERS,\n",
    "                                       sleep_time=SLEEP_TIME,\n",
    "                                       save_path=FEW_SHOT_1_OBS_SAVE_PATH,\n",
    "                                       system_content=SYSTEM_CONTENT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "fewshot_saved_data = pd.read_csv(FEW_SHOT_1_OBS_SAVE_PATH)\n",
    "\n",
    "# Display the original data types\n",
    "print(\"Original Data Types:\")\n",
    "print(fewshot_saved_data.dtypes)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Attempt to convert ratings to float and add a flag for conversion failure\n",
    "fewshot_saved_data['is_rating_float'] = pd.to_numeric(fewshot_saved_data['predicted_rating'], errors='coerce').notna()\n",
    "\n",
    "# Filter rows where ratings are not float\n",
    "non_float_ratings = fewshot_saved_data[fewshot_saved_data['is_rating_float'] == False]\n",
    "\n",
    "# total number of rows with non-float ratings\n",
    "print(f\"Total number of rows with non-float ratings: {len(non_float_ratings)}\")\n",
    "\n",
    "# rerun indices for non-float ratings\n",
    "rerun_indices = non_float_ratings.index.tolist()\n",
    "print(f\"Rerun indices: {rerun_indices}\")\n",
    "\n",
    "# Display rows with non-float ratings\n",
    "print(\"Rows with non-float ratings:\")\n",
    "non_float_ratings.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "rerun_failed_few_shot_predictions(data, \n",
    "                                  columns_for_training=[TITLE_COLUMN_NAME],\n",
    "                                  columns_for_prediction=[TITLE_COLUMN_NAME],\n",
    "                                  user_column_name=USER_COLUMN_NAME,\n",
    "                                  title_column_name=TITLE_COLUMN_NAME,\n",
    "                                  asin_column_name=ITEM_ID_COLUMN,\n",
    "                                  rating_column_name=RATING_COLUMN_NAME,\n",
    "                                  obs_per_user=TEST_OBSERVATION_PER_USER,\n",
    "                                  pause_every_n_users=PAUSE_EVERY_N_USERS,\n",
    "                                  sleep_time=SLEEP_TIME,\n",
    "                                  save_path=FEW_SHOT_1_OBS_SAVE_PATH, \n",
    "                                  new_path=FEW_SHOT_1_OBS_RERUN_PATH,\n",
    "                                  rerun_indices=rerun_indices,\n",
    "                                  system_content=SYSTEM_CONTENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "fewshot_saved_data = pd.read_csv(FEW_SHOT_1_OBS_RERUN_PATH)\n",
    "\n",
    "# Display the original data types\n",
    "print(\"Original Data Types:\")\n",
    "print(fewshot_saved_data.dtypes)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Attempt to convert ratings to float and add a flag for conversion failure\n",
    "fewshot_saved_data['is_rating_float'] = pd.to_numeric(fewshot_saved_data['predicted_rating'], errors='coerce').notna()\n",
    "\n",
    "# Filter rows where ratings are not float\n",
    "non_float_ratings = fewshot_saved_data[fewshot_saved_data['is_rating_float'] == False]\n",
    "\n",
    "# total number of rows with non-float ratings\n",
    "print(f\"Total number of rows with non-float ratings: {len(non_float_ratings)}\")\n",
    "\n",
    "# rerun indices for non-float ratings\n",
    "rerun_indices = non_float_ratings.index.tolist()\n",
    "print(f\"Rerun indices: {rerun_indices}\")\n",
    "\n",
    "# Display rows with non-float ratings\n",
    "print(\"Rows with non-float ratings:\")\n",
    "non_float_ratings.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model_predictions_rmse_mae(\n",
    "    data_path=FEW_SHOT_1_OBS_RERUN_PATH,\n",
    "    num_examples=NUM_EXAMPLES,\n",
    "    actual_ratings_column='actual_rating',\n",
    "    predicted_ratings_column='predicted_rating'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limitations:\n",
    "\n",
    "The model might not fully understand the nuanced relationships between products based on titles alone. Additional context or features might be needed for more accurate predictions.\n",
    "This approach might be computationally expensive and slower than traditional matrix factorization or deep learning-based recommendation models, especially for a large number of users.\n",
    "\n",
    "# References\n",
    "\n",
    "+ https://platform.openai.com/docs/api-reference/authentication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Advanced_Programming_for_Data_Science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
